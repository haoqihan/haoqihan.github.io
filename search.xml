<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[python登录服务器或交换机]]></title>
    <url>%2F2019%2F05%2F04%2Fpython%E7%99%BB%E5%BD%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%88%96%E4%BA%A4%E6%8D%A2%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[使用paramiko链接sshparamikoparamiko是一个用于做远程控制的模块，使用该模块可以对远程服务器进行命令或文件操作，值得一说的是，fabric和ansible内部的远程管理就是使用的paramiko来现实。 安装 1pip3 install paramiko 模块使用执行命令–用户名+密码方式1234567891011121314151617#!/usr/bin/env python#coding:utf-8import paramiko# 建立一个sshclient对象ssh = paramiko.SSHClient()# 允许将信任的主机自动加入到host_allow 列表，此方法必须放在connect方法的前面ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())# 调用connect方法连接服务器ssh.connect('192.168.1.108', 22, 'alex', '123')# 执行命令stdin, stdout, stderr = ssh.exec_command('df')# 结果放到stdout中，如果有错误将放到stderr中print(stdout.read().decode('utf-8'))# 关闭连接ssh.close(); 报错： 12345678paramiko\ecdsakey.py:164: CryptographyDeprecationWarning: Support for unsafe construction of public numbers from encoded data will be removed in a future version. Please use EllipticCurvePublicKey.from_encoded_point self.ecdsa_curve.curve_class(), pointinfoparamiko\kex_ecdh_nist.py:39: CryptographyDeprecationWarning: encode_point has been deprecated on EllipticCurvePublicNumbers and will be removed in a future version. Please use EllipticCurvePublicKey.public_bytes to obtain both compressed and uncompressed point encoding. m.add_string(self.Q_C.public_numbers().encode_point())paramiko\kex_ecdh_nist.py:96: CryptographyDeprecationWarning: Support for unsafe construction of public numbers from encoded data will be removed in a future version. Please use EllipticCurvePublicKey.from_encoded_point self.curve, Q_S_bytesparamiko\kex_ecdh_nist.py:111: CryptographyDeprecationWarning: encode_point has been deprecated on EllipticCurvePublicNumbers and will be removed in a future version. Please use EllipticCurvePublicKey.public_bytes to obtain both compressed and uncompressed point encoding. hm.add_string(self.Q_C.public_numbers().encode_point()) 原因paramiko 2.4.2 依赖 cryptography，而最新的cryptography==2.5里有一些弃用的API。 解决删掉cryptography，安装2.4.2，就不会报错了。 12pip uninstall cryptographypip install cryptography==2.4.2 执行命令：秘钥123456789101112import paramikoprivate_key_path = '/home/auto/.ssh/id_rsa'key = paramiko.RSAKey.from_private_key_file(private_key_path)ssh = paramiko.SSHClient()ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())ssh.connect('主机名 ', 端口, '用户名', key)stdin, stdout, stderr = ssh.exec_command('df')print(stdout.read().decode("utf-8"))ssh.close() 上传下载文件：用户名+密码12345678910111213141516171819# 上传文件import os,sysimport paramikot = paramiko.Transport(('182.92.219.86',22))t.connect(username='derek',password='123')sftp = paramiko.SFTPClient.from_transport(t)sftp.put('/tmp/test.py','/tmp/test.py') t.close()# 下载文件import os,sysimport paramikot = paramiko.Transport(('182.92.219.86',22))t.connect(username='derek',password='123')sftp = paramiko.SFTPClient.from_transport(t)sftp.get('/tmp/test.py','/tmp/test2.py')t.close() 上传下载文件-用户名秘钥12345678910111213141516171819202122232425import paramikopravie_key_path = '/home/auto/.ssh/id_rsa'key = paramiko.RSAKey.from_private_key_file(pravie_key_path)t = paramiko.Transport(('182.92.219.86',22))t.connect(username='derek',pkey=key)sftp = paramiko.SFTPClient.from_transport(t)sftp.put('/tmp/test3.py','/tmp/test3.py') t.close()import paramikopravie_key_path = '/home/auto/.ssh/id_rsa'key = paramiko.RSAKey.from_private_key_file(pravie_key_path)t = paramiko.Transport(('182.92.219.86',22))t.connect(username='derek',pkey=key)sftp = paramiko.SFTPClient.from_transport(t)sftp.get('/tmp/test3.py','/tmp/test4.py') t.close()]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
      <tags>
        <tag>运维开发之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins的基本使用]]></title>
    <url>%2F2019%2F05%2F03%2Fjenkins%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[持续集成的介绍 持续集成（CI）是一种软件开发实践 团队成员经常集成他们的工作，每个成员每天至少集成一次 每天可能发生多次集成 每次集成都通过自动化的构建（包括编译，打包，部署，自动化测试）来验证 目的：尽早的发现集成错误 持续集成的优势 快速集成，快速反馈，快速解决 团队信心更强 发布效率更高 Jenkins介绍 持续集成的工具 任务调度平台 Jenkins安装配置 jdk安装以及配置环境变量]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
      <tags>
        <tag>运维开发之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kail linux的使用]]></title>
    <url>%2F2019%2F05%2F03%2Fkail-linux%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[python操作excel]]></title>
    <url>%2F2019%2F05%2F01%2Fpython%E6%93%8D%E4%BD%9Cexcel%2F</url>
    <content type="text"><![CDATA[xlwings模块下载 1pip3 install xlwings 基本使用 openpyxl模块下载 1pip3 install openpyxl 基本使用 写入excel 12345678910111213141516171819202122232425262728293031323334353637383940# 加载写入的，模块from openpyxl import Workbook# 导入背景颜色模块from openpyxl.styles import PatternFill# 新建一个簿wb = Workbook()sheet = wb.activews1 = wb.create_sheet("Mysheet") #默认最后一个ws2 = wb.create_sheet("Mysheet", 0) #第一个# 设置sheet的名称sheet.title = "demo"# 设置背景颜色fill = PatternFill("solid",fgColor="1874CD")#这将返回A4处的单元格，如果尚不存在，则创建一个单元格。值可以直接分配ws['A4']=4 # 也可以通过cell来进行写入，通过行数和列数来找到单元格所在的位置，通过value来赋值ws.cell(row=4, column=2, value=10) # 添加一行ws.append([1,2,3,4])# 循环添加内容for i in range(10): # 添加内容 sheet["A%d"%(i+1)].value = i+1 if i == 6: # 设置背景颜色 sheet["A%d"%(i+1)].fill_type = "lightGrid"# B9处写入平均值sheet['B9'] = '=AVERAGE(B2:B8)'# 保存内容wb.save('666.xlsx') 读取excel 1234567891011121314151617181920212223# 导入库from openpyxl import load_workbook# 打开xlsx文件wb = load_workbook('666.xlsx')# 查看excel表里面有哪些sheet页print(wb.sheetnames) # 读取指定sheet页sheet = wb['demo']# 获取最大行print(sheet.max_row)# 获取最大列print(sheet.max_column)# 获取行和列# 因为按行，所以返回A1, B1, C1这样的顺序for row in sheet.rows: for cell in row: print(cell.value)# A1, A2, A3这样的顺序for column in sheet.columns: for cell in column: print(cell.value) 设置单元格风格123先导入需要的类from openpyxl.styles import Font, colors, Alignment分别可指定字体相关，颜色，和对齐方式。 字体123bold_itatic_24_font = Font(name='等线', size=24, italic=True, color=colors.RED, bold=True)sheet['A1'].font = bold_itatic_24_font 对齐方式12# 设置B1中的数据垂直居中和水平居中sheet['B1'].alignment = Alignment(horizontal='center', vertical='center') 设置行高和列宽1234# 第2行行高sheet.row_dimensions[2].height = 40# C列列宽sheet.column_dimensions['C'].width = 30 合并和拆分单元格123456# 合并单元格， 往左上角写入数据即可sheet.merge_cells('B1:G1') # 合并一行中的几个单元格sheet.merge_cells('A1:C3') # 合并一个矩形区域中的单元格# 拆分单元格sheet.unmerge_cells('A1:C3')]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>奇技淫巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django框架]]></title>
    <url>%2F2019%2F05%2F01%2FDjango%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gin框架]]></title>
    <url>%2F2019%2F05%2F01%2FGin%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[beego框架]]></title>
    <url>%2F2019%2F05%2F01%2Fbeego%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[bee工具应用 123bee new :新建项目目录bee run ：自动编译部署bee generate 自动生成代码 1create table user(id int(11) Not null auto_increment,name varchar(128) not null default '', gender tinyint(4) not null default '0', age int(11) not null default '0',PRIMARY KEY (id));]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask框架]]></title>
    <url>%2F2019%2F05%2F01%2Fflask%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[奇技淫巧]]></title>
    <url>%2F2019%2F04%2F30%2F%E5%A5%87%E6%B7%AB%E5%B7%A7%E6%8A%80%2F</url>
    <content type="text"><![CDATA[图床下载 picgo 图床 Imagine 压缩图片 设置github 注册github（跳过） 新建repo，命名为img 设置token 访问：https://github.com/settings/tokens 点击：generate new token 打钩 “repo“就可以了 点：generate token 注意：把生成的token复制下来，下面需要使用，这个token生成后只会显示一次 设置picGO 打开详细设置 点击“图床设置”-“GitHub图床” 设置仓库名：如：github名称/仓库名 设定分支名：如：master 设定token：上面让你生成的token 开始使用 截图后用imagine压缩 直接拖拽到picGO上 粘贴剪切板的链接到markdown文档里 jupyter 制作网页ppt安装和使用 1234567pip3 install jupyter # or python -m pip install jupyterpip3 install RISEjupyter-nbextension install rise --py --sys-prefixjupyter-nbextension enable rise --py --sys-prefixjupyter notebook # 启动jupyter 压测工具 Locust安装 12pip3 install locustio文档地址：https://docs.locust.io/en/stable/ 快速生成flask项目安装： 1234pip3 install cookiecuttercookiecutter https://github.com/sloria/cookiecutter-flask.git github地址：https://github.com/sloria/cookiecutter-flask 基本使用 12 视频下载（youtube-dl、you-get）**安装 12pip3 install --upgrade youtube-dlpip3 install --upgrade you-get 数据可视化模块安装 1pip3 install pyecharts 文档地址（中文）：https://pyecharts.org/#/zh-cn/ linux命令tldr命令 github地址：https://github.com/tldr-pages/tldr 1pip3 install tldr # 提示命令如何使用 github地址： fzf命令** github地址：https://github.com/junegunn/fzf 12git clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf~/.fzf/install thefuck 下载 1pip3 install thefuck github地址：https://github.com/nvbn/thefuck 基本使用** 12345678910cd ** # 然后tabctrl + r # 查看历史命令fzf --preview '[[ $(file --mime &#123;&#125;) =~ binary ]] &amp;&amp; echo &#123;&#125; is a binary file || (bat --style=numbers --color=always &#123;&#125; || highlight -O ansi -l &#123;&#125; || coderay &#123;&#125; || rougify &#123;&#125; || cat &#123;&#125;) 2&gt; /dev/null | head -500' vim小游戏下载 123git clone https://github.com/jmoon018/PacVim.gitcd PacVim[sudo] make install 玩法 chrome插件 FeHelper插件 Tampermonkey（油猴子） vimium Octotree Momentum OneTab 管理python环境下载 1pip3 install virtualenvwrapper 设置环境变量 12345678910把下面两行代码添加到 ~/.bashrc文件中打开文件vim ~/.bashrc写入以下两行代码export WORKON_HOME=~/Envs #设置virtualenv的统一管理目录export VIRTUALENVWRAPPER_VIRTUALENV_ARGS='--no-site-packages' #添加virtualenvwrapper的参数，生成干净隔绝的环境export VIRTUALENVWRAPPER_PYTHON=/opt/python347/bin/python3 #指定python解释器source /opt/python34/bin/virtualenvwrapper.sh #执行virtualenvwrapper安装脚本读取文件，使得生效，此时已经可以使用virtalenvwrappersource ~/.bashrc 常用命令 12345678910111213141516# 创建一个虚拟环境mkvirtualenv 环境名称 # 例如：mkvirtualenv flask_demo# 激活虚拟环境workon 环境名称 # 例子：workon flask_demo#停止虚拟环境deactivate# 删除虚拟环境，需要先退出虚拟环境rmvirtualenv 环境名称 # 例子：rmvirtualenv flask_demo# 列举所有的环境lsvirtualenv# 文档地址：https://virtualenvwrapper.readthedocs.io/en/latest/command_ref.html 文档查询工具下载 123地址：https://zealdocs.org/MacOS系统的：https://kapeli.com/dash]]></content>
      <categories>
        <category>奇技淫巧</category>
      </categories>
      <tags>
        <tag>奇技淫巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx笔记]]></title>
    <url>%2F2019%2F04%2F26%2Fnginx%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[NGINX的三个主要应用场景 静态资源服务 通过本地文件系统提供服务 反向代理服务 nginx的强大性能 缓存 负载均衡 API服务 Nginx为什么会出现 互联网的数量快速增长 互联网的快速普及 全球网 物联网 摩尔定律：性能提升 低效Apache 一个链接对一个进程 nginx的优点 高并发，高性能 可扩展性好 高可靠性 热部署 BDS许可证 nginx的组成 Nginx二进制可执行文件 由各模块源码编译的一个文件 nginx.conf配置文件 控制nginx的行为 access.log访问日志 记录每一条http请求信息 error.log错误日志 定位问题 nginx的安装123456789101112131415nginx地址：http://nginx.org/en/download.htmlwget Stable version 下的nginx# 下载nginxwget http://nginx.org/download/nginx-1.16.0.tar.gz # 解压nginxtar -xzf nginx-1.16.0.tar.gz # 进入nginxcd nginx-1.16.0# 指定编译目录./configure --prefix=/home/haoqihan/nginx --prefix=PATH 设置编译目录 # 编译 make # 安装 make install nginx的目录结构12# 让vim编辑的时候高亮显示cp -r contrib/vim/* ~/.vim/ nginx常用配置语法 配置文件由指令和指令块构成 每条指令以；分号结尾，指令与参数间以空格符号分隔 指令块以{}大括号将多条指令组织在一起 include语句允许组合多个配置文件以提升代码的可维护性 使用#符号添加注释，提高可读性 使用$符号使用变量 部分指令的参数支持正则表达式 配置参数 时间单位 time ms（毫秒） milliseconds s（秒） seconds m（分钟） minutes h（小时） hours d（天） days w（周） weeks M（月） months，30 days y（年） years 365days 空间单位 bytes k、K kilobytes m、M megabytes g、G gigabytes http配置的指令块 http server upstream location Nginx命令行 格式：nginx -s reload 帮助 -？ -h 使用指定的配置文件 -c 指定配置指令 -g 指定运行目录 -p 发送信号 -s 立刻停止 stop 优雅的停止： quit 重载配置文件 reload 重新开始记录日志文件 reopen 测试配置文件是否语法错误 -t -T 打印nginx的版本信息，编译信息等 -v -V 热部署1234567# 把二进制文件改名cp nginx nginx.old# 把编译好的二进制文件，进行替换# 把旧进程kill掉kill -USR2 pid# 把老进程进行关闭kill -WINCH pid 日志切割1234# 移动老日志mv 老日志 old.log# 重新生成日志nginx -s reopen nginx搭建简单的web静态资源网站1234567891011121314151617181920212223# 开启gzip压缩gzip on;# 字节数小于1的话就不进行压缩了gzip_min_length 1;# 压缩级别gzip_comp_level 2;server &#123; listen 8080; server_name localhost; #charset koi8-r; access_log logs/host.access.log main; location / &#123; # 设置index地址 alias dlib/; # 可直接访问文件 autoindex on; # 现在访问速度为1k set $limet_rate 1k; &#125; nginx反向代理12345678910111213141516171819listen 127.0.0.1:8000 代表只能本机的800端口访问# 配置上游服务upstream local&#123; server 127.0.0.1:8080&#125;# 设置内存存储地址proxy_cache_path /home/haoqihan/nginxcache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_cache my_cache;# 会把这些存储在内存中proxy_cache_key $host$uri$is_args$args; 用GoAccess实现可视化并实时监控access日志123下载： apt-get install goaccess# 把日志生成一个html页面goaccess access.log -o ../html/report.html --real-time-html --time-format='%H:%M:%S' --date-format='%d/%b/%Y' --log-format=COMBINED ssl安全协议为nginx增加一个https证书1安装：sudo yum install certbot python2-certbot-nginx]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
      <tags>
        <tag>运维开发之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python测试]]></title>
    <url>%2F2019%2F04%2F22%2Fpython%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[pytest模块安装 1pip3 install pytest 第一个案例 demo.py 12345678def func(x): return x + 1 def test_func1(): assert func(4) == 5 # 成功示例 def test_func2(): assert func(3) == 5 # 失败示例 test_create.py 1234567class TestClass(object): def test_one(self): x = "this" assert 'h' in x def test_two(self): x = "hello" assert hasattr(x, 'check') 执行方法 1pytest 文件名 # 可以执行文件中的测试代码 unittest框架htmlreport模块]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言模块]]></title>
    <url>%2F2019%2F04%2F22%2Fgo%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[数据库redis模块]]></content>
      <categories>
        <category>go语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode的使用方法]]></title>
    <url>%2F2019%2F04%2F18%2Fvscode%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[快捷键 1234567891011Ctrl + C 复制Ctrl + V 粘贴Ctrl + X 剪切Ctrl + F 查找Ctrl + H 替换Ctrl + S 保存Ctrl + / 行注释Ctrl + Alt + A 块注释Ctrl + Shift + Enter 上方插入一行Ctrl + Shift + F 文件夹查找Ctrl + Enter 下方插入一行 git的使用]]></content>
      <categories>
        <category>vscode</category>
      </categories>
      <tags>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统]]></title>
    <url>%2F2019%2F04%2F16%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[linux常考命令tldr：类似于man命令 1pip3 install tldr 文件、目录操作 chown chmod chgrp ls rm cd cp mv touch rename ln（软连接和硬链接） locate find grep 定位查找和搜索 文件或日志查看工具 编辑器 vi nano cat head tail 查看文件 more less 交互式查看文件 进程操作的命令 ps 查看进程 kill 杀死进程 top htop 监控进程 内存相关命令 free 查看内存 网络操作命令 ifconfig 查看网卡信息 lsof、netstat 查看端口信息 ssh scp 远程登录和复制 tcpdump 抓包 常见用户、组操作命令 useradd 、usermod 增加和修改用户 groupadd、groupmod 增加和修改组 进程与线程进程与线程的区别 进程是对运行时程序的封装，是系统资源调度和分配的基本单位 线程是进程的子任务，cpu调度的基本单位，实现进程内并发 一个进程可以包含多个线程，线程依赖进程存在，并共享进程内存 什么是线程安全python那些操作是线程安全的？ 一个操作可以在多线程的环境中安全使用，获取正确结果 线程安全的操作就好比线程是顺序执行，而不是并发执行的 一般涉及到写操作数据需要考虑如何让多个线程安全访问数据 线程同步的方式 互斥量（锁） ：通过互斥机制防止多线程同时访问公共资源 信号量：控制同一时刻多线程访问同一资源的线程数 事件：通过通知的方式保持多个线程同步 进程之间通信的方式 管道 匿名管道 有名管道 信号 比如ctrl + c 产生sigint 程序终止信号 消息队列 共享内存 信号量 套接字（socket） linux内存相关什么是分页机制 逻辑地址和物理地址分离的内存分配管理方案 程序的逻辑地址划分为固定大小的页 物理地址划分为同样大小的帧 通过页表对应逻辑地址和物理地址 什么是分段机制 分段为了满足代码的一些逻辑需求 数据共享 数据保护 动态链接 通过段表实现逻辑地址和物理地址的映射关系 每个段内部都是连续的内存分配，段和段之间是离散分配的 分页和分段的区别 页是出于内存利用率的角度提出的离散分配机制 段是出于用户角度，用于数据保护，数据隔离等用途的管理机制 页的大小是固定的，操作系统决定，段的大小不确定，用户程序决定 什么是虚拟内存 通过把部分暂时不用的内存信息放在硬盘上 局部性原理，程序运行时只有部分必要信息装入内存 内存中暂时不需要的内容放到硬盘上 系统似乎提供了比实际内存大的多的容量，称之为虚拟内存 什么是内存抖动（颠簸） 本质是频繁的页调度行为 频繁的页调度，进程不断产生缺页终端 置换一个页，又不断再次需要这个页 运行程序太多，页面替换策略不好，终止进程或者增加物理内存 python垃圾回收机制的原理 引用计数为主（缺点：循环引用） 引入标记清除和分代回收解决引用计数的问题 引用计数为主+标记清除和分代回收为辅 什么时候引用计数增加？ 对象被创建 a=1 对象被引用 b = a 对象作为参数被传递 func（a） 对象存储在容器中 l = 【a】 什么时候引用计数减少？ 显示使用del a 引用指向别的对象 b = None 离开的对象的作用域比如函数执行结束 从一个容器移除对象或销毁容器]]></content>
      <categories>
        <category>python面试</category>
      </categories>
      <tags>
        <tag>python面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python系统设计]]></title>
    <url>%2F2019%2F04%2F16%2Fpython%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[什么是系统设计？ 系统设计是一个定义系统架构，模块，接口和数据满足特定需求的过程 比如设计一个短网址服务，评论服务，Feed流服务，抢红包系统 微服务架构有很多系统被按照业务拆分，需要单独设计系统服务 系统设计 需要具备相关领域，算法的经验，有一定架构设计能力 熟悉后端计数组件，比如 消息队列 缓存 数据库 框架 具备文档撰写，流程图绘制，架构设计，编码实现等功能 系统设计三大要素 使用场景和限制条件 数据存储设计 算法模块设计 按照三要素来回答 问面试官：什么场景和条件下使用 这个系统是什么地方使用的，比如短网址系统提供给各站各种服务生成短网址 限制条件：用过估计多少，至少能支撑多少用户 估算qps ： 峰值的qps（每秒请求量多少）是多少。平均qps是多少 数据存储设计 数据库的选型 按需求设计表，需要那些字段，使用什么数据类型，数据增长规模 数据库选型：是否需要持久化，使用关系型还是Nosql 如何优化？如何设计索引？是否可以使用缓存 算法模块的设计 算法是解决问题的核心， 程序=算法+数据结构 系统=服务+存储 需要那些接口，接口如何设计 使用什么算法或者模型 不同实现方式之间的优劣对比，如何取舍 扩展问题 用户多了，qps高了如何处理 数据存储多了不够存了如何处理 故障如何处理？单点失败，多点失败，雪崩问题 如何设计短网址系统设计与实现？问题 什么是短网址服务？包含那些功能 短网址系统的存储设计，需要那些字段 如何设计算法生成短网址 什么是短网址服务？ 把一个长网址转换短网址的服务 比如：https://bitly.com/ 转换之后网址的后缀不超过7位（字符或者数字） 场景和限制：提供短网址服务为公司其他各业务服务 功能：一个长网址转换为短网址 要求短网址的后缀不超过7位 预估峰值插入请求数量级数百，查询量级上千 数据库存储设计 根据需求设计数据存储方式 使用mysql即可满足 需要的字段有那些？ id token （索引） url（原网址） create add 算法实现设计设计两个API： long2short_url（把长URL转换为短url）, short2long_url（拿短url获取长url） 1.md5摘要算法，取前7个字符，但是冲突 2.类似于62进制数字，进制0，1，十六进制 0-9 a-f 自增序列算法 自增id 需要一个计数器 redis incr mysql 建表语句 12345678create table short_url( id bigint unsigned not null auto_increment, token varchar(10), url varchar(2048), create_at timestamp not null default current_timestamp, primary key(`id`), key `idx_token` (`token`)); 练习如何设计一个秒杀系统？ 难点：如何应对高并发用户请求 什么是秒杀系统？你有没有用过 如何根据三要素来设计 秒杀系统涉及的后端组件 ​ ​]]></content>
      <categories>
        <category>python面试</category>
      </categories>
      <tags>
        <tag>python面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python数据库]]></title>
    <url>%2F2019%2F04%2F16%2Fpython%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[问题： 事务的原理，特性，事务并发控制 常用的字段，含义和区别 常用数据库引擎之间区别 什么是事务？ 事务是数据库并发控制的基本单位 事务可以看做一系列sql语句的集合 事务必须要么全部执行，要么全部执行失败（回滚） 事务的ACID特性 原子性（Atomicity）： 一个事务所有操作全部完成或全部失败 一致性（Consistency）事务开始和结束之后数据完整性没有被破坏 隔离性（Isolation）： 允许多个事务同事对数据库修改和读写 持久性（Durability） 事务结束后，修改是永久不会丢失的 事务的并发控制可能产生那些问题 幻读（phantom read） 一个事务第二次查出现第一次没有的结果 非重复读（nonrepeatable read）一个事务重复读两次得到不同的结果 脏读（dirty read） 一个事务读取到另一个事务没有提交的修改 修改丢失（lost update） 并发写入造成的一些修改丢失 四种事务的隔离级别 读未提交（read uncommitted） 别的事务可以读取到未提交改变 读已提交（read committed）只能读取已经提交的数据 可重复读（repeatable read）： 同一个事务先后查询的结果都一样 mysql innoDB 默认实现可重复读级别 串行化（serializable） 事务完全串行化执行，隔离级别最高，但是效率最低 如何解决高并发场景下的插入重复？ 使用数据库的唯一索引 使用队列异步写入 使用redis等实现分布式锁 乐观锁和悲观锁 悲观锁是先获取到锁之后再进行操作：一锁二差三更新 select for update 乐观锁 先修改，更新的时候发现数据已经变了，就回滚（check and set） 乐观锁一般通过版本号或时间戳来实现 使用需要根据响应速度，冲突频率，重试代价来判断使用哪一种 mysql常用的数据类型 InnoDB 与 MyIsAM的区别 MyISAM不支持事务，InnoDB支持事务 MyISAM不支持外键，InnoDB支持外键 MyISAM只支持表锁，InnoDB支持行锁和表锁 MyISAM支持全文索引，InnoDB不支持全文索引（5.6.24之后加上了索引） mysql索引原理及优化常见考题索引的原理，类型，结构 创建索引的注意事项，使用原则 如何排查和消除慢查询 什么是索引？ 索引是数据库表中一个或多个列进行排序的数据结构 索引能够大幅度提升检索速度 创建，更新索引本身也会耗费空间和时间的 什么是B-Tree（为什么数据库要使用B+Tree） 线性查找：一个一个找，实现简单，但是太慢了 二分查找： 有序，简单，要求是有序的，插入特别慢 hash ： 查询快，占用空间，不适合存储大规模数据 二叉树：插入和查询很快（log（n）），无法存大规模数据，复杂度退化 平衡树：解决bst 退化的问题，树是平衡的 多路查找树：一个父亲多个孩子节点，节点过多树高不会特别深 多路平衡查找树：B-Tree 什么是B-Tree，为什么使用B-Tree？ 多路平衡查找树（每个节点最多m（m&gt;=2）个孩子，称为m阶或度） 叶节点具有相同的深度 节点中的数据key从左到右是递增的 什么是B+Tree B+树是B-Tree树的变形 mysql实际使用B+Tree作为索引的数据结构 只在叶子节点带有指向记录的指针（为什么，可以增加树的度） 叶子节点通过指针相连，为什么，实现范围查询 msyql索引的类型 普通索引（create index） 唯一索引：索引列的值必须唯一（create unioue index） 多列索引 主键索引（primary key ）一个表中只能有一个主键 全文索引（fulltext index），innoDB不支持（5.6后支持） 什么时候创建索引 建表的时候需要根据查询需求来创建索引 经常用作查询条件的字段（where条件） 经常用作表连接的字段 经常出现在order by，group by之后的字段 创建索引有那些需要注意的 非空字段 not null ，mysql很难对空值做查询优化 区分度高，离散度大，作为索引的字段值尽量不要有大量相同值 索引的长度不要太长（比较耗费时间） 索引什么时候失效 模糊匹配，类型隐转，最左匹配 以%开头的like语句，模糊搜索 出现隐式类型转换（在python这种动态语言查询中需要注意） 没有满足最左前缀原则 什么是聚集索引和非聚集索引 聚集还是非聚集指的是B+Tree叶节点存的是指针还是数据记录 MyISAM索引和数据分离，使用的是非聚集索引 InnoDB数据文件就是索引文件，主键索引就是聚集索引 如何排查慢查询 慢查询通常是缺少索引，索引不合理或者业务代码实现导致的 slow_query_log_file 开启兵器查询慢查询日志 通过explain 排查索引问题 调整数据修改索引，业务代码层限制不合理访问 sql语句编写常考题sql语句考察各种链接为重点 内连接（inner join） 两个表都存在匹配时，才会匹配行 外链接（left、right join）返回一个表的行，即使另一个没有匹配 全连接（full join） 只要某一个表存在匹配就返回 （mysql中不支持full join 可以使用left join+ union+right join） 12345678# 内连接select * from Channel inner JOIN Tage on Channel.id = Tage.id# 左链接select * from Channel left JOIN Tage on Channel.id = Tage.id# 右链接select * from Channel right JOIN Tage on Channel.id = Tage.id# 全链接from Channel left JOIN Tage on Channel.id = Tage.id union select * from Channel right JOIN Tage on Channel.id = Tage.id 缓存的使用场景 问什么要使用缓存？ 缓解关系数据库（常见的是Mysql）并发访问的压力，热点数据 减少响应时间： 内存IO速度比磁盘快 提升吞吐量：Redis等内存数据库单机就可以支撑很大的并发 简述redis常用的数据类型和使用场景 string（字符串） 用来实现简单的kv键值对存储，比如计数器 List（链表）：实现双向链表，比如用户关注，粉丝列表 Hash（哈希表）：用来存储彼此相关信息的键值对 Set（集合） 存储不重复元素，比如用户的关注者 sorted Set（有序集合） 实时信息排行榜 redis各种类型的底层实现 string：整数或者sds（Simple Dynamic String） List： ziplist 或者double linked list ziplist：通过一个连续的内存块实现list结构，其中的每个entry节点头部保存节点前后长度信息，实现双向链表功能 Hash：ziplist 或者hashtable set intset 或者hashtable sortedSet： skiplist跳跃表 redis实现的跳跃表是什么 sorted set 为了简化实现，使用skiplist 而不是平衡树实现 redis支持两种方式实现持久化 快照方式：把数据快照放在磁盘二进制文件中，dump.rdb 快照的实现方式是指定时间间隔把redis数据库状态保存到一个压缩二进制文件中 AOF：每个写命令追加到appendonly.aof 中 可以通过修改Redis配置实现 什么是Redis事务？ 将多个请求打包，一次性，按序执行多个命令的机制 Redis通过MULTI，EXEC，WATCH 等命令实现事务功能 1python redis-py plpline = conn.pipline（transaction=True） Redis如何实现分布式锁？ 使用setnx实现加锁，可以同事通过expire添加超时时间 锁的value值可以使用一个随机的uuid或者特定的命名 释放锁的时候，通过uuid判断是否是该锁，是则执行delete释放锁 使用缓存的模式 cache Aside 同时更新缓存和数据库 Read、Write Through：先更新缓存，缓存负责同步更新数据库 Write Behind Caching：先更新缓存，缓存定期异步更新数据库 如何解决缓存穿透问题 原因 大量查询不到的数据的请求落到后端数据库，数据库压力增大 由于大量缓存查不到就去数据库取，数据库也没有要查的数据 解决 对于没有查到的数据返回None的数据也缓存下来 插入数据的时候删除一个缓存，或者设置较短的超时时间 如何解决缓存击穿问题？ 原因 某些非常热点的数据key过期，大量请求打到后端数据库 热点数据key失效导致大量请求打到数据库增加数据库压力 解决 分布式锁： 获取锁的线程从数据库拉数据更新缓存，其他线程等待 异步后台更新：后台任务针对过期的key 自动刷新 如何解决缓存雪崩问题 原因 缓存不可用或者大量缓存key，大量请求直接打到数据库 解决 多级缓存： 不同级别的key设置不同的超时时间 随机超时：key的超时时间随机设置，防止同时超时‘ 架构层：提升系统可用性，监控，报警完善 练习索引的理解？ 为什么mysql数据库的主键使用自增证书比较好 使用uuid可以吗？为什么 如果是分布式系统下我们如何生成自己数据库中的自增id redis的应用？ 请基于Redis编写代码实现一个分布式锁 要求：支持超时时间参数 深入思考：如果Redis单个节点宕机，如何处理，还有其他方式实现分布式锁吗 ​]]></content>
      <categories>
        <category>python面试</category>
      </categories>
      <tags>
        <tag>python面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python网络编程]]></title>
    <url>%2F2019%2F04%2F16%2Fpython%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[浏览器输入一个url中间经历的过程DNS 缓存 -&gt; DNS查询 -&gt; TCP握手 -&gt; HTTP请求 ——&gt; 反向代理Nginx -&gt;uwsgi、gunicom -&gt; web app响应 -&gt; TCP挥手 TCP、UDP的区别 TCP 面向链接，可靠的，基于字节流 UDP 无链接，不可靠，面向报文 HTTP协议HTTP协议有哪些部分组成？ 状态行 请求头 消息主体 curl 和 pip3 install httpie http 请求网页 响应 状态行 响应头 响应主体 状态码 1×× 信息 服务器收到请求，需要请求者继续操做 2×× 成功 操作操作被成功接受并处理 3×× 重定向 需要进一步操作完成请求 4×× 客户端错误 请求有语法错误或者无法完成请求 5×× 服务器错误 服务器在处理请求的过程中发生错误 GET 和 POST 的区别 restful语义上一个是获取一个是创建 GET是幂等的，POST非幂等的 GET请求参数放在明文中，长度限制，POST放在请求体中比较安全 什么是幂等的 幂等方法是无论调用多少次都得到相同结果的HTTP方法 例如：a=4是幂等的，a+=4 就是非幂等的 幂等的方法客户端可以安全的重发请求 什么是HTTP的长链接 短连接： 建立链接 数据传输 关闭链接（链接的建立和关闭） 长连接： Connection：keep-alive 保持TCP链接不断开 如何区分不同的HTTP请求呢？ Content-Length Transfer-Encoding chunked cookie 和 session的区别 session一般是服务器生成之后给客户端（通过URL参数或者Cookie） Cookie是实现Session的一种机制，通过http 的cookie字段实现 Session通过在服务器保存sessionid来识别用户，cookie存储在客户端 TCP socket 编程原理 使用socket 接口发送http请求. HTTP建立在TCP基础之上 HTTP是基于文本的协议 IO多路复用五种IO模型 阻塞式IO 非阻塞式IO IO多路复用 信号式IO 异步IO 如何提升服务器的并发能力一些常见的提升并发能力的方式 多线程模型，创建新的线程处理请求 多进程模型，创建新的进程处理请求 开销大 可以使用线程池和进程池解决 资源占用比较多 难以创建太多 IO多路复用，实现单进程同时处理多个socket请求 什么是IO多路复用？ 操作系统提供的同时监听多个sockt的机制 为实现高并发需要一种机制并发处理多个socket LINUX常见的是select poll epoll 可以使用单线程 单进程 处理多个socket python如何实现IO多路复用 python的IO多路复用基于操作系统实现（select poll epoll python2 select模块 python3 selectors 模块 python并发网络库？tornado Gevent Asyncio Tornado 框架 Tornado 适用于微服务，实现Restful接口 底层基于Linux 多路复用 可以通过协程或者回调实现异步编程 不过生态不完善，响应的异步框架比如ORM不完善 Gevent 高性能的并发网络库 基于轻量级绿色线程(greenlet) 实现并发 需要注意monkey patch ，gevent修改了内置socket为非阻塞的 配合gunicorn 和gevent 部署作为wsgi server 推荐：《Gevent 程序员指南》 Asyncio 基于协程实现的内置并发网络库 python引入到内置库，协程+事件循环 生态不够完善，没有大规模的生产环境检验 目前应用不够广泛，基于Aiohttp可以实现一些小的服务 问题： 使用asyncio实现一个异步爬虫类]]></content>
      <categories>
        <category>python面试</category>
      </categories>
      <tags>
        <tag>python面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python算法与数据结构]]></title>
    <url>%2F2019%2F04%2F16%2Fpython%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[collections模块namedtuple（） 可以使用名称访问tuple1234import collectionspoint = collections.namedtuple('porint','x,y')p = point(1,2)print(p.x) deque（） 双端队列123456import collections de = collections.deque()de.append(1)de.appendleft(2)de.pop()de.popleft() counter（） 计数器123import collections c= collections.Counter('sadsafdsjfhdgjhdjfgbdfjbjvkdhf')print(c) ordereDict 有序字典12345import collections dic = collections.OrderedDict()dic['1'] = 1dic['2'] = 2print(dic) defaultdict 给dict做一个初始化1234import collections dd = collections.defaultdict(int)dd['a'] += 1print(dd) python dict底层结构 dict 底层使用哈希表 为了快速查找使用哈希表作为底层结构 哈希表平均查找时间复杂度O(1) cpython 解释器使用二次探查解决哈希冲突 解决哈希冲突： 链接法 元素key冲突之后使用一个链表，填充形同key的元素 探查法（开放寻址法） 探查法又分为：线性探查和二次探查等 开放寻址法是冲突之后根据一种方式（二次探查）寻找下一个可用的槽 cpython使用的是二次探查的 哈希表扩容 python的list和tuple的区别 都是线性结构，支持下标访问 list是可变对象，tuple保存的引用不可变 保存引用不可变是指你没法替换掉这个对象，但是如果对象本身是一个可变对象，是可以修改这个引用指向的可变对象的 list 没法作为字典的key，tuple可以（可变对象不可hash） LRUCache least-Recently-Used 替换掉最近最少使用的对象 缓存剔除策略，当缓存空间不够用的时候，需要一种方式剔除key 常见的有LRU LFU LRU通过使用一个循环双端队列不断把最新访问的key放在表头实现 实现LRUCache 字典用来缓存，循环双端链表用来记录访问顺序 利用python内置的dict+collections.OrderedDict（）实现 dict 用来当做k、v键值对的缓存 OrderedDict 用来实现最新最近访问的key 算法常考题 排序+查找，重中之重 常考排序算法：冒泡排序，快速排序，归并排序，堆排序 线性查找+二分查找 能独立实现代码（手写） 能够分析时间空间复杂度 python数据结构常考题python web后端常考数据结构 常见的数据结构链表，队列，栈，二叉树，堆 使用内置数据结构实现高级数据结构，比如内置的list，deque实现栈 链表 链表有单链表，双链表，循环双链表 如何使用python来标示链表结构 实现链表常见操作，比如插入节点，反转链表，合并多个链表等 链表涉及到指针操作比较复杂，容易出错，经常用做考题 熟悉链表的定义和常用操作 常考题：删除一个链表节点 常考题：合并两个有序链表 常考题：反转一个链表 队列 队列（queue） 是先进先出结构 实现队列的apend和pop操作，如何做到先进先出 使用python的list或者collections.deque实现队列 常考题：用栈实现一个队列 栈 栈（stack） 是后进先出 实现栈的push和pop操作，如何实现 同样使用python的list或者collections.deque实现栈 常考题：用队列实现一个栈 字典和集合 python dict、set底层都是哈希表 哈希表的实现原理，底层就是一个数组 根据哈希函数快速定位一个元素，平均查找O（1） 不断加入元素会引起哈希表重新开辟空间，拷贝之前元素到新的数组 二叉树 先序，中序，后序遍历 先序：先处理根，之后是左子树，然后是右子树 中序：先处理左子树，然后是根，然后是右子树 后序：先处理左子树，然后是右子树，最后是根 二叉树涉及到递归和指针操作，常结合递归考察 二叉树的操作很多可以用递归方式解决，不了解递归会比较吃力 常考题：二叉树的镜像 常考题：如何层序便利二叉树（广度优先） 堆 堆其实就是一个完全二叉树，有最大堆和最小堆 最大堆：对于每个非叶子节点v，v的值都比他的两个孩子大 最小堆：对于每个非叶子节点v，v的值都比他的两个孩子小 最大堆支持每次pop操作获取最大的元素，最小堆获取最小元素 堆的常考题基本围绕在合并多个有序（数组，链表）；topk问题 理解堆的概念，堆是完全二叉树，有最大堆和最小堆 会使用python内置的heapq模块实现堆的操作 字符串 反转一个字符串 判断一个数字是否是回环数字]]></content>
      <categories>
        <category>python面试</category>
      </categories>
      <tags>
        <tag>python面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web框架]]></title>
    <url>%2F2019%2F04%2F16%2Fweb%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[python wsgi 和web框架什么是WSGI？ web server 与 web框架交互的规范 目的是解决：python web server的乱象 django vs Flask vs Tornado django : 大而全，内置ORM，Admin等插件，第三方插件丰富 flask 微框架，插件机制，比较灵活 cookiecutter-flask 生成统一模板 Tornado 异步支持的微框架和异步网络库（轮子少） 什么是mvc模式 Model 负责业务对象和数据库之间的交互 View 负责与用户的交互展示 Controller 接收请求参数调用模型和视图完成请求 什么是ORM？ 对象关系映射 用于实现业务对象与数据表中的字段映射 常见的ORM ：sqlalchemy django ORM Peewee 优势：代码更加面向对象，代码量更少，灵活性高，提升开发效率 web安全常见的安全问题 sql注入 XSS （跨站脚本攻击） csrf（跨站请求伪造） 什么是sql注入 通过构造特殊的输入参数传入web应用 通常由于程序员未堆输入进行过滤，直接动态拼接sql导致的 可以使用开源工具sqlmap SQLLninja 检测 如何防范？ web安全一大原则：永远不要相信用户的任何输入 对输入参数做好检查（类型和范围） 过滤和转义特殊字符 不要直接拼接sql，使用ORM可以大大降低sql注入风险 数据库层： 做好权限管理配置，不要明文存储敏感信息 什么是XSS 而已用户将代码植入到提供给其他用户使用的页面中，未经转义的而已代码输出到其他用户的浏览器执行 用户浏览页面的时候嵌入页面中的脚本（js） 会执行，攻击用户 主要分为两类：反射型（非持久型），存储型（持久型） 前后端分离什么是前后端分离？ 后端负责提供数据接口，不再渲染模板，前端获取数据并呈现 前后端解耦，接口复用（前端和客户端公用接口），减少开发量 各司其职，前后端同步开发，提升工作效率，定义好接口规范 更利调试（mock） ，测试和运维部署 缺点：对于单页的应用不好做seo 什么是RESTFUL？ 表现层状态转移，由HTTP协议的主要设计者Roy Fielding 提出 资源 表现层 状态转化 资源： 使用URL 指向的一个实体 表现层： 资源的表现形式，比如图片，html文本等 状态转化：GET POST DELETE PUT http动词操作资源，实现资源状态的改变 是一种以资源为中心的web软件架构风格，可以使用ajax 或restful web 构建应用 规范和准则 所有事务抽象为资源，资源对应唯一 资源通过接口操作实现状态转移，操作本身是无状态的 对资源的操作不会改变资源标识 restful 风格API接口 通过HTTP GET POST PUT DELETE 来增删改查资源 一般使用json格式返回数据 一般web框架都有响应的插件支持restful api 练习什么是HTTP和HTTPS？ HTTPS 和HTTP 的区别 你了解什么是对称加密和非对称加密 HTTP的通信过程是什么样的 ​ ​ ​]]></content>
      <categories>
        <category>python面试</category>
      </categories>
      <tags>
        <tag>python面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python编程范式]]></title>
    <url>%2F2019%2F04%2F16%2Fpython%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[什么是面对对象编程？ OOP编程（面向对象） 把对象作为基本单元，把对象抽象成类（class） 包含成员和方法 数据封装，继承，多态 python中使用类来实现，过程式编程（函数），OOP（类） 组合与继承 使用面对对象编程时，优先使用组合而非继承 组合是使用其他类的实例作为自己的一个属性（Has-a） 关系 子类继承父类的方法（Is-a 关系） 优先使用组合保持代码简单 类变量与实例变量的区别区别类变量和实例变量 类变量由所有实例共享 实例变量由实例单独享有，不同实例之间互不影响 当我们需要在一个类的不同实例之间共享变量需要使用类变量 classmethod/starticmethod区别 都可以通过class.method（）的方法使用 classmethod第一个参数是cls，可以引用类变量 starticmethod使用起来和普通函数一样，只是放在类里面 什么是元类 元类是创建类的类 元类允许我们控制类的生成，比如修改类的属性等 使用type来定义元类 元类最常见的一个使用场景就是ORM框架 12x = type('X',(object,),&#123;'abc':123,'xx':'xx'&#125;)print(x.xx 装饰器 装饰器是接受函数作为参数，添加功能后返回一个新函数的函数（类） 通过@使用 类写装饰器 12345678910111213141516# 一个简单的测算函数运行时间的装饰器class LogTime: def __init__(self, use_int=False): self.use_int = use_int def __call__(self, func): def _log(*args, **kwargs): beg = time.time() res = func(*args, **kwargs) print('use time:&#123;&#125;,&#123;&#125;'.format(time.time() - beg, self.use_int)) return res return _log# 使用时需要加（）@LogTime()def func(): time.sleep(1) 设计模式创建型设计模式工厂模式：解决对象创建问题 解决对象创建问题 解耦对象的创建和使用 包括工厂方法和抽象工厂 12345678910111213class Dog: def speak(self): print('wangwang')class CatToy: def speak(self): print('miao miao')def toy_factory(toy_type): if toy_type == 'dog': return Dog() elif toy_type == 'cat': return CatToy() 构造模式 用来控制复杂对象构造 创建和分离，比如你要买电脑，工厂模式直接把电脑给你 但是构造模式允许你自己定义电脑配置，组装完成后给你 原型模式 通过克隆原型来创建新的实例 可以使用相同的原型，通过修改部分属性来创建新的实例 用途：对于一些创建实例开销比较大的地方可以使用原型模式 单例模式 单例模式：一个类创建出来的对象都是同一个 python的模块其实就是单例的，只会导入一次 使用共享同一个实例的方式创建单例模式 123456class Singleton: def __new__(cls, *args, **kwargs): if not hasattr(cls,'_instance'): _instance = super().__new__(cls,*args,**kwargs) cls._instance = _instance return cls._instance 结构型设计模式装饰器模式 无需子类化扩展对象功能 代理模式 把一个对象的操作代理到另一个对象 适配器模式 把不同对象的接口适配到同一接口 想象一下多功能充电头 当我们需要给不同对象同一接口的时候可以使用适配器模式 行为模式迭代器模式 通过统一的接口迭代对象 python内置对迭代器的使用 python里可以实现__next__ 和 __iter__实现迭代器 观察者模式 发布订阅是一种最常用的实现方式 发布订阅用于解耦逻辑 可以通过回调等方式实现，当事件发生的时候，执行相应的回调函数 什么是闭包？ 绑定外部作用域的变量的函数 即使程序离开外部作用域，如果闭包仍然可见，绑定变量不会销毁 每次运行外部函数都会重新创建闭包 闭包：引用外部自由变量的函数 自由变量：不在当前函数定义的变量 特性：自由变量和闭包函数同时存在]]></content>
      <categories>
        <category>python面试</category>
      </categories>
      <tags>
        <tag>python面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python面试流程]]></title>
    <url>%2F2019%2F04%2F16%2Fpython%E9%9D%A2%E8%AF%95%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[面试的基本了解职位分析 岗位职责（业务是否感兴趣） 职位要求（自己是否掌握，查缺补漏） 公司技术栈（公司使用到那些技术栈） 从招聘信息中我们能挖掘到什么？ 你对公司做的业务是否感兴趣 职位要求的知识技能是否掌握，面试有多大的成功几率 自己还有那些知识技能需要查缺补漏 针对准备，提高成功率 针对公司技术栈和要求编写不同的简历 表现出对职位和业务的兴趣 突出自己的技能优势，提高匹配度（技能与公司要求比较匹配） 学生重视基础 学历和成绩 大学所学计算机课程 在校项目、实习经验 社招重视项目和设计 参与过那些项目，有没有知名项目 在项目中承担的职责 有没有系统设计经验 行为面试 自我介绍 口头表达能力 沟通交流能力 HR面试 薪资待遇（锚定效应，可以提出比期望薪资稍微高的待遇） 职业规划 自我介绍、沟通交流等 初级工程师 扎实的计算机理论基础 代码规范，风格良好 能在指导下靠谱地完成业务需求 中级工程师 扎实的计算机基础和丰富的项目经验 能独立设计和完成项目需求 熟悉常用的web组件（缓存，消息队列等），具备一定的系统设计能力 软实力 具有产品意识，技术引导产品 沟通交流能力，团队协作能力 技术领导能力和影响力 简历的编写简历内容 表现个人优势，突出关键信息 基本信息（姓名 学校 学历 联系方式） 职业技能（编程语言 框架 数据库 开发工具） 关键项目敬仰（担任责任 用到了什么技术） 简历加分项 知名项目经验 技术栈比较匹配 开源项目（github、技术blog、linux、unix geek） 简历注意事项 内容精简，突出重点。不宜超过两页，可以套模板 注意格式，推荐PDF（保证跨平台打开格式一致） 信息真实，不弄虚作假，技能和技术岗位匹配，没有太多无关内容 自我介绍 个人信息 掌握的技术，参与过的项目 应聘的岗位，表达对该岗位的看法和兴趣 不会表达怎么办？ 早准备 准备开场白讲稿，面试前多练习 找一个同伴好友模拟面试，消除紧张心理 什么是行为面试？ 根据候选人过去的行为评测其胜任能力 理论依据：行为的连贯性 人在面对相似的场景时会倾向于重复过去的行为 评判人的业务能力，沟通交流能力，语言表达能力，抗压能力 行为面试套路 提问方式：说说你曾经 说说你做过的这个项目 说说你碰到过的技术难题，你是如何解决的？有什么收获 根据start模型来描述项目 制作表格应对面试 常见问题 最后一般面试官会问：你还有什么要问我的 你千万别说没了，直接说没了表明你对岗位缺乏了解和兴趣 表现出兴趣：问问工作内容（业务） 技术栈 团队 项目等 问自己的感兴趣的一些技术问题和架构问题 注意事项 聊天是一个重要的软技能 态度真诚，力求真实，不要弄虚作假 言简意赅，突出重点，省略细枝末节 采用STAR模型让回答更有调理 讲讲你觉得最有技术含量的项目 讲一讲你做过最有难度的项目 你做了什么工作，承担的责任是什么 你遇到的困难是什么？如何解决的？]]></content>
      <categories>
        <category>python面试</category>
      </categories>
      <tags>
        <tag>python面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python语言基础]]></title>
    <url>%2F2019%2F04%2F16%2Fpython%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[python是一个解释强类型语言 python的优缺点 胶水语言，轮子多，应用广泛 语言灵活，生产力高 性能问题，代码维护问题，python2、3兼容问题 什么是鸭子类型 关注点是对象的行为，而不是类型（duck typing） 什么是monkey patch 所谓的monkey patch 就是运行时替换 比如gevent库需要修改socket from gevent import monkey;monkey.patch_select() 什么是自省？ 使用id，type，isinstance() 判断一个对象的类型 python2与python3相关问题python2与3的差异 print 在2里面是一个关键字，在3中是一个函数 编码问题： python3中没有unicode对象，默认str就是unicode，python2有两种 一种是str（byte）和unicode 除法问题： python3除号返回浮点数 python3的改进 类型注解（type hint） 帮助IDE实现类型检查 优化的super（）方便直接调用父类函数 python2 super(A,self)：python2需要2个参数 python3 super() : 可以直接调用 高级解包操作 a，b，*c = range(10） 限定关键字参数 def he(a,b,*,c):return a,b,c python3 重新跑出异常不会丢失栈信息 一切返回迭代器 range zip map dict.values etc.are all, iterators python3新增特性 yield from 链接子生成器 asyncio内置库，async/await 原生协程支持异步编程 新的内置库：enum，mock，asyncio，ipaddress，concurrent.futures等 python3改进 生成的pyc文件统一放到pycache 一些内置库的修改，urllib，selector等 兼容2/3的工具 six模块 2to3等工具转换代码 __future__ python函数常考题python的参数传递 python的参数传递方式，既不是引用传递也不是值传递，他是对象引用传递 python如何传递参数 一个混淆的问题 传递值还是引用呢，都不是，唯一支持的参数传递是共享传参 共享传参：函数形参获得实参中各个引用的副本 python的可变和不可变对象 不可变对象： bool，int，float，tuple，str，frozenset 可变对象 list、set、dict 默认参数只计算一次 *args 和 **kwargs是什么 用来处理可变参数 *args 被打包成tuple **kwargs 被打包成dict python的异常什么时候需要捕获处理异常，看python内置异常的类型 网络请求（超时，链接错误等） 资源访问（权限问题，资源不存在） 代码逻辑（越界访问，keyError等） 如何自定义自己的异常，为什么需要定义自己的异常 继承Exception实现自定义异常（） 给异常加上一些附加信息 处理一些业务相关的特定异常（raise MyException） python性能分析与优化，GIL常见考题GIL锁带来的缺点？ 限制了程序的多核执行 同一个时间只能有一个线程执行字节码 CPU密集程序难以利用多核优势 IO期间会释放GIL，对IO密集程序影响不大 如何规避GIL影响 区分CPU和IO密集程序 CPU密集可以使用多进程+进程池 IO密集使用多线程、协程 cython扩展 为什么有了GIL还要关注线程安全 python中什么操作才是原子的，一步到位执行完的 一个操作如果是一个字节码指令可以完成的，这就是原子的 原子操作是可以保证线程安全的 使用dis操作来分析字节码 如何剖析程序性能 使用各种profile工具（内置或第三方） 二八定律，大部分时间好事在少量代码之上 内置的profile、cprofile等工具 使用pyflame（uber开源）的火焰图工具 服务端性能优化措施 web应用一般语言不会成为瓶颈 数据结构与算法优化 数据库层：索引优化，慢查询消除，批量操作减少IO，NoSql 网络IO：批量操作，pipline操作 减少IO 缓存：使用内存数据库redis、memcached 异步： asyncio，celery 并发：gevent、多线程 什么是生成器 生成器就是可以生成值的函数 当一个函数里有了yield关键字就成了生成器 生成器可以挂起来执行并且保持当前执行的状态 基于生成器的协程 python3之前没有原生的协程，只有基于生成器的协程 生成器可以通过yield暂停执行和产出数据 同时支持send（）向生成器发送数据和throw（）向生成器抛出异常 协成的注意点 协成需要使用send（None）或者next（coroutine）来预激才能启动 在yield处协成会暂停执行 单独的yield value会产出值给调用方 可以通过coroutine.send（value） 来给协成发送值，发送的值或赋值给yield表达式左边的值 协程执行完成后没有遇到下一个yield语句会抛出Stoplteration python3.5引入async、await支持原生协成（native coroutine） python 单元测试unit Testing 针对程序模块进行正确性检验 一个函数，一个类进行验证 自底向上保证程序的正确性 三无代码不可取（无文档，无注释，无单测） 保证代码逻辑的正确性，（甚至有些采用测试驱动开发（TDD）） 单测影响设计，易测的代码往往是高内聚低耦合的 回归测试，防止改一处整个服务不可用 单元测试相关库 nose/pytest 较为常用 mock 模块用来模拟网络请求等 coverage 统计测试覆盖率 ​]]></content>
      <categories>
        <category>python面试</category>
      </categories>
      <tags>
        <tag>python面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nlp自然语言处理]]></title>
    <url>%2F2019%2F04%2F08%2Fnlp%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[k8s的基本使用]]></title>
    <url>%2F2019%2F04%2F04%2Fk8s%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[下载： 1234567docker pull mysql:5.6sudo docker run -p 3307:3306 --name mysql -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.6镜像（image） 容器（container） 仓库（registry） k8s的介绍 基于容器技术的分布式架构领先方案，他是google严格保密十几年的秘密武器，-Borg的一个开源方案 Kubernetes是Google开源的一个容器编排引擎，它支持自动化部署，大规模可伸缩，应用容器化管理 k8s能做什么 容器的自动化复制和部署，随时扩展或收缩容器规模，并提供负载均衡 方便的容器升级 提供容器弹性，如果失效就替换它 k8s对于测试能做什么 测试服务器的集中化，自动化管理。将各种平台的服务器加入集群，按需部署或销毁 持续集成时方便地自动部署 k8s基本概念 Master是主服务器，node是用于部署应用容器的服务器 Pod基本操作单元，也是应用运行的载体，整个Kubernetes系统都是围绕着Pod展开的，比如如何部署运行Pod，如何保证Pod的数量，如何访问Pod等 Deployment定义了Pod部署的信息 若干个Pod副本组成一个service，对外提供服务 副本是指一个Pod的多个实例 Namespace用于多租户的资源隔离，在测试环境中可以根据namespace划分成多套测试环境。默认有2个Namespace：kube-system/default K8s调度过程 kubernetes Client将请求发送给API server API server根据请求的类型，将处理的结果存入高可用键值存储系统Etcd中 Schedule将未分发的Pod绑定（bind）到可用的Node节点上，存到etcd中 Controller Manager根据etcd中的信息，调用node的kubelet创建Pod Controller Manager监控Pod的运行状况并确保运行正常 k8s安装前的准备 准备科学上网，在主机上安装shadowsocks，并配好服务器（服务器地址、密码需要自己想办法） k8s安装说明 2台主机都要安装docker 2台主机都要安装kubeadm、kubelet和kubectl 2台主机都要禁用虚拟内存（swapoff -a） k8s安装以及配置安装kubeadm，kubelet和kubectl 1sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https curl 设置代理 12# linux设置代理export http_proxy=0.0.0.1:1233 &amp;&amp; export https_proxy=0.0.0.0:1233 k8s基本使用]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
      <tags>
        <tag>运维开发之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow初接触]]></title>
    <url>%2F2019%2F03%2F23%2FTensorflow%E5%88%9D%E6%8E%A5%E8%A7%A6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[爬虫基础]]></title>
    <url>%2F2019%2F03%2F16%2F%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[爬虫的基本原理什么是爬虫 请求网站并提取数据的自动化程序 URL:统一资源定位符 能抓怎样的数据 网页文本 图片,音频,视频 705写入成功 怎么解析 1.直接处理 2.json解析 3.正则表达式 4.bs4 5.pyQuery 6.xpath 怎么解决javascript渲染的问题的? 1.分析ajax请求 2.使用selenium/webDriver 3.splash 4.pyv8或Ghost.py 怎么保存数据 文本型 关系型数据库 非关系型数据库 二进制文件 urllib库详解什么是urllib（python内置的http库） Urllib.request() 请求模块 urllib.error 异常处理模块 urllib.parse url解析模块 urllib.robotparser robots.txt 解析模块 基本用法GET请求（例子）123import urllib.requestres = urllib.request.urlopen('http://www.baidu.com')print(res.read().decode()) POST请求（例子）12345import urllib.parseimport urllib.requestdata = bytes(urllib.parse.urlencode(&#123;'name':'hello'&#125;),encoding='utf-8')res = urllib.request.urlopen('http://httpbin.org/post',data=data)print(res.read().decode()) 获取数据并自动保存12from urllib import requestrequest.urlretrieve(url='地址',filename='文件名') 设置超时时间正常123import urllib.requestres = urllib.request.urlopen('http://httpbin.org/get',timeout=1)print(res.read()) 报错12345678import socketimport urllib.requestimport urllib.errortry: res = urllib.request.urlopen('http://httpbin.org/get',timeout=0.1)except urllib.error.URLError as e: if isinstance(e.reason,socket.timeout): print('time out') 请求1234567891011121314151617181920212223import urllib.requestrequest = urllib.request.Request('http://www.baidu.com') # 生成一个对象res = urllib.request.urlopen(request)print(res)# 增加参数和使用post请求from urllib import request,parseurl = 'http://www.httpbin.org/post'headers = &#123; 'User-Agent':'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36', 'Host':'httpbin.org'&#125;dic = &#123; 'name':'Germey'&#125;data = bytes(parse.urlencode(dic),encoding='utf8')req = request.Request(url=url,data=data,headers=headers,method='POST')res = request.urlopen(req)print(res)# header也可以使用这样req.add_header('User-Agent','Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',) 响应12345678# 响应类型:&lt;class 'http.client.HTTPResponse'&gt;# 状态码和响应头import urllib.requestres = urllib.request.urlopen('http://www.baidu.com')print(res.status) # 状态码print(res.getheaders()) # 全部响应头print(res.getheader('Server'))print(res.read().decode('utf-8')) # 获取响应体内容 代理12345678from urllib import requestproxy_header = request.ProxyHandler(&#123; 'http':'http://127.0.0.1:8899', 'https':'https://127.0.0.1:8899',&#125;)opener = request.build_opener(proxy_header)res = opener.open('http://www.baidu.com')print(res.read()) 异常处理123456from urllib import request,errortry: res = request.urlopen('http://www.baidu.top/11') print(res.read())except error.URLError as e: print(e.reason) 12345678910from urllib import request,errortry: res = request.urlopen('http://www.baidu222.top/11') print(res.read())except error.HTTPError as e: print(e.reason,e.code,e.headers)except error.URLError as e: print(e.reason)else: print('xxxx') url解析协议类型:scheme=’http/https’ allow_fragments:#号后的内容存放在哪里 urlunparse:将内容上面返回的内容进行拼接的 urljoin:对两个url进行拼接,以后面的url为标准,有就覆盖,没有就用前面的 import urllib.robotparser :查看那些路径是可以访问的,那些事不可以访问的 re模块的基本使用常见的使用方法 re.S:匹配换行符 re.match(正则,带匹配的字符串):尝试从起始位置匹配一个模式,没有返回None group:匹配结果 span:匹配的位置 re.search :匹配所有能匹配到的,并返回第一个 re.sub(正则,要替换的字符串,’字符串’) : re.findall(正则,字符串) re.compile():将正则字符串,编译成一个正则对象 bs4的基本使用方法lxml的使用方法1234567from lxml import etreeheaders = &#123; 'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36', 'Connection':'close'&#125;lxml_obj = etree.HTML(html)url_list = lxml_obj.xpath('//div[@id="container"]/div') BeautifulSoup的使用方法12345from bs4 import BeautifulSouphtml = "&lt;html&gt;&lt;title class='xxx'&gt;111111&lt;/title&gt; "soup = BeautifulSoup(html,'lxml')print(soup.prettify()) #自动补全代码print(soup.title.string)#获取title标签的代码 标签选择器获取名称1print(soup.title.name) 获取属性12print(soup.p.attrs['name'])print(soup.p['name']) 获取内容1print(soup.p.string) 嵌套选择1print(soup.head.title.string) 子节点和子孙节点123print(soup.body.contents) # 返回一个列表print(soup.body.children) # 放回一个迭代器soup.body.descendants # 所有的子孙节点,也是一个迭代器 父节点和祖先节点12print(soup.a.parent) # 父节点,只有一个soup.a.parents # 祖先节点 兄弟节点12print(list(soup.p.next_siblings))print(list(soup.p.previous_siblings)) 标准选择器根据标签1print(soup.find_all('ul')) 根据属性123print(soup.find_all(attrs=&#123;'id':'list_1'&#125;))print(soup.find_all(id='list_1'))print(soup.find_all(class_='p1')) 根据文本1print(soup.find_all(text=[777,666,888])) 返回单个元素1234print(soup.find_parent('title')) :返回父节点print(soup.find_parents('title')):返回祖先节点print(soup.find_next_siblings('p')) :返回兄弟节点print(soup.find_next_sibling('p'))返回兄弟节点 css选择器12print(soup.select('.p1 .a1'))print(soup.select('#list_1 .a1')) 获取属性1ul["id"] 获取内容123for i in soup.select('#list_1 .a1'): print(i.get_text()) print(i.text) pyquery库的使用基本使用123from pyquery import PyQuery as pydoc = py(url='http://www.baidu.com') # 从url中获取数据doc = py(filename='demo.html') # 从文件中获取 查找元素子元素所有的123doc = py(html)item = doc('#list_1')print(item.find('a')) 直接的123doc = py(html)item = doc('#list_1')print(item.children()) 子元素筛选12item = doc('#list_1')print(item.children('.a1')) 父元素123456item = doc('#list_1')print(item.parent()) # 获取父元素print(item.parents()) # 获取祖先元素# 对父节点进行筛选item = doc('#list_1')print(item.parent('.r1')) 兄弟元素12345item = doc('#list_1')print(item.siblings()) # 兄弟元素item = doc('#list_1')print(item.siblings('.a1')) # 对兄弟元素进行筛选 遍历单个元素12item = doc('#list_1')print(item) 返回迭代器12item = doc('#list_1').items()print(item) 获取信息获取属性123item = doc('#list_1 a')print(item.attr('href'))print(item.attr.href) 获取文本1item = doc('#list_1 a') print(item.text()) 获取html1item = doc('#list_1') print(item.html()) DOM操作addClass和removeClass123item = doc('#list_1')print(item.remove_class('p1')) :删除p1print(item.add_class('p1')):添加p1 attr 和 css123item = doc('#list_1')print(item.attr('name','link'))print(item.css('font_size','14px')) remove:把中间a标签全部删除1234item = doc('#list_1')print(item.text())print(item.find('a').remove())print(item.text()) 伪类选择器1234567doc = py(html) print(doc('p:first-child')) # 获取第一个print(doc('p:last-child'))# 获取最后一个print(doc('p:nth-child(2)'))# 获取第二个print(doc('p:gt(1)')) # 获取比1大的所有元素print(doc('p:nth-child(2n)')) # 获取偶数的print(doc('p:contains(xxx)')) #查看包含xxx文本的所有内容 requests库的基本使用实例123456import requestsres = requests.get('http://www.baidu.com')print(type(res)) # 获取一个对象print(res.status_code) # 获取状态码print(type(res.text)) # 获取页面print(type(res.cookies)) # 获取cookie 所有请求方式 requests.get() requests.post() requests.put() requests.patch() requests.options() requests.head() requests.delete() 获取数据 res.json() :获取json数据 res.text:获取文本信息 res.content :获取二进制数据 响应 status_code :获取状态码 text:获取文本信息 headers:获取头部信息 content:获取二进制数据 cookies:获取cookie url:访问的url history:历史记录 高级操作文件上传123import requestsfiles = &#123;'file':open('11.jpg','rb')&#125;requests.post('url',files=files) 获取cookie1234res.cookies.item()&#123; 111:222&#125; 会话维持12345import requestssession = requests.session()session.get('http://httpbin.org/cookies/set/number/1000000')res = session.get('http://httpbin.org/cookies')print(res.text) 代理设置12345import requestsproxies = &#123; 'http':'http://127.0.0.1:5000'&#125;res = requests.get('http://www.baidu.com',proxies=proxies) 超时设置1234567from requests.exceptions import ReadTimeoutimport requeststry: res = requests.get('http://www.baidu.com',timeout=0.01) print(res.text)except ReadTimeout: print(111) 认证设置1res = requests.get('http://www.baidu.com',auth=&#123;'user':123&#125;) 异常处理12345from requests.exceptions import ReadTimeout, HTTPError,RequestExceptionReadTimeout:超时HTTPError:ConnectionError:网络不通RequestException selenium的基本使用基本使用12345678910111213141516171819from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.common.keys import Keysfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.support.wait import WebDriverWaitbrowser = webdriver.Chrome()try: browser.get('http://www.baidu.com') input = browser.find_element_by_id('kw') input.send_keys('Python') input.send_keys(Keys.ENTER) wait = WebDriverWait(browser,10) wait.until(EC.presence_of_all_elements_located((By.ID,'content_left'))) print(browser.current_url) print(browser.get_cookies()) print(browser.page_source)finally: browser.close() 声明浏览器对象123456from selenium import webdriver browser = webdriver.Chrome() # chrome浏览器browser = webdriver.Firefox()browser = webdriver.Edge()browser = webdriver.PhantomJS()browser = webdriver.Safari() 访问页面12345from selenium import webdriverbrowser = webdriver.Chrome()browser.get('http://www.taobao.com')print(browser.page_source)browser.close() 查找元素单个元素第一种123456789from selenium import webdriverbrowser = webdriver.Chrome()browser.get('http://www.taobao.com')input_first = browser.find_element_by_id('q')input_second = browser.find_element_by_css_selector('#q')input_third = browser.find_element_by_xpath('//*[@id="q"]')print(input_first,input_second,input_third)browser.close() 第二种1234567from selenium import webdriverfrom selenium.webdriver.common.by import Bybrowser = webdriver.Chrome()browser.get('http://www.taobao.com')input_first = browser.find_element(By.ID,'q')print(input_first)browser.close() 多个元素第一种1234567from selenium import webdriverbrowser = webdriver.Chrome()browser.get('http://www.taobao.com')lis = browser.find_elements_by_css_selector('.service-bd li')print(lis)browser.close() 第二种1234567from selenium import webdriverfrom selenium.webdriver.common.by import Bybrowser = webdriver.Chrome()browser.get('http://www.taobao.com')lis = browser.find_elements(By.CSS_SELECTOR,'.service-bd li')print(lis)browser.close() 元素交互操作12345678910111213141516import timefrom selenium import webdriverfrom selenium.webdriver.common.by import Bybrowser = webdriver.Chrome()browser.get('http://www.taobao.com')input = browser.find_element_by_id('q')input.send_keys('Iphone')time.sleep(1)input.clear()input.send_keys('iPad')button = browser.find_element_by_class_name('btn-search')button.click()browser.close() 交互动作1234567891011121314from selenium import webdriverfrom selenium.webdriver import ActionChainsbrowser = webdriver.Chrome()url = 'http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'browser.get(url)browser.switch_to.frame('iframeResult')source= browser.find_element_by_css_selector('#draggable') # 拖拽对象target= browser.find_element_by_css_selector('#droppable') # 拖拽目标actions = ActionChains(browser)actions.drag_and_drop(source,target)actions.perform()browser.close() 执行js123456from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')browser.execute_script('window.scrollTo(0,document.body.scrollHeight)') # 把下拉到最下面browser.execute_script('alert("to bottom")')browser.close() 获取元素信息获取属性1234567from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')logo = browser.find_element_by_id('zh-top-link-logo')print(logo)print(logo.get_attribute('class')) # 获取classbrowser.close() 获取文本值123456from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')input = browser.find_element_by_css_selector('.zh-summary')print(input.text)browser.close() 获取id，位置，标签名，大小123456789from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')input = browser.find_element_by_class_name('zh-summary')print(input.id)print(input.location)print(input.tag_name)print(input.size)browser.close() Frame:进去和出来123456789101112131415161718import timefrom selenium import webdriverfrom selenium.common.exceptions import NoSuchElementExceptionbrowser = webdriver.Chrome()url = 'http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'browser.get(url)browser.switch_to.frame('iframeResult') # 进入里面iframesource = browser.find_element_by_css_selector('#draggable') # 拖拽对象print(source)try: logo = browser.find_element_by_class_name('logo')except NoSuchElementException: print('No Logo')browser.switch_to.parent_frame() # 出来iframelogo = browser.find_element_by_class_name('logo')print(logo)print(logo.text) 等待隐式等待1234567from selenium import webdriverbrowser = webdriver.Chrome()browser.implicitly_wait(10)browser.get('https://www.zhihu.com/explore')input = browser.find_element_by_class_name('zu-top-add-question')print(input)browser.close() 显示等待123456789101112from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECbrowser = webdriver.Chrome()browser.get('https://www.taobao.com/')wait = WebDriverWait(browser,10)input = wait.until(EC.presence_of_all_elements_located((By.ID,'q')))button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR,'.btn-search')))print(input,button)browser.close() 前进和后退1234567891011from selenium import webdriverimport timebrowser = webdriver.Chrome()browser.get('https://www.baidu.com/')browser.get('http://www.taobao.com/')browser.get('http://www.python.org/')browser.back() # 后退一步time.sleep(1)browser.forward() # 前进一步browser.close() 设置cookie12345678from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')print(browser.get_cookies())browser.add_cookie(&#123;'name':'name','domain':'www.zhihu.com','value':'germey'&#125;)print(browser.get_cookies())browser.delete_all_cookies()print(browser.get_cookies()) 选项卡设置123456789101112import timefrom selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.baidu.com')browser.execute_script('window.open()') # 打开一个新的标签print(browser.window_handles)browser.switch_to_window(browser.window_handles[1]) # 切换标签browser.get('https://www.taobao.com')time.sleep(1)browser.switch_to_window(browser.window_handles[0])browser.get('https://python.org') 异常处理12345678910111213from selenium import webdriverfrom selenium.common.exceptions import TimeoutException, NoSuchElementExceptionbrowser = webdriver.Chrome()try: browser.get('https://www.baidu.com')except TimeoutException: print('请求超时')try: browser.find_element_by_id('hello')except NoSuchElementException: print('没有此id')finally: browser.close()]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy笔记]]></title>
    <url>%2F2019%2F03%2F05%2Fscrapy%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法练习]]></title>
    <url>%2F2019%2F02%2F26%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[如何精通一个领域 切碎知识点 刻意练习 练习缺陷，弱点地方 感觉不舒服，不爽，枯燥 反馈 基本常用的数据结构 时间和空间复杂度 描述 O（1） 常数复杂度 O（log n） 对数复杂度 O(n) 线性时间复杂度 O(n^2) 平方 O(n^3) 立方 O(2^n) 指数 O(n!) 阶乘 数组和链表的数据结构 数组：内存里一段连续的存储区域 查询的时间复杂度：O(1) 插入的时间复杂度：O(n) 删除的时间复杂度：O(n) 链表：分为单链表和双链表 查询的时间复杂度：O(n) 插入的时间复杂度：O(1) 删除的时间复杂度：O(1) 相关案例206.翻转链表 1234567891011class ListNode: def __init__(self, x): self.val = x self.next = Noneclass Solution: def reverseList(self, head: ListNode) -&gt; ListNode: cur, prev = head , None while cur: cur.next,prev,cur = prev,cur,cur.next return prev 24：交换链表相邻的两个元素 123456789class Solution: def swapPairs(self, head: ListNode) -&gt; ListNode: pre,pre.next = self,head while pre.next and pre.next.next: a = pre.next b = a.next pre.next, b.next, a.next = b,a,b.next pre = a return self.next 141.环形链表 1234567891011121314# 解题思路:根据快慢指针来判断这个链表中是否有环形的存在class Solution(object): def hasCycle(self, head): """ :type head: ListNode :rtype: bool """ fast = slow = head while slow and fast and fast.next: slow = slow.next fast = fast.next.next if slow is fast: return True return False 堆栈和队列栈：先入后出队列：先进先出 相关案例20.判断括号是否合法 12345678910class Solution: def isValid(self, s: str) -&gt; bool: stack = [] paren_map = &#123;')':"(","]":"[","&#125;":"&#123;"&#125; for c in s: if c not in paren_map: stack.append(c) elif not stack or paren_map[c] != stack.pop(): return False return not stack 232.用栈来实现队列 225.用队列事现栈 优先队列实现机制： 使用堆(heap)来实现 使用二叉搜索树 相关案例703.实时判断数据流中k大的元素 239.滑动窗口最大值 映射(map) 和 集合（set）如何解决哈希碰撞？ 拉链法 开放寻址法 ​ hashMap vs TreeMap hashSet vs TreeSetpython中使用的是hashmap和hashset 相关案例242.有效的异位字符 12345678class Solution: def isAnagram(self, s: str, t: str) -&gt; bool: dic1,dic2 = &#123;&#125;,&#123;&#125; for item in s: dic1[item] = dic1.get(item,0)+1 for item in t: dic2[item] = dic2.get(item,0)+1 return dic1 == dic2 1.两数之和 1234567class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: hash_map = dict() for i,x in enumerate(nums): if target - x in hash_map: return [hash_map[target - x],i] hash_map[x] = i 15.三数之和 1234567891011121314151617181920class Solution: def threeSum(self, nums: List[int]) -&gt; List[List[int]]: res = [] nums.sort() for i in range(len(nums)-2): if i &gt; 0 and nums[i] == nums[i-1]: continue l, r = i+1, len(nums)-1 while l &lt; r: s = nums[i] + nums[l] + nums[r] if s &lt; 0 :l +=1 elif s &gt; 0:r -= 1 else: res.append((nums[i],nums[l],nums[r])) while l &lt; r and nums[l] == nums[l+1]: l += 1 while l &lt; r and nums[r] == nums[r-1]: r -= 1 l +=1;r -= 1 return list(map(list,res)) 18.四数之和 树&amp;二叉树&amp;二叉搜索树链表就是特殊化的Tree Tree就是特殊化的图 实现二叉树 123456# pythonclass TreeNode(object): def __init__(self, x): self.val = x self.left = None self.right = None 二叉搜索树二叉搜索树,也成为二叉搜索树,有序二叉树,排序二叉树,是指一颗空树或者具有下列性质的二叉树 左子树上所有节点的值均小于它的根节点的值 右子树上所有的值均大于它的根节点的值 左右子树也分别为二叉查找树 相关案例98.验证二叉搜索树 1234567891011121314151617181920212223242526272829303132333435# 低效法class Solution(object): def isValidBST(self, root): """ :type root: TreeNode :rtype: bool """ inorder = self.inorder(root) return inorder == list(sorted(set(inorder))) def inorder(self,root): if root is None: return [] return self.inorder(root.left) + [root.val] + self.inorder(root.right) # 中序遍历class Solution(object): def isValidBST(self, root): """ :type root: TreeNode :rtype: bool """ self.prev = None return self.helper(root) def helper(self,root): if root is None: return True if not self.helper(root.left): return False if self.prev and self.prev.val &gt;= root.val: return False self.prev = root return self.helper(root.right) 235.. 二叉搜索树的最近公共祖先 12345678910111213class Solution(object): def lowestCommonAncestor(self, root, p, q): """ :type root: TreeNode :type p: TreeNode :type q: TreeNode :rtype: TreeNode """ if p.val &lt; root.val &gt; q.val: return self.lowestCommonAncestor(root.left,p,q) if p.val &gt; root.val &lt; q.val: return self.lowestCommonAncestor(root.right,p,q) return root 236. 二叉树的最近公共祖先 1234567891011121314151617class Solution(object): def lowestCommonAncestor(self, root, p, q): """ :type root: TreeNode :type p: TreeNode :type q: TreeNode :rtype: TreeNode """ if root == None or root == p or root == q:return root left = self.lowestCommonAncestor(root.left,p,q) right = self.lowestCommonAncestor(root.right,p,q) if left == None: return right elif right == None: return left else: return root 二叉树的遍历前序遍历(Pre-order):根-左-右 中序遍历(in-order):左-根-右 后序遍历(Post-order):左-右-根 递归和分治相关例题50. Pow(x, n) 12345678910111213141516171819202122232425262728293031323334# 递归法class Solution(object): def myPow(self, x, n): """ :type x: float :type n: int :rtype: float """ if not n: return 1 if n &lt; 0: return 1/self.myPow(x,-n) if n % 2 : return x * self.myPow(x,n-1) return self.myPow(x*x,n/2) # 非递归方式class Solution(object): def myPow(self, x, n): """ :type x: float :type n: int :rtype: float """ if n &lt; 0: x = 1/x n = -n pow = 1 while n: if n &amp; 1: pow *= x x *=x n &gt;&gt;=1 return pow 169. 求众数 12 贪心法适用贪心法的场景 简单来说,问题能够分解成子问题来解决,子问题的最优解能递推到最终问题的最优解,这种子问题最优解成为最优子结构 贪心算法与动态规划的不同在于对每个子问题的解决方案都作出选择,不能回退,动态规划则会保存以前的运行结果,并根据以前的结果对当前进行选择,有回退的功能 相关案例122.买卖股票的最佳时机 II 广度优先搜索深度优先搜索102.二叉树的层次遍历 12 104.二叉树的最大深度 111.二叉树的最小深度 22. 括号生成 123456789101112131415class Solution: def generateParenthesis(self, n: int): self.list = [] self._gen(0, 0, n, "") return self.list def _gen(self, left, right, n, result): if left == n and right == n: self.list.append(result) return if left &lt; n: self._gen(left + 1, right, n, result + "(") if left &gt; right and right &lt; n: self._gen(left, right + 1, n, result + ")") 剪枝把较差的枝叶剪掉 相关案例51.N皇后 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Solution: def solveNQueens(self, n: int): if n &lt; 1: return [] self.result = [] self.cols = set() self.pie = set() self.na = set() self.DFS(n, 0, []) return self._generate_result(n) def DFS(self, n, row, cur_state): if row &gt;= n: self.result.append(cur_state) return for col in range(n): if col in self.cols or row + col in self.pie or row - col in self.na: continue self.cols.add(col) self.pie.add(row + col) self.na.add(row - col) self.DFS(n, row + 1, cur_state + [col]) self.cols.remove(col) self.pie.remove(row + col) self.na.remove(row - col) def _generate_result(self, n): board = [] for res in self.result: for i in res: board.append('.' * i + "Q" + '.' * (n - i - 1)) return [board[i:i + n] for i in range(0, len(board), n)]def solveNQueens( n: int): def DFS(queens, xy_dif, xy_sum): p = len(queens) if p == n: result.append(queens) return None for q in range(n): if q not in queens and p - q not in xy_dif and p + q not in xy_sum: DFS(queens + [q], xy_dif + [p - q], xy_sum + [p + q]) result = [] DFS([], [], []) return [['.' * i + 'Q' + '.' * (n - i - 1) for i in sol] for sol in result] 52 36/37 数读 12 二分查找12 实战例题69.x 的平方根 123456class Solution(object): def mySqrt(self,x): r = x while r * r &gt; x: r = (r + x/r)/2 return r 字典树 Trie树的数据结构 Trie树，即字典树，又称单词查找树或键树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计和排序大量的字符串（但不仅限于字符串），所以经常被搜索引擎用于文本词频统计 。它的优点是最大限度的减少无所谓的字符串比较，查询效率比哈希表高 Trie树的核心思想 Trie的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的 Trie树的基本性质 根节点不包含字符，除根节点之外每个节点只包含一个字符 从根节点到某一节点，路径经过的字符串连接起来，为该节点对应的字符串 每个节点所有子节点包含的字符都不相同 实战例题208 实现 Trie (前缀树) 1234567891011121314151617181920212223242526class Trie(object): def __init__(self): self.root = &#123;&#125; self.end_of_word = "#" def insert(self, word): node = self.root for char in word: node = node.setdefault(char, &#123;&#125;) node[self.end_of_word] = self.end_of_word def search(self, word): node = self.root for char in word: if char not in node: return False node = node[char] return self.end_of_word in node def startWith(self, prefix): node = self.root for char in prefix: if char not in node: return False node = node[char] return True 79. 单词搜索 123456789101112131415161718192021222324252627282930313233343536373839404142import collectionsdx = [-1, 1, 0, 0]dy = [0, 0, -1, 1]END_OF_WORD = "#"class Solution(object): def findWords(self, board, words): if not board or not board[0]: return [] if not words: return [] self.result = set() # 用于装载最后的结果 # 将word全部插入字典树中 root = collections.defaultdict() for word in words: node = root for char in word: node = node.setdefault(char, collections.defaultdict()) node[END_OF_WORD] = END_OF_WORD self.m, self.n = len(board), len(board[0]) for i in range(self.m): for j in range(self.n): if board[i][j] in root: self._dfs(board, i, j, "", root) def _dfs(self, board, i, j, cur_word, cur_dict): cur_word += board[i][j] cur_dict = cur_dict[board[i][j]] if END_OF_WORD in cur_dict: self.result.add(cur_word) tmp, board[i][j] = board[i][j], "@" for k in range(4): x, y = i + dx[k], j + dy[k] if 0 &lt;= x &lt; self.m and 0 &lt;= y &lt; self.n and board[x][y] != "@" and board[x][y] in cur_dict: self._dfs(board, x, y, cur_word, cur_dict) board[i][j] = tmp 位运算 位运算介绍 计算机中的内存是以二进制的形式存储的，位运算说白了，就是直接对整数在内存中的二进制位进行操作 位运算常用操作 | 符号 | 描述 | 运算规则 | | —- | —- | ———————————————————— | | &amp; | 与 | 两个都为1时，才为1 | | | | 或 | 两个都为0时，才为0 | | ^ | 异或 | 两个相同为0，相异为1 | | - | 取反 | 0变1,1变0 | | &lt;&lt; | 左移 | 各二进制位全部左移若干位，高位丢弃，低位补0 | | &gt;&gt; | 右移 | 各二进制位全部右移若干位，对无符号数，高位补0，有符号数，各编译器处理方法不一样，有的补符号位（算数右移），有的补0（符号右移） | 位运算的应用 1234567891011x &amp; 1 == 1 OR == 0 判断奇偶（x%2==1）x = X&amp;(X-1)=&gt; 清零最低位的1x &amp; -x =&gt; 得到最低位的11.将x 最右边的n位清零 - x &amp; （~0 &lt;&lt; n）2.获取x的第n位值（0或1）-（x &gt;&gt; n） &amp; 13.获取x的第n位的幂值 - x &amp; （1 &lt;&lt; (n-1)）4.仅将第n位值为1 - x | （1 &lt;&lt; n）5.仅将第n位置为0 - x &amp; （~（1 &lt;&lt; n））6.将x最高位至第n位（含）清零 - x &amp; （（1 &lt;&lt; n）-1）7.将第n为至第0位（含） 清零 - x &amp;（~（（1 &lt;&lt; (n+1)）-1）） 实战例题191.位1的个数 123456789101112def hammingWeight(self, n): """ :type n: int :rtype: int """ rst = 0 mask = 1 for i in range(32): if n&amp;mask: rst += 1 mask = mask &lt;&lt; 1 return rst 231. 2的幂 12def isPowerOfTwo(n): return n &gt; 0 and not(n &amp; n-1) 338.比特位计数 52. N皇后 II 123456789101112131415def totalNQueens(self,n): if n &lt; 1:return [] self.count = 0 self.DFS(n,0,0,0,0) return self.countdef DFS(self,n,row,cols,pie,na): if row &gt;= n: self.count += 1 return bits = (~(cols | pie | na)) &amp; ((1 &lt;&lt; n)-1) # 得到当前所有空位 while bits: p = bits &amp; -bits # 取到最低位1 self.DFS(n,row+1,cols | p,(pie | p) &lt;&lt; 1,(na | p) &gt;&gt; 1) bits = bits &amp; (bits - 1) # 去掉最低位的1 动态规划1.递归 + 记忆化 – 》 递推 2.状态的定义 ： opt[n],dp[n],fib[n] 3.状态转移方程：opt[n] = best_of(opt[n-1],opt[n-2]) 4.最优子结构 12递推公式F[n] =F[n-1] + F[n-2]]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python自动化运维]]></title>
    <url>%2F2019%2F02%2F18%2Fpython%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4%2F</url>
    <content type="text"><![CDATA[自动化运维工具部署类：jenkins 环境类：ansible 监控类：ngios ansible的使用 自动化 管理 IT资源 的工具 功能 系统环境配置 安装软件 持续集成 热回滚 优点 无客户端 推送式 丰富的module 基于YAML的playbook 商业化支持 缺点 效率低，易挂起 并发性差 Ansible配置详解123456defaults 默认配置项privilege_escalation 执行命令的用户权限设置paramiko_connection paramika 插件设置ssh_connection ssh 连接设置accelerateselinux &amp; colors 1234ask_pass &amp; ask_sudo_passask_pass :可以控制Ansible剧本playbook是否会自动默认弹出默认密码ask_sudo_pass:用户使用的系统平台开启了sudo密码的话，应该开绿这一个参数 123gather_subset设置收集的内容：包括all，network，hardware，virtual，facter，ohai 123remote_port &amp; remote_tmp &amp; remote_user客户机设置，分别对登录的用户和端口，以及临时目录 123sudo_exe &amp; sudo_flags &amp; sudo_usersudo命令相关设置，分别是sudo命令路径，sudo参数，能够使用sudo的user 123action_plugins &amp; callback_plugins &amp;connection_plugins &amp; filter_plugins &amp; lookup_plugins &amp; vars_plugins开发者中心的插件相关功能，开发者可以开发相应的插件，来完成自己的功能，分别对一个的功能为：激活事件，回调，连接。过滤器，加载路径，任何地方加载 123forks最大开辟的进程数，这个数不易过大，过大性能消费高，过小，并发性能低，一般设置方法：cpu核数*2 123module_name这个是/user/bin/ansible的默认模块名 （-m） 默认是‘command’模块，‘command’模块不支持shell变量，管道，配额，所以需要把这个参数设置为shell 123vault_password_file这个文件也可以称为一个脚本的形式，如果你使用脚本而不是单纯文件的话，请确保它可以执行并且密码可以在标准输出中打印出来，如果你的脚本需要提示请求数据，请求将会发到标准错误输出中 123pattern如果没有提供“hosts”节点，这是playbook要通信的默认主机组，默认值对所有主机通信，如果不想被惊吓到，最好还是设置个选项 123inventory &amp; library分别为存放主机目录和Ansible默认搜索模块路径 Ansible的使用如何添加一台机器？ 1.编辑/etc/ansible/hosts 2.添加本机的public SSH Key 到目标机器的authorized_keys 3.添加本机私钥到Ansible（可以省略） 运行ansible all -m ping 测试是否添加成功 Ansible命令格式-ansible all -m ping Ansible命令主题 ansible/Ansible-playbook 被操作的目标机器的正则表达式 –all 指定要使用的模块 -m ping 传入参数 1234567-a 指定传入模块的参数-C -D 两个一起使用，检查hosts规则文件的修改-l 限制匹配规则的主机数--list-hosts 显示所有匹配规则的主机数-m -M 指定所使用的模块和模块路径--syntax-check 检查语法-v 显示详细日志 12345678910111213141516ip域名写起来太长，起一个别名jumper ansible_ssh_port=5555 ansible_ssh_host=192.168.19.128不想以ROOT用户登录jumper ansible_ssh_port=5555 ansible_ssh_host=192.168.19.128 ansible_ssh_user=oooo机器太多，但是是连续的【vim】vim[1:50].xxx.comvim[a-z].xxx.com什么是patterns 是指我们通过类正则表达式的方式，决定于哪台主机进行交互如何执行一个耗时任务 ansible all -B 3600 -P 0 -a "ls" -B 3600 表示最多运行60分钟 -P 0表示不获取状态 -p 60 表示每隔1分钟获取一次状态 1234其他模块 git模块 service模块 系统服务相关 setup模块 系统环境相关 免密登录12ssh-keygen # 一直敲击回车即可ssh-copy-id ip地址 Ansible APISaltStack概念 一个配置管理系统，能够维护预定义状态的远程节点 一个分布式远程执行系统，用来在远程节点上执行命令和查询数据 特点 简单（相对Puppet） 并行执行 基于成熟技术（ZeroMQ，AES） python API 灵活，开源 服务架构 Master 负责管理所有节点 Minion 节点服务 zeroMQ 通信方式 AES 数据加密方法 缺点： 需要单独安装客户端 安全隐患大 ZerMQ简述以嵌入式网络编程库的形式实现了一个并行开发框架，能够提供进程内，进程间，网络和广播方式的消息通道，并支持 发布-》订阅 ，任务分发，请求响应等通信模式 Saltstack安装配置运行安装1234py2.6 ~ py3zeroMQ or RAETmako(可选) 一个可选的salt States解析器gcc（可选） 配置运行 运行Master节点 修改Minion节点配置，填入Master节点信息 启动Minion Master节点添加Minion 配置项]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux之网络服务]]></title>
    <url>%2F2019%2F02%2F18%2FLinux%E4%B9%8B%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Bind服务123456789101112BIND开源，稳定，应用广泛的DNS服务组成 域名解析服务 权威域名服务 DNS工具 DNS中的域名 www.baidu.com = www.baidu.com.(.代表根域。com代表一级域名，baidu代表二级域名) DNS解析记录分类 A记录，CNAME，NS记录，MX记录 123安装BINDRedhat家族：yum install bind bind-chrootUbuntu家族：sudo apt-get install bind9 1234配置文件 options&#123;&#125;整个BIND使用的全局选项 logging&#123;&#125; 服务日志选项 zone &#123;&#125; DNS域解析 Bind负载均衡智能DNS]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux之安全应用]]></title>
    <url>%2F2019%2F02%2F18%2FLinux%E4%B9%8B%E5%AE%89%E5%85%A8%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[主机扫描网络入侵方式踩点-》网络扫描-》查点-》提权 实例中运用到的命令tracert，nmap，nc 主机扫描命令 fping作用： ​ 批量的给目标主机发送ping命令，测试主机的存活情况 特点： ​ 并行发送，结果易读 fping参数介绍命令参数man、-h方式 12345678-a 只显示存活的主机（相反参数 -u）1.通过标准输入方式fping + IP1 + IP2 -g 支持主机段的方式192.168.1.1 192.168.1.255 或 192.168.1.0/24 2.通过读取一个文件中的IP内容 方式：fping -f filename 主机扫描命令hping123456789101112131415161718报错查看：https://www.cnblogs.com/fwonfo/p/7735756.html安装： 下载地址：www.hping.org依赖： yum install -y libpcap libpcap-devel ln -sf /usr/include/pcap-bpf.h /usr/include/net/bpf.h安装步骤： ./configure &amp;&amp; make &amp;&amp; make install特点：支持使用的TCP/IP数据包组装，分析工具参数： 对指定目标发起tcp探测 -p 端口 -s 设置TCP模式SYN包 伪造来源IP，模拟Ddos攻击 -a 伪造IP地址 # 屏蔽ping命令 路由扫描作用：查询一个主机到另一个主机的经过路由的跳数，及数据延迟情况 12常用工具：traceroute，mtrmtr特点：能测试出主机到每一个路由间的联通性 Traceroute参数介绍12345一。默认使用的是UDP协议（30000上的端口）二.使用TCP协议 -T -p三。使用ICMP协议 -Imtr + 域名 批量主机服务扫描目的： 批量主机存活扫描 针对主机服务扫描 作用 能更方便快捷获取网络中主机的存活状态 更加细致，智能获取主机服务侦查情况 1234567891011命令：nmap和ncatncat工具使用组合参数：-w设置的超时时间-z 一个输入输出模式-v 显示命令执行过程方式一。基于tcp协议（默认） nc -v -z -w2 39.105.162.164 1-50方式二。基于UDP协议 nc -v -u -z -w2 39.105.162.164 1-50 扫描类型 描述 特点 ICMP协议类型（-sP） ping扫描 简单，快速，有效 TCP SYN扫描（-sS） TCP半开放扫描 高效，不易被检测，通用 TCP connect 扫描（-sT） TCP全开放扫描 真实，结果可靠 UDP扫描（-sU） UDP协议扫描 有效透过防火墙策略 linux防范恶意扫描安全策略123456789101112131415161718192021常见的攻击方式： SYN攻击 DDOS攻击 恶意扫描什么是SYN攻击？ 利用TCP缺陷进行，导致系统服务停止响应，网络带宽跑满或者响应缓慢什么是DDOS攻击 分布式访问拒绝服务攻击SYN类型DDOS攻击防御方式一：减少发送syn+ack包重试次数 sysctl -w net.ip4.tcp_synack_retries=3 sysctl -w net.ip4.tcp_syn_retries=3方式二。SYN cookie技术 sysctl -w net.ipv4.tcp_syncookies=1方式三。增加backlog队列 sysctl -w net.ipv4.tcp_max_backlog=2048其他预防策略策略1.如何关闭ICMP协议请求 sysctl -w net.ipv4.icmp_echo_ignore_all=1策略2.通过iptables防止扫描 iptables的使用关于iptables什么是iptables？常见于linux系统下的应用层防火墙 常见人员系统管理人员，网络工程人员，安全人员等等]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统管理]]></title>
    <url>%2F2019%2F02%2F14%2Flinux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[进程管理进程管理简介 进程是正在执行的一个程序或命令，每一个进程都是一个运行的实体，都有自己的地址空间，并占用一定的系统资源 进程管理的作用 判断服务器健康状态 查看系统中所有进程 杀死进程 进程管理查看 -ps命令和pstree命令查看所有进程12345678910ps aux# 查看系统中所有进程，使用BSD操作格式ps -le# 查看系统中所有进程，使用Linux标准命令格式选项： -a 显示一个终端的所有进程，除了会话引线 -u 显示进程的归属用户及内存的使用情况 -x 显示没有控制终端的进程 -l 长格式显示，显示更加详细的信息 -e 显示所有进程，和-A作用一直 ps命令输出1234567891011121314151617USER 该进程由那个用户产生的PID 进程的PID号%CPU 该进程占用CPU资源的百分比，占用越高，进程越耗费资源%MEM 该进程占用物理内存的百分比，占用越高，进程越耗费资源VSZ 该进程占用虚拟内存大小，单位为kbRSS 该进程占用实际物理内存大小，单位kbTTY 该进程是在哪个终端中运行的，其中tty-tty7代表本地控制台终端，tty1-tty6是本地的字符页面终端，tty7是图像终端，pts/0-255代表虚拟机STAT 进程状态，常见状态有 R 运行 S 睡眠 T 停止状态 s 包含子进程 + 位于后台START 该进程启动时间TIME 该进程占用CPU的运算时间，注意不是系统时间COMMAND 产生此进程的命令名 pstree命令12345查看进程树pstree [选项]选项： -p 显示进程的PID -u 显示进程的所属用户 进程查看 top命令12345678910111213141516171819202122232425262728293031323334353637383940top [选项]选项： -d 秒数，指定top命令每隔几秒更新，默认3秒 -b 使用批处理模式输出，一般和“-n”选项和用 -n 次数，指定top命令执行的次数，一般和“-b”选项和用 在top命令的交互模式当中可以执行的命令命令： ？或h 显示交互模式的帮助 P 以CPU使用率排序，默认就是此项 M 以内存使用率排序 N 以PID排序 q 退出top 详细信息 第一行 (uptime) 系统时间 主机运行时间 用户连接数(who) 系统1，5，15分钟的平均负载 第二行:进程信息 进程总数 正在运行的进程数 睡眠的进程数 停止的进程数 僵尸进程数 第三行:cpu信息 1.5 us：用户空间所占CPU百分比 0.9 sy：内核空间占用CPU百分比 0.0 ni：用户进程空间内改变过优先级的进程占用CPU百分比 97.5 id：空闲CPU百分比 0.2 wa：等待输入输出的CPU时间百分比 0.0 hi：硬件CPU中断占用百分比 0.0 si：软中断占用百分比 0.0 st：虚拟机占用百分比 第四行：内存信息（与第五行的信息类似与free命令） total：物理内存总量 used：已使用的内存总量 free：空闲的内存总量（free+used=total） buffers：用作内核缓存的内存量 第五行：swap信息 total：交换分区总量 used：已使用的交换分区总量 free：空闲交换区总量 cached Mem：缓冲的交换区总量，内存中的内容被换出到交换区，然后又被换入到内存，但是使用过的交换区没有被覆盖，交换区的这些内容已存在于内存中的交换区的大小，相应的内存再次被换出时可不必再对交换区写入。 杀死进程kill命令12345kill -l# 查看可用的进程信号kill -9 2236# 强制杀死进程 killall命令12345killall [选项][信号] 进程名# 按照进程名杀死进程选项： -i 交互式，询问是否杀死某个进程 -I 忽略进程名大小写 pkill命令1234pkill [选项][信号] 进程名# 按照进程名终止进程选项： -t 终端号，按照终端号踢出用户 修改进程优先级1234567891011nice命令# nice命令可以给新执行的命令直接赋予NI值，但是不能修改已经存在进程的NI值选项： -n NI值，给命令赋予NI值例如： nice -n （-20到19） service httpd startrenice命令# renice命令是修改已经存在进程的NI值的命令例如： renice -10 2255（PID） 工作管理 当前的登录终端，只能管理当前终端的工作，而不能管理其他登录终端工作 放入后台的命令必须可以持续运行一段时间，这样我们才能捕捉和操作这个任务 放入后台执行的命令不能和前台用户有交互或需要前台输入，否则放入后台只能暂停，而不能执行 把进程放入后台12345tar -zcf etc.tar.gz /etc &amp;# 把命令放入后台，并在后台执行top# 按下ctrl + z 快捷键，放在后台暂停 查看后台的工作1234jobs [-l]选项： -l 显示工作的PID注释：“+”号代表最近一个放入后台的工作，也是工作恢复时，默认恢复的工作，“-”号代表倒数第二个放入后台的工作 将后台暂停的工作恢复到前台执行123fg %工作号参数： %工作号：%号可以省略，但是注意工作号和PID的区别 把后台暂停的工作恢复到后台执行12bg %工作号# 后台恢复执行的命令，是不能和前台有交互的，否则不能恢复到后台执行 后台命令脱离登录终端执行的方法 把需要后台执行的命令加入/etc/rc.local文件 使用系统定时任务，让系统在执行的时间执行某个后台命令 使用nohup命令 12nohup 命令 &amp;# 脱离终端执行 系统资源查看vmstat命令监控系统资源12345678910111213141516171819202122232425262728293031vmstat [刷新延时 刷新次数]例如： vmstat 1 3 详细解释：procs 进程信息字段 r 等待运行的进程数，数量越大，系统越繁忙 b 不可被唤醒的进程数量，数量越大，系统越繁忙memory 内存信息字段 swpd 虚拟内存的使用情况，单位kb free 空闲的内存容量，单位kb buff 缓冲的内存容量，单位kb cache 缓存的内存容量，单位kb 缓冲与缓存的区别 缓存（cache）是用来加速数据从硬盘中“读取”的，而缓冲（buffer）是用来加速数据“写入”硬盘的swap 交换分区的信息字段 si 从磁盘中交换到内存中数据的数量，单位kb so 从内存中交换到磁盘中数据的数量，单位kb，此两个数越大，证明数据需要经常在磁盘和内存之间交换，系统性能越差io 磁盘读写信息字段 bi 从块设备读入数据的总量，单位块 bo 写到块设备的数据的总量，单位是块，此两个数越大，代表系统的I/O越繁忙system 系统信息字段 in 每秒被中断的进程次数 cs 每秒钟进行的事件切换次数，此两个数越大，代表系统与接口设备的通信非常繁忙CPU CPU信息字段 us 非内核进程消耗CPU运算时间的百分比 sy 内核进程消耗CPU运算时间的百分比 id 空闲CPU的百分比 wa 等待I/O所消耗的CPU百分比 st 被虚笔记所盗用的CPU占比 dmesg开机时内核检测信息1dmesg | grep CPUs free命令查看内存使用状态123456free [-b|-k|-m|-g]选项： -b 以字节为单位显示 -k 以kb为单位显示，默认就是KB为单位显示 -m 以MB为单位显示 -g 以GB为单位显示 查看CPU信息1cat /proc/cpuinfo uptime命令显示系统的启动时间和平均负载，也就是top命令的第一行，w命令也可以看到这个数据 查看系统与内核相关信息12345uname [选项]选项： -a 查看系统所有相关信息 -r 查看内核版本 -s 查看内核名称 判断当前系统的位数file /bin/ls 查看当前Linux系统的发行版本1lsb_release -a 列出进程打开或使用的文件信息123456789101112131415161718lsof [选项]# 列出进程调用或打开文件的信息选项： -c字符串 只列出以字符串开头的进程打开的文件 -u用户名 只列出某个用户的进程打开的文件 -p PID 列出某个PID进程打开的文件 lsof | more# 查询系统中所有进程调用的文件lsof /sbin/init# 查看某个文件被那个进程调用lsof -c httpd# 查看httpd进程调用了那些文件lsof -u root# 按照用户名，查询某用户的进程调用的文件名 系统定时任务at一次性定时任务12345chkconfig --list | grep atd# at服务是否安装service atd restart /systemctl start atd# at服务启动（centos6） at的访问控制 如果系统中有/etc/at.allow文件，那么只有写入/etc/at.allow(白名单)中的用户可以使用at命名（/etc/at.deny文件会被忽略) 如果系统中没有/etc/at.allow文件，只有/etc/at.deny，那么写入/etc/at.deny（黑名单）中的用户不能使用at命令，对root不起作用 如果命令中这两个文件都不存在，那么只有root用户可以使用at命令 at命令12345678910111213141516171819202122232425at [选项] 时间选项： -m 当at工作完成后，无论是否命令有输出，都用email通知执行at命令的用户 -c 工作号，显示at工作的实际内容时间： HH:MM 04:00 HH:MM YYYY-MM-DD 04:00 2017-03-17 HH:MM[am|pm] [Month] [Date] 04pm March 17 HH:MM[am|pm] + number [minutes|hours|days|weeks] now + 5 minutes例子： at now +2 minutes # 在两分钟之后执行hello.sh at&gt; /root/hello.sh &gt;&gt; /root/hello.log例子2： at 02：00 2018-05-28 # 在指定时间重启 at&gt; /bin/sync at&gt; /sbin/shutdown -r now atq# 查询当前服务器上的at工作atrm [工作号]# 删除指定的at任务 crontab循环定时任务crontab服务管理与访问1234systemctl restart crond.service# 启动systemctl enable crond.service# 激活 访问控制 当系统中有/etc/cron.allow文件时，只有写入此文件的用户可以使用crontab命令，没有写入的用户不能使用crontab命令。同样如果此文件，/etc/cron.deny文件会被忽略，/etc/cron.allow文件的优先级更高 当系统中只有/etc/cron/deny文件时，则写入此文件的用户不能使用crontab命令，没有写入文件的用户可以使用crontab命令 用户的crontab设置12345678910crontab [选项]选项： -e 编辑crontab定时任务 -l 查询crontab任务 -r 删除当前用户所有的crontab任务例子： crontab -e # 进入crontab编辑页面，会打开vim编辑你的工作 * * * * * * 执行任务 分时日月星 系统的crontab设置 “crontab -e”是每个用户执行的命令，也就是说不通的用户身份可以执行自己的定时任务，可是有些定时任务需要系统执行，这时我们就需要编辑/etc/crontab这个配置文件 执行系统的定时任务的方法 手工执行定时任务 系统定时任务 第一种把需要定时的脚本复制到/etc/cron.{daily,weekly,monthly}目录中的任意一个 第二种修改/etc/crintab配置文件 anacron配置 anacron是用来保证在系统开始的时候错过的定时任务，可以在系统开机之后再执行 anacron检测周期 anacron会使用一天，七天，一个月作为检测周期 在系统的/var/spool/anacron/目录中存在cron.{daily,weekly,minthly}文件，用于记录上次执行cron的时间 和当前时间做比较，如果两个时间的差超过anacron的值定时间差值，证明有cron任务被执行 123456789vi /etc/anacrontab RANDOM_DELAY=45# 最大随机延迟START_HOURS_RANGE=3-22#anacron的执行范围是3-22点1 5 cron.daily nice run-parts /etc/cron.daily7 25 cron.weekly nice run-parts /etc/cron.weekly@monthly 45 cron.monthly nice run-parts /etc/cron.monthly# 天数 强制延迟（分） 工作名称 实际执行的命令]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux之shell实战]]></title>
    <url>%2F2019%2F02%2F14%2FLinux%E4%B9%8Bshell%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[主控脚本实现vim编辑器设置12345678语法高亮 syntax on显示行号 set number自动缩进 set autoindent set cindent自动加入文件头 shell编程高级知识shell高亮显示12345基本格式： echo -e 终端颜色 + 内容 + 结束后的颜色例子： echo -e "\e[1;30m 内容 \e[1;0m" echo -e "\e[1;30" "内容" $(tupt sgr0) shell中的关联数组123456789关联数组： 普通数组：只能使用整数作为数组索引 关联数组：可以使用字符串作为数组索引 申明关联数组变量 # declare -A ass_array1 数组名[索引]=变量值 # ass_array1[index1]=per monitor.sh脚本1234567891011121314151617181920212223#/bin/bashresettem=$(tput sgr0)declare -A ssharrayi=0numbers=""for script_file in `ls -I "monitor_man.sh" ./`do echo -e "\e[1;30]" "The script:" $&#123;i&#125; '===&gt;' $&#123;resettem&#125; $&#123;script_file&#125; ssharray[$i]=$&#123;script_file&#125; numbers="$&#123;numbers&#125; | $&#123;i&#125;" i=$((i+1))doneecho "结束l"while truedo read -p "请输入数字 [$&#123;numbers&#125;]:" execshell echo $&#123;execshell&#125; if [[ ! $&#123;execshell&#125; =~ ^[0-9]+ ]]; then exit 0 fi /bin/sh ./$&#123;ssharray[$&#123;execshell&#125;]&#125;done 系统信息及运行状态获取脚本system_monitor.sh 功能一、提取操作系统信息（内核，系统版本，网络地址） 功能二、分析系统的运行状态（cpu负载，内存及磁盘使用率等） 12345678910111213141516171819202122232425262728293031323334353637383940414243#/bin/bashclearif [[ $# -eq 0 ]]thenreset_terminal=$(tput sgr0)# 提取操作系统类型 os=$(uname -o) echo -e "\e[1;33m" "操作系统类型" $reset_terminal $os# 获取操作系统发行版本 os_name=$(lsb_release -d) echo -e '\e[1;32m' "操作系统发行版本" $reset_terminal $os_name# 获取系统架构信息 architecture=$(uname -m) echo -e "\E[32m" "操作系统位数" $reset_terminal $architecture# 获取内核信息 kernerrelease=$(uname -r) echo -e "\E[32m" "内核信息：" $reset_terminal $kernerrelease# 主机名 hostname=$HOSTNAME echo -e "\E[32m" "主机名" $reset_terminal $hostname# 获取内网ip internalIP=$(hostname -I) echo -e "\E[32m" "内网IP地址：" $reset_terminal $internalIP # 获取公网ip externalip=$(curl -s http://ipecho.net/plain) echo -e "\E[32m" "公网IP：" $reset_terminal $externalip# 获取DNS nameservers=$(cat /etc/resolv.conf | grep nameserver | awk '&#123;print $NF&#125;') echo -e "\E[32m" "DNS：" $reset_terminal $nameservers# 查看网络是否通畅 ping -c 2 www.baidu.com &amp;&gt;/dev/null &amp;&amp; echo "网络通畅" || echo “网络不通畅”# 查看当前用户登录数 who&gt;/tmp/who echo -e "\E[32m" "当前在线用户" $reset_terminal &amp;&amp; cat /tmp/who rm -f /tmp/whofi 分析系统的运行状态 系统使用的内存和应用使用的内存区别 系统使用内存=Total-Free 应用使用内存Total-（Free+Cached+Buffers） 内存中的cache和buffer的区别 功能 读取策略 cache 缓存主要用于打开的文件 最少使用原则 Buffer 分缓存主要用于目录项，inode等文件系 先进先出策略 CPU负载概念 nginx和mysql应用状态分析应用运行状态监控脚本利用操作系统命令网络命令：ping、nslookup、nm-tool、tracer、traceroute、dig、telnet、nc、curl 监控进程：ps、netstat、pgrep 应用客户端：mysql、ab、mongo、php、jstack 第三方工具包：nginxstatus、nagios-libexec 服务端接口支持 nginx -http_stub_status_module nutcracker监控集群（redis、memcache）状态 Mongodb 监控mysql主从复制状态 搭建主从复制环境 基于mysql客户端连接，获取主从复制状态 myslq &gt; show slave status\G Slave_IO_Running-IO线程是否有连接到主服务器上 Seconds_Behind_Master 主从同步的延时时间 应用日志分析系统日志文件 /var/log/messages // 系统主日志文件 /var/log/secure // 认证，安全 /var/log/dmesg //和系统启动相关 应用服务 access.log //nginx访问日志 mysqld.log //mysql运行日志 xferlog //和访问FTP服务器相关 程序脚本 开发语言：c、C++、java、php 框架：Django、MVC、servlet 脚本语言：shell、python Http状态码 1** 信息服务收到请求，需要请求者进一步操作 2** 成功，操作被成功接收并处理 3** 重定向，需要进一步的操作以完成请求 4** 客户端错误 5** 服务器错误 脚本功能介绍 功能一、分析HTTP状态码在100，200,300,400,500之间及以上的请求条数 分析日志中http状态码为404,500的请求条数]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux之shell基础]]></title>
    <url>%2F2019%2F02%2F14%2FLinux%E4%B9%8Bshell%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[shell基础shell概述1.shell的两种主要语法类型有Bourne和C，这两种语法彼此不兼容，Bourne家族主要包括sh、Bash、psh、zsh；C家族包括：csh、tcsh 1vi /etc/shells # 查看支持的shell 脚本执行方式echo输出命令123echo [选项] [输出内容]选项： -e 支持反斜线控制的字符转换 Bash的基本功能命令别名和快捷键1234567891011alias # 查看所有命令的别名alias 别名="原命令"# 设定命令别名vi ~/.bashrc# 写入环境变量配置文件unalias 别名# 删除别名 命令生效顺序 第一顺位执行用绝对路径或相对路径执行的命令 第二顺位执行别名 第三顺位执行Bash的内部命令 第四顺位执行按照￥PATH环境变量定义的目录查找顺序找到的第一个命令 快捷键 作用 ctrl + c 强制终止当前命令 ctrl + l 清屏 ctrl + a 光标移动到行首 ctrl + e 光标移动到行尾 ctrl + u 从光标所在位置删除到行首 Ctrl + z 把命令放入后台 Ctrl + r 在历史命令中搜索 历史命令12345history [选项] [历史命令保存文件]选项： -c 清空历史命令 -w 把缓存中的历史命令写入历史命令保存文件~/.bash_history# 历史命令默认保存1000条，可以在环境变量配置文件/etc/profile中进行修改 输出重定向1234567891011121314标准输出重定向 命令 &gt; 文件 # 直接写入，里面有内容就覆盖 命令 &gt;&gt; 文件 # 追加内容标准错误输出重定向： 命令 2&gt; 文件 # 以覆盖的方式把错误信息写入文件 命令 2&gt;&gt; 文件 # 追加写入到文件正确输出和错误输出同时保存 命令 &gt; 文件 2&gt;&amp;1 命令 &gt;&gt; 文件 2&gt;&amp;1 命令 &amp;&gt; 文件 命令 &amp;&gt;&gt; 文件 命令 &gt;&gt; 文件1 2&gt;&gt; 文件2/dev/null # 黑洞 输入重定向12345wc [选项] [文件名]选项： -c 统计字节数 -w 统计单词数 -l 统计行数 多命令顺序执行 多命令执行符 格式 作用 ： 命令1：命令2 多个命令顺序执行，命令之间没有任何逻辑联系 &amp;&amp; 命令1&amp;&amp;命令2 逻辑与 当命令1正确执行，命令2才会执行，否则就不会执行 \ \ 命令1 \ \ 命令2 逻辑或 命令1执行不正确，2才会执行，命令1正确，2就不会执行 123456管道符命令格式： 命令1 | 命令2 # 命令1的正确输出作为命令2的操作对象netstat -an# 查看端口连接和用户连接 通配符 通配符 作用 ？ 匹配一个任意字符 * 匹配0个或多个任意字符 [] 匹配括号中任意一个字符 [-] 匹配括号中任意一个字符如：[a-z] [^] l逻辑非，表示匹配不是括号中的任意字符 [ ^0-9],表示不匹配数字 Bash中其他特殊符号 符号 作用 ‘ ‘ 单引号，在单引号中所有特殊符号，如“$ `（反引号） ”都没有特殊含义 “ “ 双引号，在单引号中所有特殊符号，都没有特殊含义，但“$ `（反引号） 和 \ 是一个例外”都没有特殊含义 反引号，反引号括起来的是命令系统，在bash中会先执行它，和$()作用一样，不过推荐使用 \$ (),因为反引号容易看错 $() 和反引号的作用一样 # # 号代表注释 $ 用于调用变量值，如$PATH \ 转意符，跟在\后面的符号将失去特殊含义 Bash变量什么是变量与变量的分类什么是变量 变量是计算机内存的单元，其中存放的值可以改变 变量让你能够把程序中准备使用的每一段数据都赋给一个简短、易于记忆的名字 变量命名规则 变量名必须以字母或下划线开头，名字中间只能由字母、数字和下滑线组成 变量长度不得超过255个字符 变量名在有效范围之内必须唯一 在Bash中，变量的默认类型必须是字符串类型 变量的分类 用户自定义变量 环境变量 位置参数变量 预定义变量 用户自定义变量定义变量1234变量名=变量值例如： x=5 name="xxx" 变量调用1234echo $变量名例如： echo $x echo $name 变量叠加123x=123x="$x"456x=$&#123;x&#125;789 变量查看123set选项： -u 如果设定此选项，调用未声明变量时会报错（默认无任何提示） 变量删除1unset 变量名 环境变量环境变量与用户自定义变量的区别 环境变量是全局变量 用户自定义变量是局部变量 设置环境变量1234export 变量名=变量值或变量名=变量值export 变量名 查看环境变量12345set # 查看所有变量env# 查看环境变量 删除变量1unset 变量名 常用环境变量1234567HOSTNAME 主机名SHELL 当前的shellTERM 终端环境HISTSIZE 历史命令条数SSH_CLIENT 当前操作环境是用ssh连接的，这里记录客户端ipSSH_TTY ssh连接的终端pts/1USER 当前登录用户 PATH环境变量 1234567PATH变量 系统查找命令的路径echo $PATH# 查看PATH环境变量PATH="$PATH":/root/sh# 增加PATH变量值 PS1环境变量1234567891011121314151617PS1变量 命令提示符设置以自行调整全局变量/etc/profile文件用于永久生效 PS1='[\u@\h \W\t]\$'\d 日期\H 完整主机名\h 主机名第一个名字\t 时间24小时制HHMMSS\T 时间12小时制\A 时间24小时制HHMM\u 当前用户账号名\v BASH的版本\w 完整工作目录\W 利用basename取得工作目录名\# 下达的第几个命令\$ 提示字符，root为"#"，普通用户为"$"PS1显示ip地址export PS1="[\u@\h `/sbin/ifconfig ens33 | sed -nr 's/.*inet (addr:)?(([0-9]*\.)&#123;3&#125;[0-9]*).*/\2/p'` \w]\$" 当前语系查询12345678910locale# 查询当前系统语系 LANG 定义系统主语系的变量 LC_ALL 定义整体语系的变量 echo $LANG# 查看系统当前语系locale -a | more# 查看linux支持的所有语系 查询系统默认语系12cat /etc/sysconfig/i18n# centos 6 Linux中文支持前提条件，正确安装的中文字体和中文语系 如果有图形界面，可以正确支持中文显示 如果使用第三方远程工具，只要语系设定正确，可以支持中文显示 如果使用纯字符界面，必须使用第三方插件（如zhcon等） 位置参数变量 位置参数变量 作用 $n n为数字，$0代表命令背书，$1-$9代表第一到第九个参数，十以上的需要用大括号包括，如${10} $* 这个变量代表命令行中所有参数，$*把所有的参数都看做一个整体 $@ 这个变量也代表命令行中所有的参数，不过$@把每个参数区分对待 $# 这个变量代表命令行中所有参数的个数 123456789101112131415161718例子1： #!/bin/bash nun1=$1 num2=$2 sum=$(($num1+$num2)) # 变量sum是num1和num2的和 echo $sum # 打印变量sum的值 例子2： #!/bin/bash echo "这是$*" echo "这是$@" echo "这是$#" 例子3: $* 是指一个整体，只能循环一次 $@ 类似于一个列表，可以循环一个个的取出 预定变量 预定义变量 作用 $? 最后一次执行命令的返回状态，如果这个变量的值为0，证明上一个命令正确执行，如果值非0（具体哪个数，由命令自己决定），则证明上一个命令执行不正确 $$ 当前进程的进程号（PID） $! 后台运行的最后一个进程的进程号（PID） 接收键盘输入1234567891011read [选项] [变量名]选项： -p 提示信息，等待read输入时，输出提示信息 -t 描述，read命令会一直等待用户输入，使用此选项可以指定等待时间 -n 字符数，read命令只接受指定字符数，就会执行 -s 隐藏输入数据，适用于机密信息输入例子： #!/bin/bash read -p "请输入用户名：" name echo $name 运算符declare命令12345678910111213141516declare 声明变量类型declare [+/-] [选项] 变量名选项： - 给变量设定类型属性 + 取消变量的类型属性 -a 声明变量类型为数组 -i 将变量声明为整数型 -x 将变量声明为环境变量 -r 将变量声明为只读类型 -p 显示指定变量的被声明的类型例子： aa=1 bb=2 declare -i cc=$aa+$bb # 声明变量cc的类型是整数型，他的值是aa和bb的和 声明数组变量123456789# 定义数组movie[0]=zpmovie[1]=tpdeclare -a movie[2]=live# 查看数组echo $&#123;movie&#125;echo $&#123;movie[2]&#125;echo $&#123;movie[*]&#125; 声明环境变量12declare -x test=123# 和export作用相似，但其实是declare命令的作用 声明变量只读属性12declare -r test# 给test赋予只读属性，但是注意只读属性会让变量不能修改和删除，甚至不能取消只读属性 查询变量的属性1234declare -p# 查询所有变量的属性declare -p 变量名# 查询指定变量的属性 数值运算的方法1234expr和let数值运算工具dd=$(expr $aa + $bb)# dd的值是aa和bb的和，注意+号两边必须加空格 \$ ((运算式))或 $[运算式]12ff = $(($aa+$bb))gg=$[$aa+$bb] 运算符 优先级 运算符 说明 13 -,+ 单目负，单目正 12 !,~ 逻辑非，按位取反或补码 11 * / % 乘，除、取模 10 +,- 加、减 9 &lt;&lt;, &gt;&gt; 按位左移，按位右移 8 &lt; = ,&gt;= ,&lt; ,&gt; 小于或等于，大于或等于，大于，小于 7 == ,!= 等于，不等于 6 &amp; 按位与 5 ^ 按位异或 4 \ 按位或 3 &amp;&amp; 逻辑与 2 \ \ 逻辑或 1 =,+=,-=,*=,/=,%=,&amp;=,^=,\ =,&lt;&lt;=,&gt;&gt;= 赋值，运算且赋值 变量测试环境变量配置文件简介PATH,HISTSIZE,PS1,HOSTNAME等环境变量写入对应的环境变量配置文件 环境变量配置文件中主要是定义系统操作环境生效的系统默认环境变量，如PATH等 /etc/profile /etc/profile.d/*.sh ~/.bash_profile ~/.bashrc /etc/bashrc source命令1234source 配置文件或. 配置文件# 修改文件之后，必须注销重新登录才能登录也可以source一下 配置文件的功能/etc/profile的作用 USER变量 LOGNAME变量 MAIL变量 HOSTNAME变量 HISTSIZE变量 umask变量 调用/etc/profile.d/*.sh文件 其他配置文件注销时生效的环境变量配置文件 ~/.bash_logout 其他配置文件 ~./bash_history shell登录信息 本地终端登录信息 ： /etc/issue 转义符 作用 \d 显示当前系统日期 \s 显示操作系统名称 \l 显示登录终端号，这个比较常用 \m 先试试硬件体系结构如i386 i686等 \n 显示主机名 \o 显示域名 \r 显示内核版本 \t 显示当前系统时间 \u 显示当前登录用户的序列号 远程终端欢迎信息123/etc/issue.net转义符在/etc/issue.net文件中不能使用是否显示欢迎信息，由ssh的配置文件/etc/ssh/sshd_config决定，加入"Banner/etc/issue.net" 行才能显示（记得重启ssh服务） 登录后欢迎信息：/etc/motd 不管是本地登录，还是远程登录，都可以显示欢迎信息 正则表达式之字符截取命令cut字段提取命令1234567cut [选项] 文件名选项： -f 列号：提取第几列 -d 分隔符：按照指定分隔符分隔例子： cut -d ":" -f 1,3 /etc/passwd # 截取以：分隔的第一列和第三列 printf命令 printf ‘输出类型输出格式’ 输出内容 输出类型 %ns：输出字符串，n是数字代指输出几个字符 %ni：输出整数，n是数字代指输出几个数字 %m.nf :输出浮点数，m和n是数字，代指输出的整数位和小数位，如%8.2f代表共输出8位数，其中2位是小数，6位是整数 输出格式 \a:输出警告声音 \b:输出退格键，也就是backspace键 \f：清除屏幕 \n:换行 \r:回车 \t:水平输出退格符 \v:垂直输出退格符 awk命令123456789101112131415161718192021222324awk '条件1&#123;动作1&#125;条件2&#123;动作2&#125;..' 文件名条件（pattern） 一般使用关系表达式作为条件 x &gt; 10 判断变量x是否大于10 x &gt;= 10 判断变量x是否大于等于10 x &lt;= 10 判断变量x是否小于等于10动作（action） 格式化输出 流程控制语句 例子1： df -h | awk '&#123;print $5 &#125;'BEGIN 在开始执行的东西END 在结束执行的命令例子2： df -h | awk'END&#123;print "end"&#125;&#123;print $5&#125;'FS内置变量例子： awk 'BEGIN&#123;FS=":"&#125;&#123;print $1&#125;' 关系运算符 例子：awk '$4 &gt;= 70&#123;print $2&#125;' sed命令12345678910111213141516171819202122232425262728293031sed [选项] '[动作]' 文件名选项： -n 一般sed命令会把所有数据都输出到屏幕，如果加入此选择则只会经过sed命令处理的行输出到屏幕 -e 允许对输入数据应用多条sed命令编辑 -i 用sed的修改结果直接修改数据的文件，而不是屏幕输出动作： -a 追加，在当前行后添加一行或多行 -c 行替换，用c后面的字符串替换原有数据行 -i+ 插入，在当期行前插入一行或多行 -d 删除，删除指定的行 -p 打印，输出指定行 -s 字符串替换，用一个字符串替换另一个字符串，格式为"行范围s/旧字符串/新字符串/g"类似于vim的替换例子： sed '2，d' student.txt # 删除第二行到第四行 sed '2a nnnnn' student.txt # 在第二行后面加入 nnnnn sed '2i nnnnn' student.txt # 在第二行插入 nnnnn sed '4c dasdasda' student.txt # 把文件第四行替换为dasdasda字符串替换sed 's/旧的/新的/g'sed '3s/60/90/g' student.txt# 把第三行数据的60替换为90sed -e 's/xx//g;s/oo//g' student.txt# -e执行多条，用；分隔 字符处理命令sort命令12345678910sort [选项] 文件名选项： -f 忽略大小写 -n 以数值型进行排序，默认使用字符串进行排序 -r 反向排序 -t 指定分隔符 -k n[,m] 按照指定的字段排序，从第n个字段开始，m字段结束（默认行尾）例子： sort -n -t ":" -k 3,3 /etc/passwd # 指定分隔符是：，用第三段开头，第三段结尾排序，就是只用第三段进行排序 统计命令wc命令12345wc [选项] 文件名选项： -l 只统计行数 -w 只统计单词数 -m 只统计字符数 条件判断条件判断式按照文件类型进行判断 测试选项 作用 -b 文件 判断该文件是否存在，并且是否为块设备文件（是块设备文件为真） -c 文件 判断该文件是否存在，并且是否为字符设备文件（是字符设备文件为真） -d 文件 判断该文件是否存在，并且是否为目录文件（是目录文件为真） -e 文件 判断该文件是否存在（存在为真） -f 文件 判断该文件是否存在，并且是否为普通文件（是普通文件为真） -L 文件 判断该文件是否存在，并且是否为符号链接文件（是符号链接文件为真） -p 文件 判断该文件是否存在，并且是否为管道文件（是管道文件为真） -s 文件 判断该文件是否存在，并且是否为非空（非空为真） -S 文件 判断该文件是否存在，并且是否为套接字文件（是套接字文件为真） 123456两种判断格式test -e /root/1.log[-e /root/1.log] # 推荐[-d /root] &amp;&amp; echo "yes" || echo "no"# 第一条为真则为yes，否则为no 按照文件权限来判断 测试选项 作用 -r 文件 判断该文件是否存在，并且拥有该文件的读权限（有读权限为真） -w 文件 判断该文件是否存在，并且拥有该文件的写权限（有写权限为真） -x 文件 判断该文件是否存在，并且拥有该文件的执行权限（有执行权限为真） -u 文件 判断该文件是否存在，并且拥有该文件的SUID权限（有SUID权限为真） -u 文件 判断该文件是否存在，并且拥有该文件的SGID权限（有SGID权限为真） -k 文件 判断该文件是否存在，并且拥有该文件的SBit权限（有SBit权限为真） 两个文件之间进行比较 测试选项 作用 文件1 -nt 文件 2 判断文件1的修改时间是否比文件2新（如果新则为真） 文件1 -ot 文件2 判断文件1的修改时间是否比文件2旧（如果旧则为真） 文件1 -ef 文件2 判断文件1是否和文件2的inode号一致，可以理解问是否是同一文件，这个是判断硬链接的一种方式 两个整数之间比较 测试选项 作用 整数1 -eq 整数2 判断整数1是否和整数2相等（相等为真） 整数1 -ne 整数2 判断整数1是否和整数2不相等（不相等为真） 整数1 -gt 整数2 判断整数1是否大于整数2（大于为真） 整数1 -lt 整数2 判断整数1是否小于整数2（小于为真） 整数1 -ge整数2 判断整数1是否大于等于整数2（大于等于为真） 整数1 -le整数2 判断整数1是否小于等于整数2（小于等于为真） 字符串的判断 测试选项 作用 -z 字符串 判断字符串是否为空（为空返回真） -n 字符串 判断字符串是否为非空（非空返回真） 字符串1 == 字符串2 判断字符串1是否和字符串2相等（相等返回真） 字符串1 ！= 字符串2 判断字符串1是否和字符串2不相等（不相等返回真） 多重条件判断 测试选项 作用 判断1 -a 判断2 逻辑与 判断1 -o 判断2 逻辑或 ！ 判断 逻辑非 if语句1234567891011121314151617181920212223242526272829单分支if语句格式：if [条件判断式]；then 程序fi或者if [条件判断式] then 程序fi双分支if语句if [条件判断式] then 条件成立 else 条件不成立fi www.netcraft.com多分支if语句if [条件判断1] then 条件1成立 elif [条件2] then 条件2成立执行的 else 都不成立要执行的fi case语句123456789case $变量名 in "值1"） 如果变量的值等于值1，则执行程序1 ；； "值2"） 如果变量的值等于值2，则执行程序1 *） 如果都不等于，执行它 ；；esac for循环12345语法1for 变量 in 值1 值2 值3 do 程序 done while循环和until循环1234while [条件] do 循环体 done]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux权限管理之特殊权限]]></title>
    <url>%2F2019%2F02%2F13%2Flinux%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E4%B9%8B%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[ACL权限ACL权限简介与开启1234567891011121314151.查看分区ACL权限是否开启dumpe2fs -h /dev/vda1# dumpe2fs命令式查询指定分区详细文件系统信息的命令选项: -h 仅显示超级块中信息,而不显示磁盘块组的详细信息2.临时开启分区ACL权限mount -o remount,acl /3.永久开启分区ACL权限vim /etc/fstab UUID=eb448abb-3012-4d8d-bcde-94434d586a31 / ext4 defaults,acl 1 1# 加入aclmount -o remount /# 重新挂载文件或重启系统,使修改生效 查看与设定ACL权限查看ACL命令12getfacl 文件名# 获取文件的ACL权限 设定ACL权限的命令12345678910setfacl 选项 文件名选项: -m 设定ACL权限 -x 删除指定ACL权限 -b 删除所有的ACL权限 -d 设定默认的ACL权限 -k 删除默认ACL权限 -R 递归设定ACL权限例如: setfacl -m u:用户名:权限 文件夹 给用户组设定ACL权限1setfacl -m g:组名:权限 文件夹 给mask设定权限12345setfacl -m m:权限 文件夹# 设定mask权限例子： setfacl -m m:rx 文件夹名 # 设定mask权限为r-x，使用m：权限的格式 最大有效权限与删除ACL权限最大有效权限mask mask是用来指最大有效权限的，如果我给用户赋予了ACL权限，是需要和mask相 “与” 才能得到用户的真正权限 删除ACL权限12345678setfacl -x u:用户名 文件名# 删除指定用户的ACL权限setfacl -x g：组名 文件名# 删除指定用户组ACL权限setfacl -b 文件名# 删除文件的所有的ACL权限 默认ACL权限与递归ACL权限递归权限 递归是父目录在设定ACL权限时，所有的子文件和子目录也会拥有相同的ACL权限 setfacl -m u：用户名：权限 -R 文件夹名 默认权限 默认ACL权限的作用是如果给父目录设定了默认ACL权限，那么父目录中所有新建的子文件都会继承父目录的ACL权限 1serfacl -m d:u:用户名：权限 文件夹名 sudo权限 root把本来只能超级用户执行超级用户执行的命令赋予普通用户执行 sudo的操作对象是系统命令 sudo的使用1234567891011121314151617181920visudo# 实际修改的是/etc/sudoersroot ALL=（ALL） ALL# 用户名 被管理主机的地址 = （可使用的身份） 授权命令 （绝对路径）# %where ALL（ALL） ALL# %组名 被管理主机地址=（可使用的身份） 授权命令（绝对路径）sudo -l# 查看可用的sudo的命令sudo /sbin/shoutdown -r now例子1： # 普通用户执行sudo赋予的命令 sudo + 命令例子2： # 授权普通用户可以添加其他用户 visudo user1 ALL=/user/sbin/useradd user1 ALL=/user/sbin/passwd # 授予用户设定密码权限 注意：这个很危险，可以修改root密码 文件特殊权限SetUID功能 只有可以执行的二进制程序才能设定SUID权限 命令执行者要对程序拥有x（执行）权限 命令执行者在执行该程序时获得该程序文件属主的身份（在执行程序的过程中灵魂附体为文件的属主） SetUID权限只在该程序执行的过程中有效，也就是说身份改变只在程序运行中有效 12345passwd命令拥有SetUID权限，所以普通用户可以修改自己的密码-rwsr-xr-x. 1 root root 27832 Jun 10 2014 /usr/bin/passwdcat命令没有SetUID权限，所以普通用户必能查看/etc/shadown文件内容-rwxr-xr-x. 1 root root 54080 Nov 6 2016 /bin/cat 设定SetUID的方法1234代表SUID chmod 4755 文件名 chmod u+s 文件名 危险的SetUID 关键目录应严格控制写权限，比如：/ ,”/usr”等 用户密码设置要严格遵守三原则 对系统中默认应该具有SetUID权限的文件作一列表，定时检查有没有这之外的文件被设置了SetUID权限 SetGID作用 只有可以执行的二进制程序才能设定SGID权限 命令执行者要对程序拥有x（执行）权限 命令执行者在执行该程序时，组身份升级为该程序文件的属组 SetGID权限只在该程序执行的过程中有效，也就是说组身份改变只在程序执行过程中有效 123ll /usr/bin/locate -rwx--s--x 1 root slocate 40520 Apr 11 2018 /usr/bin/locate# 查看设置的SGID /usr/bin/locate 是可执行的二进制程序，可以赋予SGID 执行用户lamp对/usr/bin/locate 命令拥有执行权限 执行/usr/bin/locate 命令时候，组身份升级为slocate组，而slocate组对/var/lib/mlocate/mlocate.db数据库拥有r权限，所以普通用户可以使用locate命令查询mlocate.db数据库 命令结束，lamp用户的组身份回归为lamp组 SetGID针对目录的作用 普通用户必须对此目录拥有r和x权限，才能进入此目录 普通用户在此目录中的有效组会变成此目录的数组 若普通用户对此目录拥有w权限时，新建的文件的默认数组则是这个目录的属组 设定SetUID的方法1232代表SUID chmod 2755 文件夹名 chmod g+s 文件夹名 Sticky BITSBIT粘着位作用 粘着位目前只对目录有效 普通用户对于该目录拥有w和x权限，即普通用户可以在此目录有写入权限 如果没有粘着位，用为普通用户拥有w权限，所以可以删除此目录下的所有文件，包括其他用户建立的文件，一旦赋予了粘着位，除了root可以删除所有文件，普通用户就算有w权限，也只能删除自己建立的文件，但是不能删除其他用户建立的文件 设置与取消粘着位123456设置粘着位 chmod 1755 目录名 chmod o+t 目录名取消粘着为 chmod 0777 目录名 chmod o-t 目录名 不可改变位权限（chattr权限）chattr命令123456789chattr [+-=] [选项] 文件或目录名 + 增加权限 - 删除权限 = 等于某权限选项： i 如果对文件设置i属性，那么不允许对文件进行删除，改名，也不能添加和修改数据； 如果对目录设置值i属性，那么只能修改目录下文件的数据，但不允许建立和删除文件 a 如果对文件设置a属性，那么只能在文件中增加数据，但不能删除也不能修改数据 如果对目录设置值a属性，那么只允许在目录中建立和修改文件，但不允许删除 查看文件系统属性1234lsattr 选项 文件名选项： a 显示所有文件和目录 d 若目标是目录，仅列出目录本身属性，而不是子文件的]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux权限管理之基本权限]]></title>
    <url>%2F2019%2F02%2F13%2Flinux%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E4%B9%8B%E5%9F%BA%E6%9C%AC%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[文件基本权限基本权限的修改123456789101112131415161718-rw-r--r-- - 文件类型（-文件 d目录 | 软连接） rw- r-- r-- u所有者 g所属组 o其他人 r 读 w 写 x 执行chmod命令chmod [选项] 模式 文件名选项： -R 递归模式： [ugoa][+-=][rwx] [mode=421]权限的数字表示 r 4 w 2 x 1 权限的作用权限对文件的作用123r 读取文件内容（cat more head tail）w 编辑，新增，修改文件内容，但是不包含删除文件（vi echo）x 可执行 权限对目录的作用1234r 可以查询目录下文件名（ls）w 具有修改目录结构的权限，如新建文件和目录，删除此目录下文件和目录，重命名此目录下文件和目录，剪切（touch rm mv cp）x 可以进入目录目录适用的权限：0 5 7三种 其他权限命令12chown 用户名 文件名 # 修改文件所有者chgrp 组名 文件名 # 修改所属组 文件默认权限查看默认权限的命令123456umask# 查看默认权限0022 第一位0：文件特殊权限 022 文件默认权限 文件的默认权限 文件默认不能建立执行文件，必须手工赋予执行权限 所以文件默认权限最大是666 默认权限需要换算成字母再相减 建立文件后的默认权限，为666减去umask值 123456例如: 文件默认最大权限666 umask值022 -rw-rw-rw- 减去 -----w--w- 等于 -rw-r--r--例如: 文件默认最大权限666 umask值033 -rw-rw-rw- 减去 -----wx-wx 等于 -rw-r--r-- 目录的默认权限 目录默认权限最大为777 默认权限需要算成字母再相减 建立文件之后的默认权限,为777减去umask值 123456例如: 文件夹默认最大权限777 umask值022 -rwxrwxrwx 减去 -----w--w- 等于 -rwxr-xr-x例如: 文件夹默认最大权限777 umask值033 -rw-rw-rw- 减去 -----wx-wx 等于 -rw-r--r--]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux软件安装管理]]></title>
    <url>%2F2019%2F02%2F12%2FLinux%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[软件包管理软件包的分类 源码包 二进制包 源码包的优点 开源，如果有足够能力，可以修改源代码 可以自由选择所需的功能 软件是编译安装，所有更加适合自己的系统，更加稳定也效率更高 卸载方便 源码包的缺点 安装麻烦，尤其是一些比较大的集合软件 编译过程时间比较长，安装比二进制安装时间长 因为是编译安装，一旦出错会很麻烦 二进制包的优点 包管理系统简单，只通过几个命令就可以实现包的安装，升级，查询和卸载 安装速度比源码包要快 二进制的缺点 经过编译，不能看到源代码了 功能选择不如源码包灵活 依赖性 rpm命令管理RPM包命名规则1234567httpd-2.2.15-15.el6.centos.1.i686.rpm - httpd 软件包名 - 2.2.15 软件版本 - 15 软件发布的次数 - el6.centos 适合的linux的平台 - i686 适合的硬件平台 - rpm rpm包的扩展名 RPM包的依赖性 树形依赖：a -&gt; b -&gt; c 环形依赖：a - &gt; b -&gt; c -&gt; a 模块依赖：查询网站：www.rpmfind.net 安装命令包全名与包名 包全名：操作的包是没有按照的软件包时，使用包全名，而且要注意路径 包名：操作已经安装的软件包时，使用包名是搜索/var/lib/rpm 中的数据库 RPM安装123456rpm -ivh 包全名选项： -i 安装 -v 显示详细信息 -h 显示进度 --nodeps 不检测依赖性 升级和卸载RPM包升级123rpm -Uvh 包全名选项： -U 升级 RPM包卸载1234rpm -e 包名选项： -e 卸载 --nodeps 不检查依赖性 RPM包查询查询是否安装123456rpm -q 包名# 查询是否安装-q 查询rpm -qa# 查询所有安装的rpm包 查询软件包的详细信息1234rpm -qi 包名选项： -i 查询软件信息 -p 查询未安装包信息 查询包中文件安装位置1234rpm -ql 包名选项： -l 列表 -p 查询未安装包信息 RPM包默认安装位置 地址 详细 /etc/ 配置文件安装目录 /usr/bin/ 可执行的命令安装目录 /usr/lib/ 程序所使用的函数库保存位置 /usr/share/doc/ 基本的软件使用手册保存位置 /usr/share/man/ 帮助文件保存位置 查询系统文件属于哪个rpm包123rpm -qf 系统文件名选项： -f 查询系统文件属于哪个软件包 查询软件包的依赖性1234rpm -qR 包名选项： -R 查询软件包的依赖性 -p 查询未安装包的信息 RPM包校验1234567891011121314151617181920rpm -V 已安装的包名选项： -V 校验指定RPM包的文件 验证内容中的8个信息的具体内容 s 文件大小是否改变 M 文件的类型或文件权限（rwx）是否被改变 5 文件MD5校验是否改变（可以看成文件内容是否被改变） D 设备的主从代码是否改变 L 文件路径是否改变 U 文件的属主（所有者）是否改变 G 文件的属组是否改变 T 文件的修改实际是否改变文件类型 c 配置文件 d 普通文件 g “鬼”文件，就是该文件不应该被这个RPM所包含的 L 授权文件 r 描述文件 RPM包中的文件提取12345678910111213rpm2cpio 包全名 | cpio -idv .文件绝对路径rpm2cpio# 将rpm包转换为cpio格式的命令cpio # 是一个标准工具，他用于创建软件档案文件和从档案文件中提取文件cpio 选项 &lt; [文件|设备]选项： -i copy-in模式，还原 -d 还原时自动新建目录 -v 显示还原过程 yum在线安装yum源文件12345678910vim /etc/yum.repos.d/CentOS-Base.repo [base] 容器说明，一定要放在[]中name 容器说明，可以自己随便写mirrorlist 镜像站点，这个可以注释baseurl yum源服务器的地址，可以自己更改自己喜欢的yum源enabled 此容器是否生效，1代表生效，0代表不生效gpgcheck 如果是1是指RPM数字保证书生效，如果是0则是不生效gpgkey 数字保证书的公钥文件保存位置，不用修改failovermethod=priority 光盘搭建yum源123456789101112131415161.挂载光盘mkdir /mnt/cdrom# 建立挂载点mount /dev/cdrom /mnt/cdrom/# 挂载光盘2.使网络yum源失效cd /etc/yum.repos.d/# 进入yum源目录mv CentOS-Base.repo CentOS-Base.repo.bak# 修改yum源文件后缀名，使其失效3.使光盘yum源生效vim CentOS-Media.repo# 修改位置为光盘挂载位置 yum命令常用yum命令12345678910111213141516171819202122查询yum list# 查询所有可用软件包列表yum search 关键字# 搜索服务器上所有和关键字相关的包安装yum -y install 包名选项： install 安装 -y 自动回答yes 升级yum -y update 包名选项： update 升级 卸载yum -y remove 包名选项： remove 卸载 yum软件组管理命令12345678yum grouplist# 列出所有可用的软件组列表yum grouplist 软件组名# 安装指定软件组，组名可用由grouplist查询出来yum groupremove 软件组名# 卸载指定软件组 源码包安装源码包和RPM包的区别区别： 安装之前的区别：概念上的区别 安装之后的区别：安装位置的不同 安装位置不同带来的影响RPM包安装的服务可以使用系统服务管理命令（service）来管理，例如RPM包安装的apache的启动方法 /etc/rc.d/init.d/httpd start service httpd start 源码包安装位置安装在指定位置，一般是 /usr/local/软件名/ 源码包安装过程12345678910111213141516171819202122231.安装准备 安装gcc 下载源码包2.安装注意事项 源码包保存位置：/usr/local/src 软件安装位置：/usr/local 如何确定安装过程报错 安装过程停止 并出现error，warning或no提示3.源码包安装过程 下载源码包 解压下载好的源码包 进入解压目录 ./configure 软件配置与检查 定义需要功能的选项 检测系统环境是否符合安装需求 把定义好的功能选项和检测系统环境的信息都写入Makefile文件，用于后续编辑 --prefix=指定安装的位置4.make编译 make clean 清除编译好的文件 make install 编译安装卸载：直接删除安装目录即可 脚本安装1234567891011网址： lnmp.org所谓的一键安装包，实际上还是安装的源码包与RPM包，知识把安装过程写成了脚本，便于初学者安装优点： 简单，快捷，方便缺点： 不能定义安装软件的版本 不能定义所需要的软件功能 源码包的优势丧失 关闭SElinux和防火墙vim /etc/selinux/config 把enforcing改为disabled]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux网络管理]]></title>
    <url>%2F2019%2F02%2F11%2Flinux%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[网络基础OSI七层模型123ISO:国际标准化组织OSI：开放系统互联模型IOS：苹果操作系统 名称 详细 应用层 用户接口 表示层 数据的表示形态，功能特定的实现：加密 会话层 对应用会话管理，同步 传输层 可靠与不可靠传输，传输前的错误检测，流控 网络层 提供逻辑地址，选路 数据链路层 成帧，用MAC访问媒介，错误检测与修正 物理层 设备之间的比特流的传输，物理接口，电气特性等 TCP/IP四层模型OSI七层与TCP/IP的对应关系 12345678910111213141516171819202122232425262728293031应用层表示层 应用层会话层传输层 传输层网络层 网际互联层数据链路层物理层 网络接口层网络接口层 网络接入层与OSI参考模型中的物理层和数据链路层相对应，他负责监视数据在主机和网络之间的交换 事实上，TCP/IP本身并未定义该层协议，而又参与互联的各网络接入层进行连接，地址解析协议（ARP） 工作在此层，即OSI参考模型的数据链路层网际互联层 网际互联层对应于OSI参考模型的网络层，主要解决主机到主机的通信问题，他所包含的协议涉及数据包 在整个网络上的逻辑传输，该层有三个主要协议：网际协议（IP），互联网组管理协议（IGMP）和互联网 控制报文协议（ICMP）传输层 传输层对应OSI参考模型的传输层，为应用层实体提供端到端的通信功能，保证了数据包的顺序传送及 数据的完整性，该层定义了两个主要协议：传输控制协议（TCP）和 用户数据报协议（UDP）应用层 应用层对应OSI参考模型的高层，为用户提供所需要提供的各种服务，如：FTP，Telnet，DNS，SMTP等TCP/IP模型与OSI模型的比较共同点 OSI参考模型和TCP/IP参考模型都采用了分层结构的概念 都能够提供面向连接和无连接两种通信服务机制不同点 前者是七层，后者是四层 对可靠性要求不同 OSI模型在协议开发前设计的，具有通用性，TCP/IP是现有协议然后集然后建立模型，不适用与非TCP/IP网络 实际市场应用不同（OSI模型只是理论上的模型，并没有成熟的产品，而TCP/IP已经成为“实际上的国际标准”） IP地址ip地址分类 子网掩码的使用1234三种： 255.255.255.0 255.255.0.0 255.0.0.0 端口作用123456789101112端口号是什么？ 计算机有2的16次方的端口号，可以通过端口找到对应服务端口号的分类？常见的端口号？ FTP（文件传输协议）：端口号 20 21 SSH（安全shell协议）：端口号 22 telnet（远程登录协议）：端口号 23 DNS（域名系统）： 端口号 53 http（超文本传输协议）：端口号 80 https（超文本传输安全协议）：端口号 443 SMTP（简单邮件传输协议）：端口号 25 POP3(邮局协议3代)： 端口 110 查看本机启用的端口1234netstat -an选项： -a 查看所有连接和监听端口 -n 显示IP地址和端口号，而不显示域名和服务名 DNS作用1234567891011121314将域名解析为IP地址 客户机向DNS服务器发送域名查询请求 DNS服务器告知客户机Web服务器的ip地址 客户机与web服务器进行通信从查询方式划分 递归查询 要么作出成功响应，要么一直作出查询失败的响应，一般客户机和服务区之间属递归查询，即客户机向DNS服务器 发送请求后，若DNS服务器本身不能解析，则会向另外的DNS服务器发起查询请求，得到的请求转交给客户机 迭代查询 服务器收到一次迭代查询回复一次查询结果，但是这个结果不一定是目标IP与域名的映射关系，也可以是其他DNS服务器的地址 从查询内容上划分 正向查询由域名查询IP地址 反向查询由IP地址查找域名 网关作用 网关又称为网间连接器，协议转换器 网关在网络层实现网络互连，是最复杂的网络互连设备，近用于两个高层协议不同的网络互连 网关即可用于广域互连，也可以用于局域网互连 网关是一种充当转换重任的服务器和路由器 123网关的作用 1.网关在所有内网计算机访问的不是本网段的数据报时使用 2.网关负责将内网ip转换为公网ip，公网ip转换为内网ip linux网络配置linux配置IP地址1234567service network restart# 重启网络1.ifconfig命令临时配置IP地址2.setup工具永久配置IP地址3.修改网络配置文件4.图形界面 linux网络配置文件网卡配置文件123456789101112131415vim /etc/sysconfig/network-scripts/ifcfg-eth0# 查看网卡配置DEVICE=eth0 网卡设备名BOOTPROTO=static 是否自动获取IP（none，static，dhcp）HWADDR=00：0c:29:17:c4:09 MAC地址NM_CONTROLLED=yes 是否可以由Network Manager图形管理工具托管ONBOOT=yes 是否随网络服务启动，eth0生效TYPE=Ethernet 类型为以太网UUID="asdasdasda" 唯一标识码IPADDR=172.17.189.129 IP地址NETMASK=255.255.240.0 子网掩码GATEWAY=192.168.19.0 网关DNS1=8.8.8.8 DNSIPV6INIT=no IPV6没有启用USERCTL=no 不允许非root用户控制此网卡 主机名文件123456789vim /etc/sysconfig/network# 查看主机名NETWORKING_IPV6=noPEERNTP=noGATEWAY=172.17.191.253HOSTNAME=root 主机名hostname [主机名]# 查看或临时设置主机名命令 DNS配置文件123456vim /etc/resolv.conf # 查看DNS配置文件nameserver 100.100.2.136 设置dnsnameserver 100.100.2.138options timeout:2 attempts:3 rotate single-request-reopen 虚拟机网络参数配置12345678910111213141516171819202122231.配置linux的IP地址 setup # 修改ip地址 2.启动网卡vim /etc/sysconfig/network-scripts/ifcfg-eth0把 ONBOOT=no改为 ONBOOT=yesservice network restart# 重启网络服务3.修改UUID vim /etc/sysconfig/network-scripts/ifcfg-eth0 # 删除MAC地址行 rm -rf /etc/udev/rules.d/75-persistent-net-generator.rules # 删除网卡和MAC地址绑定文件 重启系统 4.设置网络连接方式5.修改桥接网卡 Linux网络命令网络环境查看命令查看网络状态1ifconfig 查看与配置网络状态命令 关闭和启动网卡12345ifdown 网卡设备名# 禁用该网卡设备ifup 网卡设备名# 启用该网卡设备 查询网络状态123456789101112131415netstat 选项选项： -t 列出TCP协议端口 -u 列出UDP协议端口 -n 不使用域名和服务名，而使用IP地址和端口号 -l 仅列出在监听状态网络服务 -a 列出所有的网络连接 netstat -rn# 查看网关route -n# 查看路由列表route add default gw 192.168.19.1# 临时设定网关 域名解析命令12345yum install bind-utils -y# 下载nslookupnslookup [主机名或IP]# 进行域名与IP地址解析 网络测试命令ping命令1234ping [选项] ip或域名# 探测指定IP或域名的网络情况选项： -c 次数指定ping包的次数 telnet命令123telnet [域名或IP] [端口]# 远程管理与端口探测命令telnet 192.168.19.1 80 traceroute命令1234traceroute [选项] IP或域名# 路由跟踪命令选项： -n 使用IP，不使用域名，速度更快 wget命令12wget http：//.........# 下载命令 tcpdump命令123456tcpdump -i eth0 -nnX port 21选项： -i 指定网卡接口 -nn 将数据包中的域名与服务转为IP和端口 -X 将十六进制和ASCII码显示数据包内容 port 指定监听的端口 远程登录SSH协议原理12345对称加密算法 采用但要是密码系统的加密方法，同一个秘钥可以同时用作信息的加密和解密，这种加密方法称为对称加密，也称为单秘钥加密非对称加密算法 非对称加密算法又称为“公开秘钥加密算法”，非对称加密需要两个秘钥：公开秘钥和私有秘钥 ssh命令123456789ssh 用户名@ip# 远程管理指定Linux服务器scp [-r] 用户名@ip：文件路径 本地路径# 下载文件scp [-r] 本地文件 用户名@ip：上传路径# 上传文件# -r 代表上传下载的是目录 SecureCRT远程管理工具Xshell工具和WinSCP文件传输工具]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基础(二)]]></title>
    <url>%2F2019%2F02%2F11%2Flinux%E5%9F%BA%E7%A1%80%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[磁盘管理df 查看磁盘分区使用状况12345678选项： -l 仅显示本地磁盘（默认） -a 显示所有文件系统的磁盘使用情况，包含/proc/ -h 以1024进制计算最适合的单位显示磁盘容量 -H 以1000进制计算最适合的单位显示磁盘容量 -T 显示磁盘分区类型 -t 显示指定类型文件系统的磁盘分区 -x 不显示指定类型文件系统的磁盘分区 du 统计磁盘的文件大小1234567选项： -b 以byte为单位统计文件 -k 以kb为单位统计文件 -m 以MB为单位统计文件 -h 按照1024进制以最适合的单位统计文件 -H 按照1000进制以最适合的单位统计文件 -s 指定统计目标 分区的概念 第一 主分区和扩展分区总数不能超过4个 第二 扩展分区最多只能有一个 第三 扩展分区不能直接存取数据 1分区： fdisk来分区 分区模式值MBR 主分区不超过4个 单个分区容量最大2TB 分区模式之GPT 主分区的个数“几乎”没有限制 单个分区容量“几乎”没有限制 parted的使用123456789101112parted #分区工具选项： help 查看帮助信息 mklabel gpt 指定使用gpt来分区 select /dev/sdc 切换分区 mkpart 添加分区 cancel 取消操作 print 查看目前分区情况 rm 分区编号 删除分区 mkpart 分区名称 起始位置 结束位置# 使用命令分区 mkfs的使用1234567mkfs.ext3 /dev/sdb# 把/dev/sdb 分区格式化为ext3文件系统格式mkfs -t ext4 /dev/sdb2# 把/dev/sdb2 分区格式化为ext4文件系统格式# 只有主分区和逻辑分区可以格式化，其他分区不可以 挂载分区12345678mount /dev/sdb /mnt/xxx# 把/dev/sdb挂载到/mnt/xxx下umount /mnt/xxx# 把挂载的分区卸载掉vim + /etc/fstab# 修改系统的挂载，可以自动挂载 swap交换分区12345678910111213如何为硬盘添加swap交换分区 - 第一，建立一个普通的linux分区 - 第二，修改分区类型的16进制编码 - 第三，格式化交换分区 - 第四，启用交换分区 mkswap /dev/sdb # 格式化为swap交换分区swapon /dev/sdb # 启动分区swapoff /dev/sdb # 关闭分区 用户和用户组用户和用户组信息存储位置1234567891011121314用户：使用操作系统的人用户组：具有相同系统权限的一组用户/etc/group 存储当前系统中所有用户组信息 - Group： x ：123 ：abc，def，xxx - 组名： 组密码占位符：组编号：组中用户列表/etc/gshadow 存储当前系统中用户组密码信息 - group： *： ： abc，def，xxx - 组名： 组密码： 组管理者： 组中用户名列表/etc/passwd 存储当前系统中所有用户信息 - user ： x ：123 ：456 ：xxxxx ：/home/user :/bin/bash - 用户名：密码占位符：用户编号：用户组编号 ：用户注释信息：用户主目录 ：shell类型/etc/shadow 存储当前系统中所有用户的密码信息 - user：$6$h26yil8F$X3OPNjL....：：：：： - 用户名：密码（加密的）：：：：： 用户组相关命令123456789101112131415161718192021groupadd 组名 添加用户组# 创建用户组选项： -f 如果组存在，则强制退出成功 -g 指定组id -h 帮助信息 -p 组密码 -r 创建一个系统账户 groupmod 修改用户组选项： -n 修改名称 -g 修改组id groupmod -n market sexy # 修改组名 把sexy改为marketgroupmod -g 668 market# 修改组编号groupdel 删除用户组 用户相关命令12345678910111213141516171819202122232425262728useradd 创建用户选项： -g 后面加组名和用户名，就是把这个用户添加到这个组中 -d 可以指定家目录 -G 指定附属组例子： useradd -g 组名 用户名 useradd -d /home/xxxx 用户名 useradd -g 主组 -G 附属组1，附属组2 用户名usermod 修改用户选项： -c 修改用户备注信息 -l 修改用户名称 -d 修改家目录 -g 修改用户的主用户组例子： usermod -c 注释内容 用户名 usermod -l 新用户名 旧用户名 usermod -d 家目录 用户名 userdel 删除用户选项: -r 删除用户时，连同用户家目录一块删除touch /etc/nolog# 除了root用户，其他用户都不能登录 进阶命令123456789101112131415161718192021222324252627282930313233343536373839passwd -l 用户名# 锁定用户passwd -u 用户名# 解锁用户passwd -d 用户名# 清空用户密码gpasswd -a 用户名 用户组# 给这个用户添加一个附属组gpasswd -d 用户名 用户组# 给这个用户删除一个附属组gpasswd 组名# 修改用户组密码newgrp 组名# 切换用户组su 切换用户whoami # 显示当前登录用户id 用户名# 显示指定用户信息，包括用户编号，用户名# 主要组编号及名称，附属组列表groups 用户名# 显示用户所在的所有用户组chfn 用户名# 设置用户资料，依次输入用户资料finger 用户名# 显示用户详细信息]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基础（一）]]></title>
    <url>%2F2019%2F02%2F07%2Flinux%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Linux安装虚拟机的安装Vmware官网 虚拟机的使用系统分区linux系统安装centos6的文件系统类型是ext4 linux安装时至少划分根分区 / 和SWAP分区 setup工具配置IP地址 linux的常用命令命令基础格式1234567[root@root ~]# 其中： root（1）： 当前登录用户 root（2）：主机名 ~ ：当前所在目录（~ 表示家目录） # ：超级用户提示符 $ :普通用户的提示符 12345命令 [选项] [参数]注意：个别命令使用不遵循此格式 当有多个选项的时候，可以写在一起 简化选项和完整选项 -a 等于 --al 查询目录中的内容： ls 1234567891011121314151617ls 【选项】 【文件或目录】选项： -a 显示所有文件，包括隐藏文件 -l 显示详细信息 -d 查看目录属性 -h 人性化显示文件大小 -i 显示inode-rw-r--r-- 1 root root 332 Feb 6 19:26 main.go - 文件类型（-文件 d 目录 |软链接文件） rw- r-- r-- u所有者 g所属组 o其他人 r读 w写 x执行 root 属主 root 属组 332 文件大小 Feb 6 19:26 最后一次更改的时间 main.go 文件名称 文件处理命令目录处理命令建立目录： mkdir 123mkdir -p [目录名] -p 递归创建 命令英文原意： make directories 切换所在目录： cd 123456789101112切换所在目录： cd 命令英文原意： change directory简化操作 cd ~ 进入当前用户的家目录 cd 和cd ~一样 cd - 进入上一次目录 cd .. 进入上一级目录 cd . 进入当前目录 相对路径和绝对路径 相对路径：参照当前所在目录，进行查找 绝对路径：从根目录开始指定，一级一级递归查找，在任何目录下都能进入指定位置 查询所在目录位置： pwd 12pwd命令英文原意：print working directory 删除空目录：rmdir 12rmdir [目录名]命令英文原意：remove empty directories 文件处理命令删除文件或目录：rm 12345rm -rf [文件或目录] 命令英文原意：remove选项： -r 删除目录 -f 强制 复制命令：cp 1234567cp [选项] [原文件或目录] [目标目录]命令英文原意：copy选项： -r 复制目录 -p 连带文件属性复制 -d 若源文件是链接文件，则复制链接属性 -a 相当于 -pdr 剪切或改名命令：mv 12mv [原文件或目录] [目标目录]命令英文原意：move 常用的目录 / 根目录 /bin 命令保存目录(普通用户可以读取命令) /boot 启动目录，启动相关文件 /dev 设备文件保存目录 /etc 配置文件保存目录 /home 普通用户的家目录 /lib 系统库保存目录 /mnt 系统挂载目录 /media 挂载目录 / root 超级用户的家目录 /tmp 临时目录 /sbin 命令保存目录（超级用户才能使用的目录） /proc 直接写入内存的 /sys /user 系统软件资源目录 /user/bin/系统命令 （普通用户） /user/sbin/系统命令 （超级用户） /var 系统相关文档内容 链接命令链接命令：ln 123456789101112131415ln -s [原文件] [目标文件]命令英文原意：link功能描述：生成链接文件 选项： -s 创建软连接硬链接的特征： 1.拥有相同的i节点和存储block块，可以看做同一个文件 2.可通过i节点识别 3.不能跨分区 4.不能针对目录使用软连接特征 1.类似windows快捷方式 2.软链接拥有自己的i节点和block块，但数据块只保存原文件的文件名和i节点，并没有实际的文件数据 3.lrwxrwxrwx l软连接，软连接的文件权限都是lrwxrwxrwx 4.修改任意文件，另一个都改变 5.删除原文件，软连接不能使用 文件搜索命令locate命令格式1234567891011121314151617181920212223locate 文件名在后台数据库中按文件名搜索，搜索速度更快./var/lib/mlocate# locate命令所搜索的后台数据库updatedb更新数据库updatedb的配置文件/etc/updatedb.confcat /etc/updatedb.conf PRUNE_BIND_MOUNTS = "yes" PRUNEFS = "9p afs anon_inodefs auto autofs bdev binfmt_misc cgroup cifs coda configfs cpuset debugfs devpts ecryptfs exofs fuse fuse.sshfs fusectl gfs gfs2 gpfs hugetlbfs inotifyfs iso9660 jffs2 lustre mqueue ncpfs nfs nfs4 nfsd pipefs proc ramfs rootfs rpc_pipefs securityfs selinuxfs sfs sockfs sysfs tmpfs ubifs udf usbfs fuse.glusterfs ceph fuse.ceph" PRUNENAMES = ".git .hg .svn" PRUNEPATHS = "/afs /media /mnt /net /sfs /tmp /udev /var/cache/ccache /var/lib/yum/yumdb /var/spool/cups /var/spool/squid /var/tmp /var/lib/ceph" 第一行PRUNE_BIND_MOUNTS="yes"的意思是：是否进行限制搜索。第二行是排除检索的文件系统类型，即列出的文件系统类型不进行检索。第三行表示对哪些后缀的文件排除检索，也就是列在这里面的后缀的文件跳过不进行检索。不同后缀之间用空格隔开。第四行是排除检索的路径，即列出的路径下的文件和子文件夹均跳过不进行检索。updatedb之后使用locate仍然找不到想要文件可以检查挂载的目录是否被忽略了 命令搜索命令whereis与which123456789whereis 命令名 # 搜索命令所在路径及帮助文档所在位置选项： -a： 查看所有的选项 -b： 只查找可执行文件 -m： 只查找帮助文件which 命令名$PATH :系统环境 文件搜索命令find1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950find [搜索范围] [搜索条件]# 搜索文件find / -name main.go# 避免大范围搜索，会非常耗费系统资源# find是在系统当中搜索符合条件的文件名，如果需要匹配，使用通配符匹配，通配符是完全匹配linux的通配符* 匹配任意内容？ 匹配任意一个字符[] 匹配任意一个括号内的字符find /root -iname main.go# 不区分大小写find /root -user root# 按照所有者搜索find /root -nouser# 查找没有所有者的文件find /var/log/ -mtime +10# 查找10天前修改的文件-10 10天内修改的文件10 10天当天修改的文件+10 10天前修改的文件atime 文件访问时间ctime 改变文件属性mtime 修改文件内容find . -size 25k# 查找当前目录大小是25kb的文件-25k 小于25kb的文件25k 等于25kb的文件+25k 大于25kb的文件find . inum 262422# 查找i节点是262422的文件find /etc -size +20k -a -size -50k# 查找/etc目录下，大于20kb并且小于50kb的文件-a and 逻辑与，两个条件都满足-o or 逻辑或，两个条件满足一个即可find /etc -size +20k -a -size -50k -exec ls -lh &#123;&#125;\;# 查找/etc目录下，大于20kb并且小于50kb的文件，并显示详细信息# -exec/-ok 命令 &#123;&#125;\; 对搜索结果执行操作 字符串搜索命令grep123456789grep [选项] 字符串 文件名# 在文件当中匹配符合条件的字符串选项： -i 忽略大小写 -v 取反find命令和grep命令的区别find命令：在系统当中搜索符合条件的文件名，如果匹配，使用通配符，通配符是完全匹配grep命令：在文件中搜索符合条件的字符串，如果需要匹配，使用正则进行匹配，正则表达式包含匹配 帮助命令帮助命令man12345678910111213141516171819202122232425man 命令# 获取指定命令帮助man ls# 查看ls的帮助man的级别1： 查看命令的帮助2： 查看可被内核调用的函数的帮助3： 查看函数和函数库的帮助4： 查看特殊文件的帮助（主要是/dev目录下的文件）5： 查看配置文件的帮助6： 查看游戏的帮助7： 查看其它杂项的帮助8： 查看系统管理员可用命令的帮助9： 查看内核相关的帮助man f 命令 == whatis 命令# 查看命令有几个级别man -1 passwd# 查看passwd命令帮助apropos 命令# 查看所有包含该命令帮助 其他帮助命令123456789101112131415161718192021命令 --help# 获取命令选项的帮助例如： ls --helphelp shell内部命令# 获取shell 内部命令的帮助例如 whereis cd # 确定是否是shell内部命令 help cd # 获取内部命令的帮助info 命令 -回车： 进入子帮助页面（带有*号标记） -u： 进入上一层页面 -n： 进入下一层帮助小节 -p： 进入上一个帮助小节 -q： 退出 压缩与解压缩命令常用压缩格式：.zip .gz .bz2 .tar.gz .tar.bz2 .zip压缩格式12345678zip 压缩文件名 原文件# 压缩文件zip -r 压缩文件名 源目录# 压缩目录unzip 压缩文件# 解压缩 .zip文件 .gz格式压缩123456789101112131415gzip 原文件# 压缩为.gz格式的压缩文件，源文件会消失gzip -c 源文件 &gt; 压缩文件# 压缩为.gz格式，源文件保留# 例如 gzip -c cangls &gt; cangls.gzgzip -r 目录# 压缩目录下所有的子文件，但是不能压缩目录gzip -d 压缩文件# 解压缩文件gunzip 压缩文件# 解压缩文件 .bz2格式压缩12345678910111213bzip2 源文件# 压缩为.bz2格式，不保留源文件bzip2 -k 源文件# 压缩之后保留源文件### bzip2命令不能压缩目录bzip2 -d 压缩文件# 解压缩 -k保留压缩文件bunzip2 压缩文件# 解压缩 -k保留压缩文件 打包命令tar123456789101112131415# 压缩tar -cvf 打包文件名 源文件选项： -c 打包 -v 显示过程 -f 指定打包后的文件名例如： tar -cvf login.tar login# 解压tar -xvf 打包文件名选项： -x 解打包例如： tar -xvf login.tar .tar.gz压缩格式1234567压缩tar -zcvf 压缩包名.tar.gz 源文件选项： -z 压缩为.tar.gz格式tar -zxvf 压缩包名.tar.gz选项： -x 解压缩.tar.gz格式 .tar.bz2压缩格式12345678910111213141516压缩tar -jcvf 压缩包名.tar.bz2 源文件选项： -j 压缩为.tar.bz2格式 tar -jcvf /tmp/压缩包名.tar.bz2 源文件# 压缩到指定目录下解压缩tar -jxvf 压缩包名.tar.bz2选项： -x 解压缩.tar.bz2格式 -t 测试一下，压缩包中有什么tar -jxvf 压缩包名.tar.bz2 -C /tmp/...# 指定解压缩位置 关机和重启命令shutdown命令1234567891011121314151617181920212223# 关机命令shutdown [选项] 时间选项： -c 取消前一个关机命令 -h 关机 -r 重启haltpoweroffinit 0# 重启命令rebootinit 6# 查看当前系统运行级别runlevel# N：代表在进入3之前的级别 3：代表多用户# 修改系统默认运行级别cat /etc/inittab# 退出登录logout 系统运行级别 0 关机 1 单用户 2 不完全多用户，不含NFS服务 3 完全多用户 4 未分配 5 图形界面 6 重启 其他常用命令挂载命令12345678910111213141516171819202122232425262728293031323334351.查询与自动挂载mount# 查询系统中已经挂载的设备mount -a# 依据配置文件/etc/fstab内容自动挂载2.挂载命令格式mount [-t 文件系统] [-o 特殊选项] 设备文件名 挂载点选项： -t 文件系统：加入文件系统类型来指定挂载类型，可以ext3，ext4，iso9660等文件系统 -o 特殊选项：可以指定挂载的额外选项 3.挂载光盘mkdir /mnt/cdrom/# 建立挂载点mount -t iso9660 /dev/cdrom /mnt/cdrom/# 挂载光盘mount /dev/sr0 /mnt/cdrom/# 挂载光盘4.卸载命令umount 设备文件名或挂载点umount /mnt/cdrom5.挂载u盘fdisk -l# 查看U盘设备名称mount -t vfat /dev/sdb1 /mnt/usb/# 注意：Linux默认是不支持NTFS文件系统的 用户登录查看12345678910111213141516171819202122232425w 用户名命令输出： USER 登录的用户名 TTY 登录终端 FROM 从哪个ip地址登录的 LOGIN@ 登录时间 IDLE 用户闲置时间 JCPU 指的是该终端连接的所有进程占用的时间，这个时间并不包括过去的后台作业时间，但却包括当前正在运行的后台作业所占用的时间 PCPU 是指当前进程所占用的时间 WGAT 当前正在运行的命令who命令输出 用户名 登录终端 登录时间（登录来源ip地址）last和lastloglast命令默认读取/var/log/wtmp文件数据命令输出 用户名称 登录终端 登录ip 登录时间 退出时间（在线时间）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[devops导论]]></title>
    <url>%2F2019%2F02%2F06%2Fdevops%E5%AF%BC%E8%AE%BA-1%2F</url>
    <content type="text"><![CDATA[DevOps概述个体软件过程敏捷软件开发软件架构演化云原生和容器技术Xaas和IT服务标准DevOps工具链]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[devops导论]]></title>
    <url>%2F2019%2F02%2F06%2Fdevops%E5%AF%BC%E8%AE%BA%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[DevOps和云计算的初识]]></title>
    <url>%2F2019%2F02%2F06%2FDevOps%E5%92%8C%E4%BA%91%E8%AE%A1%E7%AE%97%E7%9A%84%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[什么是云计算云计算跟云没有任何关系 虚拟化（Virtualization）是基础（计算，存储，网络等） 产品服务化（laas，Paas，Saas，Xaas） 弹性伸缩，没有边界 云计算分类 公有云（Aws，阿里云，Azure等） 私有云（Vmware等） 混合云（Azure，Rackspace） 公有云 云服务提供商对基础设施维护 多租户 Pay For Use 私有云 自己维护基础措施 单租户或狭义上的多租户 Pay For Cloud 混合云(专属云) 云服务提供商维护自己的云设施 用户范围内租户隔离 Pay For Use of Cloud 什么是DevOps DevOps = Development + Operations 极速的迭代和快速的用户反馈]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习的基本了解]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BA%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[机器学习的目标​ 机器学习是实现人工智能的手段,其主要研究内容时如何利用数据或经验进行学习,改善算法的性能 多领域交叉,涉及概率论、统计学、算法复杂度理论等多门学科 广泛应用于网络搜索、垃圾邮件过滤、推荐系统、广告投放、信用评价、欺诈检测、股票交易和医疗诊断等应用 机器学习的分类 监督学习（Supervised Learning） 无监督学习（Unsupervised Learning） 强化学习（Reinforcement Learning，增强学习） 半监督学习（Semi-supervised Learning） 深度学习（Deep learning） 机器学习模块Scikit-learn 一组简单有效的工具集 依赖python 的Numpy，scipy和matplotlib库 开源和可复用的 Scikit-learn常用函数 应用（Applications） 算法（Algorithm） 分类（Classification） 异常检测，图像识别等 KNN，SVM，etc 聚类（Clustering） 图像分割，群体划分，等 K-Means，谱聚类，etc 回归（Regression） 价格预测，趋势预测，等 线性回归，SVR，etc 降维（Dimension Reduction） 可视化 PCA，NMF，etc sklearn库sklearn是scikit-learn的简称，是一个基于python的第三方模块，sklearn库集成了一些常见的机器学习方法，在进行机器学习任务时，并不需要实现算法，只需要简单的调用sklearn库中提供的模块就能完成大多数的机器学习任务 sklearn库是在Numpy，scipy和matplotlib的基础上开发而成的，因此在安装sklearn之前，请先安装这些依赖库 12# 安装Scikit-learn模块,pip会自动安装其他模块pip3 install Scikit-learn sklearn库的基本功能sklearn库共分为6大部分,分别用于完成分类任务,回归任务,聚类任务,降维任务,模型选择以及数据的预处理 分类任务 分类模型 加载模块 最近邻算法 from sklearn.neighbors import NearestNeighbors 支持向量机 from sklearn.svm import SVC 朴素贝叶斯 from sklearn.naive_bayes import GaussianNB 决策树 from sklearn.tree import DecisionTreeClassifier 集成方法 from sklearn.ensemble import BaggingClassifier 神经网络 from sklearn.neural_network import MLPClassifier 回归任务 回归模型 加载模块 岭回归 from sklearn.linear_model import Ridge Lasso回归 from sklearn.linear_model import Lasso 弹性网络 from sklearn.linear_model import ElasticNet 最小角回归 from sklearn.linear_model import Lars 贝叶斯回归 from sklearn.linear_model import BayesianRidge 逻辑回归 from sklearn.linear_model import LogisticRegression 多项式回归 from sklearn.preprocessing import PolynomialFeatures 聚类任务 聚类方法 加载模块 K-means from sklearn.cluster import KMeans AP聚类 from sklearn.cluster import AffinityPropagation 均值漂移 from sklearn.cluster import MeanShift 层次聚类 from sklearn.cluster import AgglomerativeClustering DBSCAN from sklearn.cluster import DBSCAN BIRCH from sklearn.cluster import Birch 谱聚类 from sklearn.cluster import SpectralClustering 降维任务 降维方法 加载模块 主成分分析 from sklearn.decomposition import PCA 截断SVD和LSA from sklearn.decomposition import TruncatedSVD 字典学习 from sklearn.decomposition import SparseCoder 因子分析 from sklearn.decomposition import FactorAnalysis 独立成分分析 from sklearn.decomposition import FastICA 非负矩阵分解 from sklearn.decomposition import NMF LDA from sklearn.decomposition import LatentDirichletAllocation]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习之有监督学习]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[机器学习之无监督学习]]></title>
    <url>%2F2019%2F01%2F28%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[无监督学习的目标利用无标签的数据学习数据的分布或数据与数据之间的关系被称作为无监督学习 有监督学习与无监督学习最大的区别在于数据是否有标签 无监督学习最常用的场景是聚类和降维 聚类聚类,就是根据数据的”相似性”将数据分为多类的过程 评估两个不同样本之间的相似性,通常使用的方法就是计算两个样本之间的距离,使用不同的方法计算样本间的距离会关系到聚类结果的好坏 欧式距离欧式距离是最常用的一种距离度量方法,源于欧式空间中两点之间的距离 曼哈顿距离曼哈顿距离也称作”城市街区距离”,类似于在城市之中驾车行驶,从一个十字路口到另一个十字路口的距离 马氏距离马氏距离表示数据的协方差距离,是一种尺度无关的度量方式也就是说马氏距离会先将样本点的各个属性标准化,再计算样本间的距离 夹角余弦余弦相似度用向量空间中两个向量夹角的余弦作为衡量两个样本差异的大小,余弦越接近1,说明两个向量夹角越接近0度,表明两个向量越相似 降维降维,就是在保证数据所具有代表性特征或分布的情况下,将高维数据转化为低维数据的过程 数据可视化 精简数据 sklearn.decomposition 算法名称 参数 可扩展性 适用任务 PCA 所降维度和其他超参 大规模数据 信号处理 FastICA 所降维度和其他超参 超大规模数据 图形图像特征提取 NMF 所降维度和其他超参 大规模数据 图形图像特征提取 LDA 所降维度和其他超参 大规模数据 文本数据,主题挖掘 K-means聚类算法k-means算法以k为参数,把N个对象分为k个簇,使簇内具有较高的相似度,而簇间的相似度较低 随机选择k个点作为初始的聚类中心 对于剩下的点,根据与聚类中心的距离,将其归为最近的簇 对每个簇,计算所有点的均值作为新的聚类中心 重复2,3直到聚类中心不再发生改变]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim的使用]]></title>
    <url>%2F2019%2F01%2F16%2Fvim%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[常用指令底行模式常用指令 ：w 写 ：q 退出 ：！ 强制 ：ls 列出打开的所有文件 ：n 切换到后一个文件 ：N 切换到上一个文件 ：15 跳到15行 /xxx 向后搜索 ？xxx 向前搜索 命令模式常用指令 h 光标左移 j 光标下移 k 光标上移 l 光标右移 ctrl + f 向下翻页（front） ctrl + b 向上翻页（back） ctrl + d 向下翻半页（down） ctrl + u 向上翻半页（up） dd 删除光标所在行 o 在光标所在行的下方插入一行并切换到输入模式 yy 复制光标所在的行 p 在光标所在行的下方粘贴 P 在光标所在行的上方粘贴 打造自己的vim123456789101112131415161718192021# 常用设置# 设置行号set number# 设置主题colorscheme hybrid# 按f2进入粘贴模式set pastetoggle=&lt;F2&gt;# 高亮搜索set hlsearch# 设置折叠方式set foldmethod=indent# 常用映射# 使用jj进入normal 模式inoremap jj &lt;Esc&gt;`^# 插件设置call plug#begin() 设置分4部分 常用设置 常用映射 插件的安装和配置 自定义函数（vimscript）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础数据结构]]></title>
    <url>%2F2019%2F01%2F16%2F%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[什么是数据结构 数据结构是指相互之间存在着一种或多种关系的数据元素的集合和该集合中数据元素之间的关系组成。 简单来说，数据结构就是设计数据以何种方式组织并存储在计算机中。比如：列表、集合与字典等都是一种数据结构。 N.Wirth: “程序=数据结构+算法” 数据结构的分类 数据结构按照其逻辑结构可分为线性结构、树结构、图结构 线性结构：数据结构中的元素存在一对一的相互关系 树结构：数据结构中的元素存在一对多的相互关系 图结构：数据结构中的元素存在多对多的相互关系 列表 列表：在其他编程语言中称为“数组”，是一种基本的数据结构类型 关于列表的问题 列表中元素使如何存储的？ 列表提供了哪些基本的操作？ 这些操作的时间复杂度是多少？ 栈 栈(Stack)是一个数据集合，可以理解为只能在一端进行插入或删除操作的列表 栈的特点：后进先出（last-in, first-out） 栈的概念： 栈顶 栈底 栈的基本操作 进栈（压栈）：push 出栈：pop 取栈顶：gettop 栈的python实现 不需要自己定义,使用列表结构即可 进栈函数:append() 出栈函数:pop 查看栈顶函数:li[-1] 队列 队列(Queue)是一个数据集合，仅允许在列表的一端进行插入，另一端进行删除 进行插入的一端称为队尾(rear)，插入动作称为进队或入队 进行删除的一端称为队头(front)，删除动作称为出队 队列的性质：先进先出(First-in, First-out) 双向队列：队列的两端都允许进行进队和出队操作 队列的实现 初步设想:列表+两个下标指针 创建一个列表和两个变量,front变量指向队首,rear变量指向队尾,初始时,front和rear都为0 进队操作:元素写到li[rear]的位置,rear自增1 出队操作:返回li[front]的元素,front自增1 环形队列 环形队列：当队尾指针front == Maxsize + 1时，再前进一个位置就自动到0。 实现方式：求余数运算 队首指针前进1：front = (front + 1) % MaxSize 队尾指针前进1：rear = (rear + 1) % MaxSize 队空条件：rear == front 队满条件：(rear + 1) % MaxSize == front 队列的内置模块 使用方法:from collections import deque 创建队列：queue = deque(li) 进队：append 出队：popleft 双向队列队首进队：appendleft 双向队列队尾出队：pop 链表 链表中每一个元素都是一个对象，每个对象称为一个节点，包含有数据域key和指向下一个节点的指针next。通过各个节点之间的相互连接，最终串联成一个链表。 节点定义 1234class Node(object): def __init__(self, item=None): self.item = item self.next = None 头插法 1234567def createLinkList(li): l = Node() for num in li: s = Node(num) s.next = l.next l.next = s return l 尾插法 12345678def create_linklist_tail(li): head = Node() tail = head for val in li: p = Node(val) tail.next = p tail = p return head 链表节点的插入 12p.next = curNode.nextcurNode.next = p 链表的删除 123p = curNode.nextcurNode.next = curNode.next.nextdel p 双链表 双链表中每个节点有两个指针：一个指向后面节点、一个指向前面节点 节点定义 12345class Node(object): def __init__(self, item=None): self.item = item self.next = None self.prior = None 双链表节点的插入 1234p.next = curNode.nextcurNode.next.prior = pp.prior = curNodecurNode.next = p 双链表节点的删除 1234p = curNode.nextcurNode.next = p.nextp.next.prior = curNodedel p 链表-复杂度分析 列表和链表 按元素值查找 按下标查找 在某元素后插入 删除某元素 链表在插入和删除的操作上明显快于顺序表 链表的内存可以更灵活的分配 试利用链表重新实现栈和队列 链表这种链式存储的数据结构对树和图的结构有很大的启发性 哈希表 哈希表一个通过哈希函数来计算数据存储位置的数据结构，通常支持如下操作： insert(key, value)：插入键值对(key,value) get(key)：如果存在键为key的键值对则返回其value，否则返回空值 delete(key)：删除键为key的键值对 直接寻址表 当关键字的全域U比较小时，直接寻址是一种简单而有效的方法。 直接寻址法技术缺点 当域U很大时,需要消耗大量内存,很不实际 如果域U很大而时间出现的key很少,则大量空间被浪费 无法处理关键字不是数字的情况 哈希 直接寻址表：key为k的元素放到k位置上 改进直接寻址表：哈希（Hashing） 构建大小为m的寻址表T key为k的元素放到h(k)位置上 h(k)是一个函数，其将域U映射到表T[0,1,…,m-1]]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十大基础算法]]></title>
    <url>%2F2019%2F01%2F16%2F%E5%8D%81%E5%A4%A7%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[什么是算法?算法(Algorithm):一个计算过程,解决问题的方法时间复杂度 时间复杂度 :用来评估算法运行效率的一个东西 一般来说,时间复杂度高的算法比时间复杂度低的算法慢 常见的时间复杂度(按照效率排序 O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n2)&lt;O(n2logn)&lt;O(n3) 不常见的时间复杂度 O(n!) O(2n) O(nn)…. 如何一眼判断时间复杂度 循环减半的过程O(logn) 几次循环就是n的几次方的复杂度 12345678910print('hello World') # O(1)for i in range(n): # O(n) print('hello world')for i in range(n): #O(n²) for j in range(n): print('hello world')for i in range(n): #O(n³) for j in range(n): for k in range(n): print('hello world') 空间复杂度空间复杂度: 用来评估算法内存占用大小的一个式子 二分查找代码: 123456# 普通的查找方式def linear_search(data_set,value): for i in range(len(data_set)): # 时间复杂度是O(n) if data_set[i] == value: return i return 1234567891011121314151617181920212223242526# 二分查找# 循环版本def bin_search(data_set,value): low = 0 high = len(data_set) - 1 while low &lt;= high: mid = (low + high) // 2 if data_set[mid] == value: # 时间复杂度O(logn) return mid elif data_set[mid] &gt; value: high = mid-1 else: low = mid + 1# 递归版本def bin_search_rec(data_set,value,low,high): if low &lt;= high: mid = (low + high) // 2 if data_set[mid] == value: return mid elif data_set[mid] &gt; value: return bin_search_rec(data_set,value,low,mid-1) else: return bin_search_rec(data_set,value,mid+1,high) else: return 冒泡排序冒泡排序思路: 首先,列表两个相邻的数,如果前边的比后边的大,那么交换这两个数,如果不大,那就不需要交换 代码关键点: 1.趟 2.无序区 12345678910111213141516171819​```python# 冒泡算法 时间复杂度:O(n²)def bubble_sort(li): for i in range(len(li)): for j in range(i+1,len(li)): if li[i] &gt; li[j]: li[i], li[j] = li[j], li[i]# 冒泡算法优化# 如果冒泡排序中执行一趟而没有交换，则列表已经是有序状态，可以直接结束算法def bubble_sort(li): for i in range(len(li)): exchange = False for j in range(i+1,len(li)): if li[i] &gt; li[j]: li[i], li[j] = li[j], li[i] exchange = True if not exchange: return ​ 1234567891011121314151617181920## 选择排序**选择排序思路:** - 一趟遍历记录最小的数放在第一个位置- 再一趟遍历记录剩余列表中最小的数，继续放置**代码关键点:** 1.无序区 2.最小数的位置```python# 选择排序代码 时间复杂度:O(n²)def select_sort(li): for i in range(len(li)): min_loc = i for j in range(i+1,len(li)): if li[j] &lt; li[min_loc]: min_loc = j if min_loc != i: li[i],li[min_loc] = li[min_loc],li[i] 插入排序插入排序思路 ​ 列表被分为有序区和无序区两部分,最初有序区只有一个元素 ​ 每次从无序区选择一个元素,插入到有序区的位置,直到无序区变空 123456789# 插入排序代码 时间复杂度O(n²)def insert_sort(li): for i in range(1,len(li)): tmp = li[i] j = i - 1 while j&gt;=0 and tmp &lt; li[j]: li[j+1] = li[j] j -= 1 li[j+1] = tmp 快速排序快速排序思路 1.取一个元素p(第一个元素),使元素p归为 2.列表被p分为两部分,左边比p小,右边比p大 3..递归完成排序 1234567891011121314151617# 快速排序 时间复杂度O(nlogn)def quick_sort(data,left,right): if left &lt; right: mid = partition(data,left,right) quick_sort(data,left,mid-1) quick_sort(data,mid+1,right)def partition(data,left,right): tmp = data[left] while left &lt; right: while left &lt; right and data[right] &gt;= tmp: right -= 1 data[left] = data[right] while left &lt; right and data[left] &lt;= tmp: left += 1 data[right] = data[left] data[left] = tmp return left 堆排序树与二叉树的简介 树是一种数据结构 比如：目录结构 树是一种可以递归定义的数据结构 树是由n个节点组成的集合： 如果n=0，那这是一棵空树； 如果n&gt;0，那存在1个节点作为树的根节点，其他节点可以分为m个集合，每个集合本身又是一棵树。 一些概念: 根节点、 叶子节点树的深度（高度） 树的度孩子节点/父节点 子树 两种特殊二叉树 满二叉:一个二叉树，如果每一个层的结点数都达到最大值，则这个二叉树就是满二叉树。 完全二叉树：叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树。 二叉树的存储方式: 链式存储方式 顺序存储方式(列表) 父节点和左孩子节点的编号下标有什么关系？ 2i+1 i:代表下标 父节点和右孩子节点的编号下标有什么关系？ 2i+2 堆排序 堆: 大根堆：一棵完全二叉树，满足任一节点都比其孩子节点大 小根堆：一棵完全二叉树，满足任一节点都比其孩子节点小 堆的向下调整性质: 假设:节点的左右子树都是堆，但自身不是堆 当根节点的左右子树都是堆时，可以通过一次向下的调整来将其变换成一个堆 堆排序过程: 建立堆 得到堆顶元素，为最大元素 去掉堆顶，将堆最后一个元素放到堆顶，此时可通过一次调整重新使堆有序。 堆顶元素为第二大元素。 重复步骤3，直到堆变空。 1234567891011121314151617181920212223# 堆排序代码 时间复杂度O(nlogn)def sift(data,low,high): i = low j = 2 * i +1 tmp = data[i] while j &lt;= high: if j &lt; high and data[j] &lt; data[j+1]: j += 1 if tmp &lt; data[j]: data[i] = data[j] i = j j = 2*i+1 else: break data[i] = tmp def heap_sort(data): n = len(data) for i in range(n//2-1,-1,-1): sift(data,i,n-1) for i in range(n-1,-1,-1): data[0],data[i] = data[i],data[0] sift(data,0,i-1) 堆排序–内置模块 优先队列：一些元素的集合，POP操作每次执行都会从优先队列中弹出最大（或最小）的元素。 堆——优先队列 Python内置模块——heapq heapify(x) heappush(heap, item) heappop(heap) 利用heapq模块实现堆排序 123456import heapqdef heapsort(li): h = [] for value in li: heappush(h, value) return [heappop(h) for i in range(len(h))] 归并排序假设现在的列表分两段有序，将其合成为一个有序列表,这种操作称为一次归并 123456789101112131415161718192021222324252627# 归并排序 时间复杂度O(logn) 空间复杂度:O(n)def merge(li,low,mid,high): li_tmp = [] i = low j = mid + 1 while i &lt;= mid and j &lt;= high: if li[i] &lt; li[j]: li_tmp.append(li[i]) i += 1 else: li_tmp.append(li[j]) j += 1 while i &lt;= mid: li_tmp.append(li[i]) i += 1 while j &lt;= high: li_tmp.append(li[j]) j += 1 for i in range(len(li_tmp)): li[i+low] = li_tmp[i]def merge_sort(li,low,high): if low &lt; high: mid = (low + high) // 2 merge_sort(li,low,mid) merge_sort(li,mid+1,high) merge(li,low,mid,high) 归并排序实现思路: 分解：将列表越分越小，直至分成一个元素。 终止条件：一个元素是有序的。 合并：将两个有序列表归并，列表越来越大 总结: 一般情况下，就运行时间而言：快速排序 &lt; 归并排序 &lt; 堆排序 三种排序算法的缺点： 快速排序：极端情况下排序效率低 归并排序：需要额外的内存开销 堆排序：在快的排序算法中相对较慢 希尔排序希尔排序思路: 希尔排序是一种分组插入排序算法 首先取一个整数d1=n/2，将元素分为d1个组，每组相邻量元素之间距离为d1，在各组内进行直接插入排序 取第二个整数d2=d1/2，重复上述分组排序过程，直到di=1，即所有元素在同一组内进行直接插入排序。 希尔排序每趟并不使某些元素有序，而是使整体数据越来越接近有序；最后一趟排序使得所有数据有序 123456789101112# 希尔排序 希尔排序的时间复杂度讨论比较复杂，并且和选取的gap序列有关。def shell_sort(li): gap = len(li) // 2 while gap &gt; 0: for i in range(gap,len(li)): tmp = li[i] j = i-gap while j &gt;= 0 and tmp &lt; li[j]: li[j + gap] = li[j] j -= gap li[j+gap] = tmp gap //= 2 计数排序现在有一个列表，已知列表中的数范围都在0到100之间。设计算法在O(n)时间复杂度内将列表进行排序。 创建一个列表，用来统计每个数出现的次数 123456789101112def count_sort(li,max_num): count = [0 for i in range(max_num+1)] for num in li: count[num] += 1 i = 0 for num , m in enumerate(count): for j in range(m): li[i] = num i += 1li = [1,2,3,4,5,8,6,3,2,1,4]count_sort(li,8)print(li) 桶排序 在计数排序中，如果元素的范围比较大（比如在1到1亿之间），如何改造算法？ 桶排序(Bucket Sort)：首先将元素分在不同的桶中，在对每个桶中的元素排序。 桶排序的表现取决于数据的分布。也就是需要对不同数据排序时采取不同的分桶策略。 平均情况时间复杂度：O(n+k) 最坏情况时间复杂度：O(n2k) 空间复杂度：O(nk) 基数排序 多关键字排序：加入现在有一个员工表，要求按照薪资排序，年龄相同的员工按照年龄排序。 先按照年龄进行排序，再按照薪资进行稳定的排序。 对32,13,94,52,17,54,93排序，是否可以看做多关键字排序？ 12345678910111213141516171819202122232425# 基数排序 # 时间复杂度 O(kn)# 空间复杂度:O(k+n)# k表示数字位数def list_to_bucket(li, i): buckets = [[] for _ in range(10)] for val in li: digit = val // (10 ** i) % 10 buckets[digit].append(val) return bucketsdef bucket_to_list(buckets): li = [] for bucket in buckets: for val in bucket: li.append(val) return lidef radix_sort(li): max_val = max(li) i = 0 while 10 ** i &lt;= max_val: li = bucket_to_list(list_to_bucket(li, i)) i += 1 return li]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode的刷题(1-50)]]></title>
    <url>%2F2019%2F01%2F16%2FLeetCode%E7%9A%84%E5%88%B7%E9%A2%98-1-50%2F</url>
    <content type="text"></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基础命令]]></title>
    <url>%2F2019%2F01%2F16%2Flinux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[查看版本信息 cat /etc/redhat-release :查看版本信息 uname -r 查看内核版本号 uname -m 查看系统多少位 uname -a 查看内核全部信息 IP相关查看ip ip addr ifconfig ip详细信息 eth0 网卡的代号 lo 回环地址loopback inet IPv4的Ip地址 netmask 子网掩码 broadcast 广播地址 RX/TX 流量发/收情况 tx是发送（transport），rx是接收(receive) packets 数据包数 errors 数据包错误数 dropped 数据包有问题被丢弃的数量 collisions 数据包碰撞情况，数值太多代表网络状况差 ifup,ifdown 脚本命令,更简单的方式启动关闭网络 pup + 网卡名 ipdown + 网卡名 # 编辑网卡配置文件 vim /etc/sysconfig/network-scripts/ifcfg-eth0 # 修改配置参数 ONBOOT=yes 关闭防火墙 systemctl stop / start / restart firewalld 关闭/开启/重启 防火墙 systemctl disable firewalld 永久关闭防火墙 修改网络配置 systemctl restart network 重启服务 linux的目录结构 根目录 linux的文件系统 Ext3 : 是一款日志文件系统，能够在系统异常宕机时避免文件系统资料丢失，并能 自动修复数据的不一致与错误。 Etx4:Etx3的进阶版本,作为 RHEL 6 系统中的默认文件管理系统，它支持的存储容 量高达 1EB(1EB=1,073,741,824GB)，且能够有无限多的子目录。另外，Ext4 文件系统能够批量分配 block 块，从而极大地提高了读写效率。 XFS 是一种高性能的日志文件系统，而且是 RHEL 7 中默认的文件管理系统，它的优势在发生意外宕机后尤其明显，即可以快速地恢复可能被破坏的文件，而且强大的 日志功能只用花费极低的计算和存储性能。并且它最大可支持的存储容量为 18EB， 这几乎满足了所有需求。 查看linux的文件系统 cat /etc/fstab 创建文件夹 mkdir -p 文件名 查看目录 ls /目录名 stat 文件名:查看详细信息 创建文本 touch 文件名 改变当前的位置 cd /目录名 cd ~ :家目录 cd - :返回上一次的地址 打印当前目录 pwd 查看文本 cat -n 文件 :带行号 cat &gt;&gt; 文件 &lt;&lt; EOF …. EOF more 查看文件百分比 head 查看前10行 tail 查看后10行 tail -f 动态监听文件 linux快捷键 快捷键 说明 tab键 自动补全代码 ctrl + l 清理终端显示 clear / cls 清理终端显示 ctrl + c 终止操作 echo命令 echo $PATH :打印环境变量 特殊符号 “&gt;&gt;” 追加重定向 “&gt;” 清空重定向 “*” 通配符 复制 cp -r 递归,复制目录以及目录的子孙后代 cp -p 复制文件,且保持文件属性不变 cp -a :相当于-pdr 移动 mv 删除 rm -f 不需要提示,强制删除 rm -rf :全删 xargs命令 xargs命令是给其他命令传递参数的一个过滤器，擅长将标准输入数据转换成命令行参数，xargs能够处理管道或者stdin并将其转换成特定命令的参数。 xargs默认命令是echo，空格是默认定界符 查找命令 find 在哪里(目录) -type f -name ‘*.txt’ 找到所有txt文件 find / -name *.txt 管道命令 Linux提供的管道符“|”讲两条命令隔开，管道符左边命令的输出会作为管道符右边命令的输入。 命令格式:命令A|命令B grep(过滤) 文本搜素 grep ‘xxx’ 文件 -i:忽略大小写 -n:输出行号 -v:反向选择 sed(流编辑器) 用法 文本替换 sed -i ‘s/old/new/g’ 文件:把这文件里的全部old替换为new 删除空白行 sed -i ‘/^$/d’ 文件名 :把这个文件里全部的空行删除 删除5-10行内容 sed -i ‘5,10d’ 文件名 akw 语法: awk [option] ‘script’ var = value filename awk [options] -f scriptfile var=value filename 常用选项 -F fs fs指定输入分隔符，fs可以是字符串或正则表达式，如-F: -v var=value 赋值一个用户定义变量，将外部变量传递给awk -f scripfile 从脚本文件中读取awk命令 -m[fr] val 对val值设置内在限制，-mf选项限制分配给val的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。 实例 # NR &gt; 行号 awk ‘NR==20,NR==30’ /tmp/oldboy.txt which命令 which命令用于查找并显示给定命令的绝对路径，环境变量PATH中保存了查找命令时需要遍历的目录。 which指令会在环境变量$PATH设置的目录里查找符合条件的文件。 也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 which pwd which python 别名alias 设置别名 alias rm = ‘echo “别用rm”‘ 取消设置:unalias rm seq(类似于for循环) seq -f ‘%03g’ 起始值 终止值 scp远程复制文件 语法: scp 【可选参数】 本地源文件 远程文件标记 参数 -r :递归复制整个目录 -v:详细方式输出 -q:不显示传输进度条 -C：允许压缩 事例 传输本地文件到远程地址 scp 本地文件 远程用户名@远程ip:远程文件夹/ 复制远程文件到本地 scp root@192.168.1.155:/home/oldboy.txt /tmp/oldboy.txt du命令 显示目录和文件大小 实例: du -sh 文件名 top top命令用于动态地件事进程活动与系统负载等信息 第一行 (uptime) 系统时间 主机运行时间 用户连接数(who) 系统1，5，15分钟的平均负载 第二行:进程信息 进程总数 正在运行的进程数 睡眠的进程数 停止的进程数 僵尸进程数 第三行:cpu信息 1.5 us：用户空间所占CPU百分比 0.9 sy：内核空间占用CPU百分比 0.0 ni：用户进程空间内改变过优先级的进程占用CPU百分比 97.5 id：空闲CPU百分比 0.2 wa：等待输入输出的CPU时间百分比 0.0 hi：硬件CPU中断占用百分比 0.0 si：软中断占用百分比 0.0 st：虚拟机占用百分比 第四行：内存信息（与第五行的信息类似与free命令） 8053444 total：物理内存总量 7779224 used：已使用的内存总量 274220 free：空闲的内存总量（free+used=total） 359212 buffers：用作内核缓存的内存量 第五行：swap信息 8265724 total：交换分区总量 33840 used：已使用的交换分区总量 8231884 free：空闲交换区总量 4358088 cached Mem：缓冲的交换区总量，内存中的内容被换出到交换区，然后又被换入到内存，但是使用过的交换区没有被覆盖，交换区的这些内容已存在于内存中的交换区的大小，相应的内存再次被换出时可不必再对交换区写入。 chattr 给文件加锁,只能写数据,无法删除 chattr +a 文件:给文件加锁 chattr -a 文件:给文件取消锁 lsattr 查看文件的隐藏属性 lsattr 文件名 linux时间同步 date +”%Y-%m-%d %T” 显示当前时间 同步系统时间和硬件时间，可以用hwclock命令 //以系统时间为基准，修改硬件时间 [root@oldboy_python ~ 10:29:07]#hwclock-w //以硬件时间为基准，修改系统时间 [root@oldboy_python ~ 10:29:21]#hwclock-s Ntp时间服务器 ntpdate -u ntp. aliyun. com:更新时间 wget命令 wget 参数 下载地址 开关机命令 reboot 命令用于重启机器 poweroff 用于关闭系统 用户管理和文件权限 用户管理 添加用户 useradd 用户名 :添加用户 passwd 用户名: 增加密码 切换用户 su - 用户名 su命令中间的-号很重要，意味着完全切换到新的用户，即环境变量信息也变更为新用户的信息 查看当前用户 whoami 退出用户 logout ctrl + d 创建用户组 grpupadd 组名 删除用户 -f 强制删除用户 -r 同事删除用户以及家目录 userdel -r 用户名 sudo命令 语法 sudo 【选项】【参数】 -b：在后台执行指令； -h：显示帮助； -H：将HOME环境变量设为新身份的HOME环境变量； -k：结束密码的有效期限，也就是下次再执行sudo时便需要输入密码；。 -l：列出目前用户可执行与无法执行的指令； -p：改变询问密码的提示符号； -s：执行指定的shell； -u&lt;用户&gt;：以指定的用户作为新的身份。若不加上此参数，则预设以root作为新的身份； -v：延长密码有效期限5分钟； -V ：显示版本信息。 编辑/etc/sudoers文件,写入 用户名 ALL=(ALL) ALL # 允许chaoge在任何地方，执行任何命令 文件权限 图片 文件类型 - 一般文件 d 文件夹 l 软连接（快捷方式） b 块设备，存储媒体文件为主 c 代表键盘,鼠标等设备 文件权限 r read可读 w write写入，编辑 x executable 可以执行 查看用户权限命令 id 用户名 需改权限属性 修改属主 chown 属主名 文件名 修改属组 chgrp 属组名 文件名 文件权限 r —- &gt; 4 w ——&gt; 2 x ——-&gt;1 修改权限命令 chmod [身份][参数] [文件] u(user) +(添加) g(group) -(减去) o(other) =(赋值) a(all) 软连接 ln -s 目标文件 软连接名 PS1变量 inux命令提示符由PS1环境变量控制 参数 可以自行调整全局变量/etc/profile文件用于永久生效 PS1=’[\u@\h \W\t]\$’ \d 日期 \H 完整主机名 \h 主机名第一个名字 \t 时间24小时制HHMMSS\T 时间12小时制 \A 时间24小时制HHMM \u 当前用户账号名 \v BASH的版本\w 完整工作目录 \W 利用basename取得工作目录名 # 下达的第几个命令 \$ 提示字符，root为#，普通用户为$ PS1 &gt; 变量名 $PS1 &gt; 查看变量内容 PS1=新内容 重新赋值 在/etc/profile下增加 export PS1=[你要显示的格式,可永久修改] tar解压命令 语法 tar(选项)(参数) -A或–catenate：新增文件到以存在的备份文件； -B：设置区块大小； -c或–create：建立新的备份文件； -C &lt;目录&gt;：这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项。 -d：记录文件的差别； -x或–extract或–get：从备份文件中还原文件； -t或–list：列出备份文件的内容； -z或–gzip或–ungzip：通过gzip指令处理备份文件； -Z或–compress或–uncompress：通过compress指令处理备份文件； -f&lt;备份文件&gt;或–file=&lt;备份文件&gt;：指定备份文件； -v或–verbose：显示指令执行过程； -r：添加文件到已经压缩的文件； -u：添加改变了和现有的文件到已经存在的压缩文件； -j：支持bzip2解压文件； -v：显示操作过程； -l：文件系统边界设置； -k：保留原有文件不覆盖； -m：保留文件不被覆盖； -w：确认压缩文件的正确性； -p或–same-permissions：用原来的文件权限还原文件； -P或–absolute-names：文件名使用绝对名称，不移除文件名称前的“/”号； -N &lt;日期格式&gt; 或 –newer=&lt;日期时间&gt;：只将较指定日期更新的文件保存到备份文件里； –exclude=&lt;范本样式&gt;：排除符合范本样式的文件。 实例 tar -zxvf Python-3.7.0b3.tgz #解压 tar -czvf oldboy.txt.tar.gz oldboy.txt #压缩oldboy.txt 上述命令等于 tar -cvf oldboy.tar oldboy.txt gzip oldboy.tar tar -cf all_pic.tar *.jpg #压缩当前目录所有jpg结尾的文件 tar -xjf xx.tar.bz2 #解压缩bz2结尾的文件 gzip命令(压缩) 语法 -d或–decompress或—-uncompress：解开压缩文件； -f或——force：强行压缩文件。 -h或——help：在线帮助； -l或——list：列出压缩文件的相关信息； -L或——license：显示版本与版权信息； -r或——recursive：递归处理，将指定目录下的所有文件及子目录一并处理； -v或——verbose：显示指令执行过程； 实例 压缩当前目录所有文件为.gz文件 gzip * 把上例中每个压缩的文件解压，并列出详细的信息 gzip -dv * 显示压缩文件的信息，并不解压 gzip -l * 压缩一个tar备份文件，扩展名是tar.gz tar -cf my.tar my_first.py gzip -r my.tar netstat命令 netstat命令用来打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况。 语法: netstat [选项] -t或–tcp：显示TCP传输协议的连线状况； -u或–udp：显示UDP传输协议的连线状况； -n或–numeric：直接使用ip地址，而不通过域名服务器； -l或–listening：显示监控中的服务器的Socket； -p或–programs：显示正在使用Socket的程序识别码和程序名称； -a或–all：显示所有连线中的Socket； ps命令 ps 命令用于查看系统中的进程状态，格式为“ps [参数]”。 参数 -a 显示所有进程 -u 用户以及其他详细信息 -x 显示没有控制终端的进程 Kill命令 kill命令用来删除执行中的程序或工作。kill可将指定的信息送至程序。 选项 -a：当处理当前进程时，不限制命令名和进程号的对应关系； -l &lt;信息编号&gt;：若不加&lt;信息编号&gt;选项，则-l参数会列出全部的信息名称； -p：指定kill 命令只打印相关进程的进程号，而不发送任何信号； -s &lt;信息名称或编号&gt;：指定要送出的信息； -u：指定用户。 9种信号 HUP 1 终端断线 INT 2 中断（同 Ctrl + C） QUIT 3 退出（同 Ctrl + \） TERM 15 终止 KILL 9 强制终止 CONT 18 继续（与STOP相反， fg/bg命令） STOP 19 暂停（同 Ctrl + Z） 实例 先用ps查找进程，然后用kill杀掉： ps -ef | grep vim root 3268 2884 0 16:21 pts/1 00:00:00 vim install.log root 3370 2822 0 16:21 pts/0 00:00:00 grep vim kill 3268 killall命令 通常来讲，复杂软件的服务程序会有多个进程协同为用户提供服务，如果逐个去结束这 些进程会比较麻烦，此时可以使用 killall 命令来批量结束某个服务程序带有的全部进程。 例子 例如nginx启动后有2个进程 killall nginx SELinux功能 大多数ssh连接不上虚拟机，都是因为防火墙和selinux阻挡了 永久关闭 1.修改配置文件，永久生效关闭selinux cp /etc/selinux/config /etc/selinux/config.bak #修改前备份 2.修改方式可以vim编辑,找到 # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled 3.用sed替换 sed -i ‘s/SELINUX=enforcing/SELINUX=disabled/‘ /etc/selinux/config 4.检查状态 grep “SELINUX=disabled” /etc/selinux/config #出现结果即表示修改成功 临时关闭selinux(命令行修改，重启失效)： getenforce #获取selinux状态 #修改selinux状态 setenforce usage: setenforce [ Enforcing | Permissive | 1 | 0 ] 数字0 表示permissive，给出警告，不会阻止，等同disabled 数字1表示enforcing，表示开启 iptables防火墙 centos7默认已经使用firewall作为防火墙了 1.关闭防火墙 systemctl status firewalld #查看防火墙状态 systemctl stop firewalld #关闭防火墙 systemctl disable firewalld#关闭防火墙开机启动 systemctl is-enabled firewalld.service#检查防火墙是否启动 linux中文显示 1.修改配置文件/etc/locale.conf LANG=”zh_CN.UTF-8” 2.更改后查看系统语言变量:locale df 命令 语法: -h或–human-readable：以可读性较高的方式来显示信息； -k或–kilobytes：指定区块大小为1024字节； -T或–print-type：显示文件系统的类型； –help：显示帮助； –version：显示版本信息 tree tree命令以树状图列出目录的内容。 -a：显示所有文件和目录； -A：使用ASNI绘图字符显示树状图而非以ASCII字符组合； -C：在文件和目录清单加上色彩，便于区分各种类型； -d：先是目录名称而非内容； -D：列出文件或目录的更改时间； -f：在每个文件或目录之前，显示完整的相对路径名称； -F：在执行文件，目录，Socket，符号连接，管道名称名称，各自加上”*”，”/“，”@”，”|”号； -g：列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码； -i：不以阶梯状列出文件和目录名称； -l：&lt;范本样式&gt; 不显示符号范本样式的文件或目录名称； -l：如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录； -n：不在文件和目录清单加上色彩； -N：直接列出文件和目录名称，包括控制字符； -p：列出权限标示； -P：&lt;范本样式&gt; 只显示符合范本样式的文件和目录名称； -q：用“？”号取代控制字符，列出文件和目录名称； -s：列出文件和目录大小； -t：用文件和目录的更改时间排序； -u：列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码； -x：将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该目录予以排除在寻找范围外。 tree参数 DNS配置 配置文件 cat /etc/resolv.conf#dns 服务器地址 nameserver 223.5.5.5 nameserver 119.29.29.29 nslookup命令 nslookup命令是常用域名查询工具，就是查DNS信息用的命令。 例子:nslookup www.oldboyedu.com 计划任务crond服务 语法 -e：编辑该用户的计时器设置； -l：列出该用户的计时器设置； -r：删除该用户的计时器设置； -u&lt;用户名称&gt;：指定要设定计时器的用户名称。 格式 分钟(0-59) 小时(0-23) 日期(1-31) 月份(1-12) 星期(0-6,0代表星期天) 命令 软件包管理 yum命令 参数 yum(选项)(参数) -h：显示帮助信息； -y：对所有的提问都回答“yes”； -c：指定配置文件； -q：安静模式； -v：详细模式； -d：设置调试等级（0-10）； -e：设置错误等级（0-10）； -R：设置yum处理一个命令的最大等待时间； -C：完全从缓存中运行，而不去下载或者更新任何头文件。 yum源配置 yum的目录 cd /etc/yum.repos.d/ https://opsx.alibaba.com/mirror 找到这个网站，然后找到centos7的帮助有第一和第二步操作 3.清空yum缓存并且生成新的yum缓存 yum clean all yum makecache 4.安装软件扩展源 yum install -y epel-release yum命令 yum repolist all 列出所有仓库 yum list all 列出仓库所有软件包 yum info 软件包名 查看软件包信息 yum install 软件包名 安装软件包 yum reinstall 软件包名 重新安装软件包 yum update 软件包名 升级软件包 yum remove 软件包名 移除软件包 yum clean all 清楚所有仓库缓存 yum check-update 检查可以更新的软件包 yum grouplist 查看系统中已安装的软件包 yum groupinstall 软件包组 安装软件包组]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tornado框架]]></title>
    <url>%2F2019%2F01%2F15%2FTornado%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[安装： 1pip3 install tornado 快速启动： 12345678910111213141516import tornado.ioloopimport tornado.webclass MainHandler(tornado.web.RequestHandler): def get(self): self.write("Hello, world")def make_app(): return tornado.web.Application([ (r"/", MainHandler), ])if __name__ == "__main__": app = make_app() app.listen(8888) tornado.ioloop.IOLoop.current().start() 常用模块 123tornado.web RequestHandler和 Application 类处理http请求tornado.template 模板渲染tornado.touting 处理路由 异步网络模块 123tornado.ioloop 事件循环tornado.iostream 非阻塞socket封装tornado.tcpserver 和 tornado.tcpclient 协程和并发模块 12tornado.gen 协程模块tornado.locks、tornado.queues 同步协程队列模块]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>tornado</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django-celery的基本使用]]></title>
    <url>%2F2019%2F01%2F15%2FDjango-celery%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[celery的基本使用]]></title>
    <url>%2F2019%2F01%2F15%2Fcelery%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[celery是什么?​ celery是一个基于python实现的模块,模块可以帮助我们实现任务管理 什么情况下使用celery?一个请求的处理时间特别长,可以使用celery(例如:发送邮件,短信等) 安装celery1pip install celery 快速入门目录结构123456- celery_app -- __init__.py -- celeryconfig.py -- task1.py -- task2.py--demo.py init .py 1234from celery import Celeryapp = Celery('demo') # demo名称,可以是任意修改app.config_from_object('celery_app.celeryconfig') # 通过celery实例加载配置模块 celeryconfig.py配置文件 123456789101112131415161718192021222324252627282930from datetime import timedeltafrom celery.schedules import crontabBROKER_URL = 'redis://localhost:6379/1' # 设置broker存储的位置CELERY_RESULT_BACKEND = 'redis://localhost:6379/0' #设置backend的位置CELERY_TIMEZONE = 'Asia/Shanghai' # 设置时区# UTC# 导入指定的任务模块CELERY_IMPORTS = ( 'celery_app.task1', 'celery_app.task2')# 定时任务CELERYBEAT_SCHEDULE = &#123; 'task1':&#123; 'task':'celery_app.task1.add', 'schedule': timedelta(seconds=10), # 每10秒执行一次 'args':(2, 8) &#125;, 'task2':&#123; 'task':'celery_app.task2.multiply', 'schedule': crontab(hour=17,minute=27), # 每天的17点27分执行一次 'args':(4,5) &#125;&#125; task1.py 12345from celery_app import app@app.task # 设置一个处理任务的函数def add(x,y): return x + y task2.py 123456from celery_app import app@app.taskdef multiply(x , y): # 设置第二个 return x * y demo.py 12345678910111213141516171819# 发起任务from celery_app import task1from celery_app import task2# 第一种 参数:args是存放数据 eta=datetime(2018, 4, 11, 2, 32, 0):可以设置定时任务task1.add.apply_async() task1.add.delay(2,4)xx = task2.multiply.delay(4,5) # 第二种 直接传入参数# 获取结果from celery.result import AsyncResultfrom celery_app import appres = AsyncResult(id=xx.id,app=app)if res.ready(): # 判断结果是否返回 return res.get() # 返回的话把结果返回]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zeroMQ的基本使用]]></title>
    <url>%2F2019%2F01%2F15%2FzeroMQ%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>zeroMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka的基本使用]]></title>
    <url>%2F2019%2F01%2F15%2Fkafka%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLAlchemy的使用]]></title>
    <url>%2F2019%2F01%2F15%2FSQLAlchemy%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[什么是sqlalchemy?SQLAlchemy是Python编程语言下的一款ORM框架，该框架建立在数据库API之上，使用关系对象映射进行数据库操作，简言之便是：将对象转换成SQL，然后使用数据API执行SQL并获取执行结果。 连接数据库首先需要导入 sqlalchemy 库，然后建立数据库连接，这里使用 mysql。通过create_engine方法进行 12from sqlalchemy import create_engineengine = create_engine("mysql://root:@localhost:3306/webpy?charset=utf8",encoding="utf-8", echo=True) 基本使用1234567891011121314151617181920212223242526272829303132333435363738394041from sqlalchemy import Column, String, create_enginefrom sqlalchemy.orm import sessionmakerfrom sqlalchemy.ext.declarative import declarative_base# 创建对象的基类:Base = declarative_base()# 定义User对象:class User(Base): # 表的名字: __tablename__ = 'user' # 表的结构: id = Column(String(20), primary_key=True) name = Column(String(20))# 初始化数据库连接:engine = create_engine('mysql+mysqlconnector://root:password@localhost:3306/test')# 创建DBSession类型:DBSession = sessionmaker(bind=engine)# 创建session对象:session = DBSession()# 创建新User对象:new_user = User(id='5', name='Bob')# 添加到session:session.add(new_user)# 提交即保存到数据库:session.commit()# 关闭session:session.close()# 创建Session:session = DBSession()# 创建Query查询，filter是where条件，最后调用one()返回唯一行，如果调用all()则返回所有行:user = session.query(User).filter(User.id=='5').one()# 打印类型和对象的name属性:print('type:', type(user))print('name:', user.name)# 关闭Session:session.close() 引用: https://github.com/michaelliao/learn-python3/blob/master/samples/db/do_sqlalchemy.py]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>sqlAlchemy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Memcache的使用]]></title>
    <url>%2F2019%2F01%2F15%2FMemcache%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[什么是Memcached?Memcached 是一个高性能的分布式内存对象缓存系统，用于动态Web应用以减轻数据库负载。它通过在内存中缓存数据和对象来减少读取数据库的次数，从而提高动态、数据库驱动网站的速度。Memcached基于一个存储键/值对的hashmap。其守护进程（daemon ）是用C写的，但是客户端可以用任何语言来编写，并通过memcached协议与守护进程通信。 安装和参数Memcached的安装12345678wget http://memcached.org/latesttar -zxvf memcached-1.x.x.tar.gzcd memcached-1.x.x./configure &amp;&amp; make &amp;&amp; make test &amp;&amp; sudo make install PS：依赖libevent yum install libevent-devel apt-get install libevent-dev 启动Memcached12345678910memcached -d -m 10 -u root -l 10.211.55.4 -p 12000 -c 256 -P /tmp/memcached.pid 参数说明: -d 是启动一个守护进程 -m 是分配给Memcache使用的内存数量，单位是MB -u 是运行Memcache的用户 -l 是监听的服务器IP地址 -p 是设置Memcache监听的端口,最好是1024以上的端口 -c 选项是最大运行的并发连接数，默认是1024，按照你服务器的负载量来设定 -P 是设置保存Memcache的pid文件 python操作Memcached12# 下载pip install python-memcached 第一次操作12345678import memcachemc = memcache.Client(['127.0.0.1:11211'], debug=True)mc.set("foo", "bar")ret = mc.get('foo')print(ret)# debug = True 表示运行出现错误时，现实错误信息，上线后移除该参数。 天生支持集群python-memcached模块原生支持集群操作，其原理是在内存维护一个主机列表，且集群中主机的权重值和主机在列表中重复出现的次数成正比 1234567891011 主机 权重 1.1.1.1 1 1.1.1.2 2 1.1.1.3 1 那么在内存中主机列表为： host_list = ["1.1.1.1", "1.1.1.2", "1.1.1.2", "1.1.1.3", ]# 代码mc = memcache.Client([('1.1.1.1:12000', 1), ('1.1.1.2:12000', 2), ('1.1.1.3:12000', 1)], debug=True)mc.set('k1', 'v1') add添加一条键值对,如果已经存在key,重复执行add操作异常 12345import memcache mc = memcache.Client(['10.211.55.4:11211'], debug=True)mc.add('k1', 'v1')# mc.add('k1', 'v2') # 报错，对已经存在的key重复添加，失败！！！ replacereplace修改某个key的值,如果key不存在则异常 12345import memcache mc = memcache.Client(['10.211.55.4:11211'], debug=True)# 如果memcache中存在kkkk，则替换成功，否则异常mc.replace('kkkk','999') set和set_multiset 设置值一个键值对,如果key不存在,则创建,如果key存在,则修改 set_multi 设置多个键值对,如果key不存在,则创建,如果key存在,则修改 1234import memcachemc = memcache.Client(['10.211.55.4:11211'], debug=True)mc.set('key0', 'wupeiqi')mc.set_multi(&#123;'key1': 'val1', 'key2': 'val2'&#125;) delete 和 delete_multidelete 在Memcached中删除指定一个键值对 delete_multi 在Memcached中删除指定的多个键值对 123456import memcache mc = memcache.Client(['10.211.55.4:11211'], debug=True) mc.delete('key0')mc.delete_multi(['key1', 'key2']) get 和 get_multiget 获取一个键值对 get_multi 获取多个键值对 1234import memcachemc = memcache.Client(['10.211.55.4:11211'], debug=True)val = mc.get('key0')item_dict = mc.get_multi(["key1", "key2", "key3"]) append 和 prependappend 修改指定key的值,在该值后面追加内容 prepend 修改指定key的值,在该值前面插入内容 12345678910import memcache mc = memcache.Client(['10.211.55.4:11211'], debug=True)# k1 = "v1" mc.append('k1', 'after')# k1 = "v1after" mc.prepend('k1', 'before')# k1 = "beforev1after" decr和incrincr 自增,将Memcached中的某一个值增加N(N默认是1) decr 自减,将Memcached中的某一个值减少N(N默认是1) 12345678910111213141516import memcache mc = memcache.Client(['10.211.55.4:11211'], debug=True)mc.set('k1', '777') mc.incr('k1')# k1 = 778 mc.incr('k1', 10)# k1 = 788 mc.decr('k1')# k1 = 787 mc.decr('k1', 10)# k1 = 777 gets 和 cas如商城商品剩余个数，假设改值保存在memcache中，product_count = 900A用户刷新页面从memcache中读取到product_count = 900B用户刷新页面从memcache中读取到product_count = 900 如果A、B用户均购买商品 A用户修改商品剩余个数 product_count＝899B用户修改商品剩余个数 product_count＝899 如此一来缓存内的数据便不在正确，两个用户购买商品后，商品剩余还是 899如果使用python的set和get来操作以上过程，那么程序就会如上述所示情况！ 如果想要避免此情况的发生，只要使用 gets 和 cas 即可，如： 1234567import memcachemc = memcache.Client(['10.211.55.4:12000'], debug=True, cache_cas=True) v = mc.gets('product_count')# ...# 如果有人在gets之后和cas之前修改了product_count，那么，下面的设置将会执行失败，剖出异常，从而避免非正常数据的产生mc.cas('product_count', "899") ​ 本质上每次执行gets时，会从memcache中获取一个自增的数字，通过cas去修改gets的值时，会携带之前获取的自增值和memcache中的自增值进行比较，如果相等，则可以提交，如果不想等，那表示在gets和cas执行之间，又有其他人执行了gets（获取了缓冲的指定值）， 如此一来有可能出现非正常数据，则不允许修改]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mangoDB基础]]></title>
    <url>%2F2019%2F01%2F14%2FmangoDB%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[数据库中的用法MangoDB的对应关系引用了不存在的对象来创建改对象 1234database ------&gt; Databasetable -------&gt; Collection字段 --------&gt; Fieldrow ---------&gt; Document mangoDB增删改查123456789101112131415161718增: 官方不推荐写法: db.users.insert([&#123;&#125;]) db.users.insert(&#123;&#125;) 官方支持写法 db.users.insertMany([&#123;'name':'ccc','age':88&#125;,&#123;'name':'ddd','age':88&#125;]) db.users.insertOne(&#123;name:"xxx",age:"73"&#125;)查: db.users.find(&#123;age:73,name:"xxx"&#125;) db.users.findOne(&#123;age:73&#125;)改：MongoDB修改器 $set $unset:删除字段的 db.users.updateOne(&#123;age:73&#125;,&#123;$set:&#123;age:74&#125;&#125;) db.users.updateMany(&#123;age:74&#125;,&#123;$set:&#123;age:73&#125;&#125;) 删: db.users.deleteOne(&#123;age:"84"&#125;) db.users.deleteMany(&#123;age:"84"&#125;) MongoDB的数据类型12345678910Object ID ：Documents 自生成的 _idString： 字符串，必须是utf-8Boolean：布尔值，true 或者false (这里有坑哦~在Python中 True False 首字母大写)Integer：整数 (Int32 Int64 你们就知道有个Int就行了,一般我们用Int32)Double：浮点数 (没有float类型,所有小数都是Double)Arrays：数组或者列表，多个值存储到一个键 (list哦,大Python中的List哦)Object：如果你学过Python的话,那么这个概念特别好理解,就是Python中的字典,这个数据类型就是字典Null：空数据类型 , 一个特殊的概念,None NullTimestamp：时间戳Date：存储当前日期或时间unix时间格式 (我们一般不用这个Date类型,时间戳可以秒杀一切时间类型) $关键字12345678910111213141516171819202122232425修改器 $set : 强制覆盖 $unset : 删除字段 $inc ：引用自增 $inc:&#123;age:-1&#125; $push append(7) db.sss.updateOne(&#123;name:"xxx"&#125;,&#123;$push:&#123;hobby_1:7&#125;&#125;) $pull remove(1) db.sss.updateOne(&#123;name:"xxx"&#125;,&#123;$pull:&#123;hobby_1:1&#125;&#125;) $pop pop() db.sss.updateOne(&#123;name:"xxx"&#125;,&#123;$pop:&#123;hobby_1:1/-1&#125;&#125;) 1删除最后一个,-1代表删除第一个 查询关键： $or $or:[&#123;age:1&#125;,&#123;name:2&#125;] $all &#123;u_list:&#123;$all:[321,123]&#125;&#125; $in &#123;age:&#123;$in:[10,15]&#125;&#125; 数学比较符： $lt &#123;age:&#123;$gt:10&#125;&#125; $lte $gt $gte $eq : $ne &#123;age:&#123;$ne:15&#125;&#125; 4. $ (&#123;name:"xxx","hobby.name":"个人计算机"&#125;,&#123;$set:&#123;"hobby.$.name":"PC"&#125;&#125;) skip limit sort12345sort: sort(&#123; age:1 / -1&#125;) -1:倒序 1:正序 skip: skip(2) 跳过两条limit： limit(2) 选取两条优先级: 1.sort 2.skip 3.limit python中使用MangoDB连接MongoDBClient12import pymongoclient = pymongo.MongoClient(host='localhost', port=27017) 获取数据库12db = Client.test_databasedb = Client['test_database'] 获取CollectionCollection是存储在MongoDB中的一组文件，同获取database一样，你可以用点取属性的方式或者字典的方法获取： 12collection = db.test_collectioncollection = db['test_collection'] 其他操作和上面一样]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MangoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis进阶]]></title>
    <url>%2F2019%2F01%2F14%2Fredis%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[什么是redisredis是一个基于内存的高性能key-value数据库 2.redis的特点Redis本质是一个key-value类型的数据库,就像memcached,整个数据库统统加载在内存中进行操作,定期通过异步把数据库数据push到硬盘上进行保存,因为是纯内存操作所以redis的性能非常出色,每秒可以处理10万次读写操作,是已知性能最快的key-value DB Redis的出色之处不仅仅只有他的性能,Redis最大的魅力是支持多种数据结构,此外单个value的最大限制是1GB,不像memcached只能保存1MB的数据,因此redis可以用来实现很多有用的功能,比如:用他的List来做FIFO双向链表实现一个轻量级的高性能消息队列服务,用他的set可以做高性能的tag系统等等,另外Redis也可以对存入的key-value设置expire(过期)时间,因此也可以当做一个加强版的memcached来用. Redis主要缺点是数据库容量受物理内存限制,不能做海量数据的高性能读写,因此它只适合在较小数据量的高性能操作和运算上 PS—–&gt;memcached:是一个高性能的分布式内存对象缓存系统，用于动态Web应用以减轻数据库负载。它通过在内存中缓存数据和对象来减少读取数据库的次数，从而提高动态、数据库驱动网站的速度。Memcached基于一个存储键/值对的hashmap。其守护进程（daemon ）是用C写的，但是客户端可以用任何语言来编写，并通过memcached协议与守护进程通信。 3.Redis支持的数据类型Redis通过key-value的单值不同类型区分 strings Lists sets sorted set hashes 4.为什么redis需要把所有数据放到内存中redis为了达到最快的读写速度将数据都读到内存中,并通过异步的方式将数据写入磁盘,所以redis具有快速和数据持久化的特性,如果不将数据放在内存中,磁盘I/O速度会影响redis的性能, 如果设置最大使用的内存,则数据已有记录达到内存限值后不能继续插入新值 5.Redis是单进程单线程的redis利用队列技术将并发访问变成为串行访问,消除了传统数据库串行控制开销 6.虚拟内存当你的key很小而value很大时,使用vm的效果会比较好,因为这样节约内存比较大 当你的key不小时,可以考虑一些非常方法将很大的key变成value,比如你可以将key-value变成一个value vm-max-threads这个参数,可以设置访问swap文件的线程数,设置最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的.可能会造成比较长时间的延迟,但是对数据完整性有很好的保证. 7.分布式redis支持主从的模式,原则:master(控制)会将数据同步到slave,而slave不会讲数据同步到master,slave启动时会连接master来同步数据 这是一个典型的分布式读写分离模型,我们可以利用master来插入数据,slave提供检索服务,这样可以有效减少单个机器的并发访问数量 8.读写分离模型通过增加slave DB的数量,读的性能可以线性增长,为了避免master DB的单点故障,集群一般都会采用两台master DB做双机热备所以整个集群的读和写的可用性都非常高 读写分离的缺陷:不管master还是slave,每个节点都必须保存完整的数据,如果在数据量很大的时候,集群的扩展能力还是受限于每个节点 的存储能力,而且对于write-intensive类型的应用,读写分离的架构并不合适 9.数据分片模型为了解决读写分离模型的缺陷,可以将数据分片模型应用进来 可以将每个节点都看成独立的master,然后通过业务实现数据分片 结合上面两种模型,可以将每个master设计由一个master和多个slave组成的模型 10.Redis的回收策略 volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据 11.使用redis有哪些好处 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) 支持丰富数据类型，支持string，list，set，sorted set，hash 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 12.redis相比memcached有哪些优势？ memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 redis的速度比memcached快很多 redis可以持久化其数据 13.redis常见性能问题和解决方案： Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内 尽量避免在压力很大的主库上增加从库 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3… 这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变 14.MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。详情见 redis的回收策略 15.redis常见的性能问题有哪些?如何解决 Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 16.redis适合的场景Redis最适合所有数据in-momory的场景，虽然Redis也提供持久化功能，但实际更多的是一个disk-backed的功能，跟传统意义上的持久化有比较大的差别，那么可能大家就会有疑问，似乎Redis更像一个加强版的Memcached，那么何时使用Memcached,何时使用Redis呢? Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 、Redis支持数据的备份，即master-slave模式的数据备份。 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 17、会话缓存（Session Cache）最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？ 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。 18、全页缓存（FPC）除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。 再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。 此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 19、队列Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。 如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。 20，排行榜/计数器Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可： 当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行： ZRANGE user_scores 0 10 WITHSCORES 21、发布/订阅最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis基础]]></title>
    <url>%2F2019%2F01%2F14%2Fredis%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[redis的数据类型 string(字符串) Hash(哈希/字典) List(数组/列表) 无序集合 有序集合 安装1pip install redis 操作模式redis-py提供两个类Redis和StrictRedis用于实现Redis的命令，StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令，Redis是StrictRedis的子类，用于向后兼容旧版本的redis-py。 1234import redisr = redis.Redis(host='10.211.55.4', port=6379)r.set('foo', 'Bar')print r.get('foo') 连接池redis-py使用connection pool来管理对一个redis server的所有连接，避免每次建立、释放连接的开销。默认，每个Redis实例都会维护一个自己的连接池。可以直接建立一个连接池，然后作为参数Redis，这样就可以实现多个Redis实例共享一个连接池。 12345import redispool = redis.ConnectionPool(host='10.211.55.4', port=6379)r = redis.Redis(connection_pool=pool)r.set('foo', 'Bar')print r.get('foo') string的基本操作set(name,value,ex=None,px=None,nx=False,xx=False) 123456在Redis中设置值，默认，不存在则创建，存在则修改参数： ex，过期时间（秒） px，过期时间（毫秒） nx，如果设置为True，则只有name不存在时，当前set操作才执行 xx，如果设置为True，则只有name存在时，岗前set操作才执行 setnx(name, value)设置值，只有name不存在时，执行设置操作（添加） setex(name, value, time) :time，过期时间（数字秒 或 timedelta对象） psetex(name, time_ms, value) :time_ms，过期时间（数字毫秒 或 timedelta对象） mset(*args, **kwargs) 12345批量设置值如： mset(k1=&apos;v1&apos;, k2=&apos;v2&apos;) 或 mget(&#123;&apos;k1&apos;: &apos;v1&apos;, &apos;k2&apos;: &apos;v2&apos;&#125;) get(name):获取值 mget(keys, *args) 12345批量获取如： mget(&apos;ylr&apos;, &apos;wupeiqi&apos;) 或 r.mget([&apos;ylr&apos;, &apos;wupeiqi&apos;]) getset(name, value) :设置新值并获取原来的值 getrange(key, start, end) : 12345# 获取子序列（根据字节获取，非字符）# 参数： # name，Redis 的 name # start，起始位置（字节） # end，结束位置（字节） setrange(name, offset, value) 1234修改字符串内容，从指定字符串索引开始向后替换（新值太长时，则向后添加）参数： # offset，字符串的索引，字节（一个汉字三个字节） # value，要设置的值 setbit(name, offset, value) 12345678910111213141516171819202122232425 对name对应值的二进制表示的位进行操作 参数： # name，redis的name # offset，位的索引（将值变换成二进制后再进行索引） # value，值只能是 1 或 0 注：如果在Redis中有一个对应： n1 = &quot;foo&quot;， 那么字符串foo的二进制表示为：01100110 01101111 01101111 所以，如果执行 setbit(&apos;n1&apos;, 7, 1)，则就会将第7位设置为1， 那么最终二进制则变成 01100111 01101111 01101111，即：&quot;goo&quot; 扩展，转换二进制表示： # source = &quot;郝起瀚&quot; source = &quot;foo&quot; for i in source: num = ord(i) print bin(num).replace(&apos;b&apos;,&apos;&apos;) 特别的，如果source是汉字 &quot;郝起瀚&quot;怎么办？ 答：对于utf-8，每一个汉字占 3 个字节，那么 &quot;武沛齐&quot; 则有 9个字节 对于汉字，for循环时候会按照 字节 迭代，那么在迭代时，将每一个字节转换 十进制数，然后再将十进制数转换成二进制 11100110 10101101 10100110 11100110 10110010 10011011 11101001 10111101 10010000 getbit(name, offset) 1获取name对应的值的二进制表示中的某位的值 （0或1） bitcount(key, start=None, end=None) 12345获取name对应的值的二进制表示中 1 的个数参数： # key，Redis的name # start，位起始位置 # end，位结束位置 bitop(operation, dest, *keys) 12345678910获取多个值，并将值做位运算，将最后的结果保存至新的name对应的值 参数： operation,AND（并） 、 OR（或） 、 NOT（非） 、 XOR（异或） dest, 新的Redis的name *keys,要查找的Redis的name 如： bitop(&quot;AND&quot;, &apos;new_name&apos;, &apos;n1&apos;, &apos;n2&apos;, &apos;n3&apos;) 获取Redis中n1,n2,n3对应的值，然后讲所有的值做位运算（求并集），然后将结果保存 new_name 对应的值中 strlen(name) 1返回name对应值的字节长度（一个汉字3个字节） incr(self, name, amount=1) 1234567 自增 name对应的值，当name不存在时，则创建name＝amount，否则，则自增。 参数： # name,Redis的name # amount,自增数（必须是整数） 注：同incrby incrbyfloat(self, name, amount=1.0) 12345自增 name对应的值，当name不存在时，则创建name＝amount，否则，则自增。 参数： name,Redis的name amount,自增数（浮点型） decr(self, name, amount=1) 12345自减 name对应的值，当name不存在时，则创建name＝amount，否则，则自减。参数： name,Redis的name amount,自减数（整数） append(key, value) 12345在redis name对应的值后面追加内容 参数： key, redis的name value, 要追加的字符串 Hash操作hset(name,key,value) 123456789name对应的hash中设置一个键值对（不存在，则创建；否则，修改） 参数： name，redis的name key，name对应的hash中的key value，name对应的hash中的value 注： hsetnx(name, key, value),当name对应的hash中不存在当前key时则创建（相当于添加） hmset(name, mapping) 1234567在name对应的hash中批量设置键值对 参数： name，redis的name mapping，字典，如：&#123;&apos;k1&apos;:&apos;v1&apos;, &apos;k2&apos;: &apos;v2&apos;&#125;如： r.hmset(&apos;xx&apos;, &#123;&apos;k1&apos;:&apos;v1&apos;, &apos;k2&apos;: &apos;v2&apos;&#125;) hget(name,key) 1在name对应的hash中获取根据key获取value hmget(name, keys, *args) 1234567891011在name对应的hash中获取多个key的值 参数： name，reids对应的name keys，要获取key集合，如：[&apos;k1&apos;, &apos;k2&apos;, &apos;k3&apos;] *args，要获取的key，如：k1,k2,k3 如： r.mget(&apos;xx&apos;, [&apos;k1&apos;, &apos;k2&apos;]) 或 print r.hmget(&apos;xx&apos;, &apos;k1&apos;, &apos;k2&apos;) hgetall(name) 1获取name对应hash的所有键值 hlen(name) 1获取name对应的hash中键值对的个数 hkeys(name) 1获取name对应的hash中所有的key的值 hvals(name) 1获取name对应的hash中所有的value的值 hexists(name, key) 1检查name对应的hash是否存在当前传入的key hdel(name,*keys) 1将name对应的hash中指定key的键值对删除 hincrby(name, key, amount=1) 12345自增name对应的hash中的指定key的值，不存在则创建key=amount参数： name，redis中的name key， hash对应的key amount，自增数（整数） hincrbyfloat(name, key, amount=1.0) 1234567自增name对应的hash中的指定key的值，不存在则创建key=amount 参数： name，redis中的name key， hash对应的key amount，自增数（浮点数）自增name对应的hash中的指定key的值，不存在则创建key=amount hscan(name, cursor=0, match=None, count=None) 1234567891011增量式迭代获取，对于数据大的数据非常有用，hscan可以实现分片的获取数据，并非一次性将数据全部获取完，从而放置内存被撑爆 参数： name，redis的name cursor，游标（基于游标分批取获取数据） match，匹配指定key，默认None 表示所有的key count，每次分片最少获取个数，默认None表示采用Redis的默认分片个数 如： 第一次：cursor1, data1 = r.hscan(&apos;xx&apos;, cursor=0, match=None, count=None) 第二次：cursor2, data1 = r.hscan(&apos;xx&apos;, cursor=cursor1, match=None, count=None) hscan_iter(name, match=None, count=None) 123456789利用yield封装hscan创建生成器，实现分批去redis中获取数据 参数： match，匹配指定key，默认None 表示所有的key count，每次分片最少获取个数，默认None表示采用Redis的默认分片个数 如： for item in r.hscan_iter(&apos;xx&apos;): print item List操作redis中的List在在内存中按照一个name对应一个List来存储。 lpush(name,values) 12345678在name对应的list中添加元素，每个新的元素都添加到列表的最左边 如： r.lpush(&apos;oo&apos;, 11,22,33) 保存顺序为: 33,22,11 扩展： rpush(name, values) 表示从右向左操作 lpushx(name,value) 1234在name对应的list中添加元素，只有name已经存在时，值添加到列表的最左边 更多： rpushx(name, value) 表示从右向左操作 llen(name) 1name对应的list元素的个数 linsert(name, where, refvalue, value)) 1234567在name对应的列表的某一个值前或后插入一个新值 参数： name，redis的name where，BEFORE或AFTER refvalue，标杆值，即：在它前后插入数据 value，要插入的数据 r.lset(name, index, value) 123456对name对应的list中的某一个索引位置重新赋值 参数： name，redis的name index，list的索引位置 value，要设置的值 r.lrem(name, value, num) 12345678在name对应的list中删除指定的值 参数： name，redis的name value，要删除的值 num， num=0，删除列表中所有的指定值； num=2,从前到后，删除2个； num=-2,从后向前，删除2个 lpop(name) 1234在name对应的列表的左侧获取第一个元素并在列表中移除，返回值则是第一个元素 更多： rpop(name) 表示从右向左操作 lindex(name, index) 1在name对应的列表中根据索引获取列表元素 lrange(name, start, end) 12345在name对应的列表分片获取数据 参数： name，redis的name start，索引的起始位置 end，索引结束位置 ltrim(name, start, end) 12345在name对应的列表中移除没有在start-end索引之间的值参数： name，redis的name start，索引的起始位置 end，索引结束位置 rpoplpush(src, dst) 1234从一个列表取出最右边的元素，同时将其添加至另一个列表的最左边 参数： src，要取数据的列表的name dst，要添加数据的列表的name blpop(keys, timeout) 12345将多个列表排列，按照从左到右去pop对应列表的元素 参数： keys，redis的name的集合 timeout，超时时间，当元素所有列表的元素获取完之后，阻塞等待列表内有数据的时间（秒）, 0 表示永远阻塞 brpoplpush(src, dst, timeout=0) 123456从一个列表的右侧移除一个元素并将其添加到另一个列表的左侧 参数： src，取出并要移除元素的列表对应的name dst，要插入元素的列表对应的name timeout，当src对应的列表中没有数据时，阻塞等待其有数据的超时时间（秒），0 表示永远阻塞 自定义增量迭代 123456789101112131415161718由于redis类库中没有提供对列表元素的增量迭代，如果想要循环name对应的列表的所有元素，那么就需要： 1、获取name对应的所有列表 2、循环列表但是，如果列表非常大，那么就有可能在第一步时就将程序的内容撑爆，所有有必要自定义一个增量迭代的功能： def list_iter(name): &quot;&quot;&quot; 自定义redis列表增量迭代 :param name: redis中的name，即：迭代name对应的列表 :return: yield 返回 列表元素 &quot;&quot;&quot; list_count = r.llen(name) for index in xrange(list_count): yield r.lindex(name, index) 使用for item in list_iter(&apos;pp&apos;): print item Set操作Set集合就是不允许重复的列表 sadd(name,values) 1name对应的集合中添加元素 scard(name) 1获取name对应的集合中元素个数 sdiff(keys, *args) 1在第一个name对应的集合中且不在其他name对应的集合的元素集合 sdiffstore(dest, keys, *args) 1获取第一个name对应的集合中且不在其他name对应的集合，再将其新加入到dest对应的集合中 sinter(keys, *args) 1获取多一个name对应集合的并集 sinterstore(dest, keys, *args) 1获取多一个name对应集合的并集，再讲其加入到dest对应的集合中 sismember(name, value) 1检查value是否是name对应的集合的成员 smembers(name) 1获取name对应的集合的所有成员 smove(src, dst, value) 1将某个成员从一个集合中移动到另外一个集合 spop(name) 1从集合的右侧（尾部）移除一个成员，并将其返回 srandmember(name, numbers) 1从name对应的集合中随机获取 numbers 个元素 srem(name, values) 1在name对应的集合中删除某些值 sunion(keys, *args) 1获取多一个name对应的集合的并集 sunionstore(dest,keys, *args) 1获取多一个name对应的集合的并集，并将结果保存到dest对应的集合中 sscan(name, cursor=0, match=None, count=None) sscan_iter(name, match=None, count=None) 1同字符串的操作，用于增量迭代分批获取元素，避免内存消耗太大 有序集合在集合的基础上，为每元素排序；元素的排序需要根据另外一个值来进行比较，所以，对于有序集合，每一个元素有两个值，即：值和分数，分数专门用来做排序。 zadd(name,*args,**kwargs) 12345在name对应的有序集合中添加元素 如： zadd(&apos;zz&apos;, &apos;n1&apos;, 1, &apos;n2&apos;, 2) 或 zadd(&apos;zz&apos;, n1=11, n2=22) zcard(name) 1获取name对应的有序集合元素的数量 zcount(name, min, max) 1获取name对应的有序集合中分数 在 [min,max] 之间的个数 zincrby(name, value, amount) 1自增name对应的有序集合的 name 对应的分数 r.zrange( name, start, end, desc=False, withscores=False, score_cast_func=float) 123456789101112131415161718按照索引范围获取name对应的有序集合的元素 参数： name，redis的name start，有序集合索引起始位置（非分数） end，有序集合索引结束位置（非分数） desc，排序规则，默认按照分数从小到大排序 withscores，是否获取元素的分数，默认只获取元素的值 score_cast_func，对分数进行数据转换的函数 更多： 从大到小排序 zrevrange(name, start, end, withscores=False, score_cast_func=float) 按照分数范围获取name对应的有序集合的元素 zrangebyscore(name, min, max, start=None, num=None, withscores=False, score_cast_func=float) 从大到小排序 zrevrangebyscore(name, max, min, start=None, num=None, withscores=False, score_cast_func=float) zrank(name, value) 1234获取某个值在 name对应的有序集合中的排行（从 0 开始） 更多： # zrevrank(name, value)，从大到小排序 zrangebylex(name, min, max, start=None, num=None) 1234567891011121314151617当有序集合的所有成员都具有相同的分值时，有序集合的元素会根据成员的 值 （lexicographical ordering）来进行排序，而这个命令则可以返回给定的有序集合键 key 中， 元素的值介于 min 和 max 之间的成员对集合中的每个成员进行逐个字节的对比（byte-by-byte compare）， 并按照从低到高的顺序， 返回排序后的集合成员。 如果两个字符串有一部分内容是相同的话， 那么命令会认为较长的字符串比较短的字符串要大 参数： name，redis的name min，左区间（值）。 + 表示正无限； - 表示负无限； ( 表示开区间； [ 则表示闭区间 min，右区间（值） start，对结果进行分片处理，索引位置 num，对结果进行分片处理，索引后面的num个元素 如： # ZADD myzset 0 aa 0 ba 0 ca 0 da 0 ea 0 fa 0 ga # r.zrangebylex(&apos;myzset&apos;, &quot;-&quot;, &quot;[ca&quot;) 结果为：[&apos;aa&apos;, &apos;ba&apos;, &apos;ca&apos;] 更多： 从大到小排序 zrevrangebylex(name, max, min, start=None, num=None) zrem(name, values) 12删除name对应的有序集合中值是values的成员如：zrem(&apos;zz&apos;, [&apos;s1&apos;, &apos;s2&apos;]) zremrangebyrank(name, min, max) 1根据排行范围删除 zremrangebyscore(name, min, max) 1根据分数范围删除 zremrangebylex(name, min, max) 1根据值返回删除 zscore(name, value) 1获取name对应有序集合中 value 对应的分数 zinterstore(dest, keys, aggregate=None) 12获取两个有序集合的交集，如果遇到相同值不同分数，则按照aggregate进行操作aggregate的值为: SUM MIN MAX zunionstore(dest, keys, aggregate=None) 12获取两个有序集合的并集，如果遇到相同值不同分数，则按照aggregate进行操作aggregate的值为: SUM MIN MAX zscan(name, cursor=0, match=None, count=None, score_cast_func=float) zscan_iter(name, match=None, count=None,score_cast_func=float) 1同字符串相似，相较于字符串新增score_cast_func，用来对分数进行操作 其他常用操作delete(*names) 1根据删除redis中的任意数据类型 exists(name) 1检测redis的name是否存在 keys(pattern=’*’) 1234567根据模型获取redis的name 更多： KEYS * 匹配数据库中所有 key 。 KEYS h?llo 匹配 hello ， hallo 和 hxllo 等。 KEYS h*llo 匹配 hllo 和 heeeeello 等。 KEYS h[ae]llo 匹配 hello 和 hallo ，但不匹配 hillo expire(name ,time) 1为某个redis的某个name设置超时时间 rename(src, dst) 1对redis的name重命名为 move(name, db)) 1将redis的某个值移动到指定的db下 randomkey() 1随机获取一个redis的name（不删除） type(name) 1获取name对应值的类型 scan(cursor=0, match=None, count=None) scan_iter(match=None, count=None) 1同字符串操作，用于增量迭代获取key 管道redis-py默认在执行每次请求都会创建（连接池申请连接）和断开（归还连接池）一次连接操作，如果想要在一次请求中指定多个命令，则可以使用pipline实现一次请求指定多个命令，并且默认情况下一次pipline 是原子性操作。 12345678910111213import redis pool = redis.ConnectionPool(host='10.211.55.4', port=6379) r = redis.Redis(connection_pool=pool) # pipe = r.pipeline(transaction=False)pipe = r.pipeline(transaction=True)pipe.multi()pipe.set('name', 'alex')pipe.set('role', 'sb') pipe.execute() 发布订阅12345678910111213141516171819import redisclass RedisHelper: def __init__(self): self.__conn = redis.Redis(host='10.211.55.4') self.chan_sub = 'fm104.5' self.chan_pub = 'fm104.5' def public(self, msg): self.__conn.publish(self.chan_pub, msg) return True def subscribe(self): pub = self.__conn.pubsub() pub.subscribe(self.chan_sub) pub.parse_response() return pub 订阅者 12345678from monitor.RedisHelper import RedisHelper obj = RedisHelper()redis_sub = obj.subscribe() while True: msg= redis_sub.parse_response() print msg 发布者： 1234from monitor.RedisHelper import RedisHelper obj = RedisHelper()obj.public('hello') sentinel(哨兵)redis重的sentinel主要用于在redis主从复制中，如果master顾上，则自动将slave替换成master 12345678910111213141516171819202122232425from redis.sentinel import Sentinel 连接哨兵服务器(主机名也可以用域名)sentinel = Sentinel([('10.211.55.20', 26379), ('10.211.55.20', 26380), ], socket_timeout=0.5) 获取主服务器地址 master = sentinel.discover_master('mymaster') print(master) 获取从服务器地址slave = sentinel.discover_slaves('mymaster') print(slave)获取主服务器进行写入 master = sentinel.master_for('mymaster') master.set('foo', 'bar') 获取从服务器进行读取（默认是round-roubin） slave = sentinel.slave_for('mymaster', password='redis_auth_pass') r_ret = slave.get('foo') print(r_ret)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql进阶]]></title>
    <url>%2F2019%2F01%2F14%2Fmysql%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[存储过程一.存储过程的定义存储过程是把一段代码封装起来，当要执行这一段代码的时候，可以通过调用该存储过程来实现（经过第一次编译后再次调用不需要再次编译，比一个个执行sql语句效率高） 二.存储过程的优点 通常存储过程有助于提高应用程序的性能。当创建，存储过程被编译之后，就存储在数据库中。 但是，MySQL实现的存储过程略有不同。 MySQL存储过程按需编译。 在编译存储过程之后，MySQL将其放入缓存中。 MySQL为每个连接维护自己的存储过程高速缓存。 如果应用程序在单个连接中多次使用存储过程，则使用编译版本，否则存储过程的工作方式类似于查询。 存储过程有助于减少应用程序和数据库服务器之间的流量，因为应用程序不必发送多个冗长的SQL语句，而只能发送存储过程的名称和参数。 存储的程序对任何应用程序都是可重用的和透明的。 存储过程将数据库接口暴露给所有应用程序，以便开发人员不必开发存储过程中已支持的功能。 存储的程序是安全的。 数据库管理员可以向访问数据库中存储过程的应用程序授予适当的权限，而不向基础数据库表提供任何权限。 三.存储过程的缺点 如果使用大量存储过程，那么使用这些存储过程的每个连接的内存使用量将会大大增加。 此外，如果您在存储过程中过度使用大量逻辑操作，则CPU使用率也会增加，因为数据库服务器的设计不当于逻辑运算 存储过程的构造使得开发具有复杂业务逻辑的存储过程变得更加困难。 很难调试存储过程。只有少数数据库管理系统允许您调试存储过程。不幸的是，MySQL不提供调试存储过程的功能。 开发和维护存储过程并不容易。开发和维护存储过程通常需要一个不是所有应用程序开发人员拥有的专业技能。这可能会导致应用程序开发和维护阶段的问题。 四.一个简单的mysql存储过程示例123456delimiter // create procedure b1() begin select * from blog; end //delimiter ; 解释: 第一个命令是delimiter //，它与存储过程语法无关。 delimter语句将标准分隔符 - 分号(;)更改为：//。 在这种情况下，分隔符从分号(;)更改为双斜杠//。为什么我们必须更改分隔符？ 因为我们想将存储过程作为整体传递给服务器，而不是让mysql工具一次解释每个语句。 在END关键字之后，使用分隔符//来指示存储过程的结束。 最后一个命令(DELIMITER;)将分隔符更改回分号(;)。 .使用create procedure语句创建一个新的存储过程。在create procedure语句之后指定存储过程的名称。在这个示例中，存储过程的名称为：b1，并把括号放在存储过程的名字之后。 begin和end之间的部分称为存储过程的主体。将声明性SQL语句放在主体中以处理业务逻辑。 在这个存储过程中，我们使用一个简单的select语句来查询blog表中的数据。 123456mysql中调用存储过程 call b1()在python中基于pymysql调用cursor.callproc('b1') print(cursor.fetchall()) 五.声明变量要在存储过程中声明变量，可以使用delclare语句，如下 1DECLARE variable_name datatype(size) DEFAULT default_value; 在DECLARE关键字后面要指定变量名。变量名必须遵循MySQL表列名称的命名规则 指定变量的数据类型及其大小。变量可以有任何MySQL数据类型，如INT，VARCHAR，DATETIME等。 当声明一个变量时，它的初始值为NULL。但是可以使用DEFAULT关键字为变量分配默认值 1234567891011delimiter // create procedure b2() begin DECLARE n int DEFAULT 1; set n = 5; select * from blog where id = n; end //delimiter ;# mysql中调用存储过程call b2(); 六.存储过程传参在现实应用中，开发的存储过程几乎都需要参数。这些参数使存储过程更加灵活和有用。 在MySQL中，参数有三种模式：IN，OUT或INOUT。 IN - 是默认模式。在存储过程中定义IN参数时，调用程序必须将参数传递给存储过程。 另外，IN参数的值被保护。这意味着即使在存储过程中更改了IN参数的值，在存储过程结束后仍保留其原始值。换句话说，存储过程只使用IN参数的副本。 OUT - 可以在存储过程中更改OUT参数的值，并将其更改后新值传递回调用程序。请注意，存储过程在启动时无法访问OUT参数的初始值。 INOUT - INOUT参数是IN和OUT参数的组合。这意味着调用程序可以传递参数，并且存储过程可以修改INOUT参数并将新值传递回调用程序。 在存储过程中定义参数的语法如下 1MODE param_name param_type(param_size) 根据存储过程中参数的目的，MODE可以是IN，OUT或INOUT。 param_name是参数的名称。参数的名称必须遵循MySQL中列名的命名规则。 在参数名之后是它的数据类型和大小。和变量一样，参数的数据类型可以是任何有效的MySQL数据类型 如果存储过程有多个参数，则每个参数由逗号(,)分隔。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 1.indelimiter // create procedure b3( in blogName varchar(30) ) begin select * from blog where NAME = blogName; end //delimiter ;#mysql中调用存储过程call b3('第5篇');#python中调用存储过程cursor.callproc('b3',args = ('第5篇')); # 2.outdelimiter // create procedure b4( in year int, out count int ) begin SELECT COUNT(1) into count FROM blog GROUP BY DATE_FORMAT(sub_time,'%Y') having max(DATE_FORMAT(sub_time,'%Y')) = year ; set count = 6; end //delimiter ;call b4(2016,@count);select @count; #out只能当返回值 # 3.inoutdelimiter // create procedure b5( inout n1 int ) begin select * from blog where id &gt; n1; end //delimiter ;#mysql中调用set @n = 3;call b5(@n);select @n;#在python中基于pymysql调用cursor.callproc('b5',(4))print(cursor.fetchall()) #查询select的查询结果cursor.execute('select @n1') print(cursor.fetchall())# inout:既可以传入又可以返回 事务事务用于将某些操作的多个sql作为原子性操作,一旦有某一个出现错误,即可回滚到原来的状态,从而保证数据库的完整性 事务的四大特性 原子性:是指事务是一个不可分割的整体,事务中的操作要么就全部发生,要么都不成功 一致性:事务处理前后数据的完整性必须保持一致,完整性是指一个数据在某个时间点完全满足数据库中的约束要求 隔离性:是指多个用户访问一个数据库时,一个用户的事务处理不能被其他用户的事务所干扰,多个并发事务之间相互隔离 持久性:是指一个事务一旦被提交,他对数据库中的数据改变是永久的 举例说明 1234567891011121314151617181920212223242526create table user2(id int primary key auto_increment,name char(32),balance int);insert into user2(name,balance)values('wsb',1000),('egn',1000),('ysb',1000);#原子操作start transaction;update user2 set balance=900 where name='wsb'; #买支付100元update user2 set balance=1010 where name='egon'; #中介拿走10元update user2 set balance=1090 where name='ysb'; #卖家拿到90元commit;#出现异常，回滚到初始状态start transaction;update user2 set balance=900 where name='wsb'; #买支付100元update user2 set balance=1010 where name='egon'; #中介拿走10元uppdate user2 set balance=1090 where name='ysb'; #卖家拿到90元,出现异常没有拿到rollback; 下面是操作：当p_return_code为1时，表示异常，立马回滚。当为2时，出现警告，立马回滚原始状态。0表示成功 1234567891011121314151617181920212223242526272829303132delimiter //create PROCEDURE b6( OUT p_return_code tinyint)BEGIN DECLARE exit handler for sqlexception BEGIN -- ERROR set p_return_code = 1; rollback; END; DECLARE exit handler for sqlwarning BEGIN -- WARNING set p_return_code = 2; rollback; END; START TRANSACTION; insert into blog(name,sub_time) values(&apos;yyy&apos;,now()); COMMIT; -- SUCCESS set p_return_code = 0; #0代表执行成功END //delimiter ;set @res=123;call b6(@res);select @res; 索引一.索引的介绍数据库中专门用于帮助用户快速查找数据的一种数据结构。类似于字典中的目录，查找字典内容时可以根据目录查找到数据的存放位置吗，然后直接获取。 二.索引的作用约束和加速查找 三.常见的几种索引 普通索引 唯一索引 主键索引 联合索引 联合主键索引 联合唯一索引 联合普通索引 无索引： 从前往后一条一条查询 有索引：创建索引的本质，就是创建额外的文件（某种格式存储，查询的时候，先去格外的文件找，定好位置，然后再去原始表中直接查询。但是创建索引越多，会对硬盘也是有损耗。 建立索引的目的： a.额外的文件保存特殊的数据结构 b.查询快，但是插入更新删除依然慢 c.创建索引之后，必须命中索引才能有效 四.索引的种类hash索引和BTree索引 hash类型的索引：查询单条快，范围查询慢 btree类型的索引：b+树，层数越多，数据量指数级增长（我们就用它，因为innodb默认支持它） 五.索引的实现原理数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。 为表设置索引要付出代价的 一是增加了数据库的存储空间, 二是在插入和修改数据的时候要花费较多的时间(因为索引也要随之变动) 六.索引详细解释普通索引作用:仅有一个加速查找 1234567创建表+普通索引create table userinfo( nid int not null auto_increment primary key, name varchar(32) not null, email varchar(64) not null, index ix_name(name) ); 12普通索引create index 索引的名字 on 表名(列名) 12删除索引drop index 索引的名字 on 表名 12查看索引show index from 表名 唯一索引唯一索引的两个功能:加速查找和唯一约束(可含null) 1234567创建表和唯一索引create table userinfo( id int not null auto_increment primary key, name varchar(32) not null, email varchar(64) not null, unique index ix_name(name) ); 12唯一索引create unique index 索引名 on 表名(列名) 12删除唯一索引drop index 索引名 on 表名; 主键索引主键索引的两个功能:加速查找和唯一约束(可含null) 1234567891011121314151617 创建表和主键索引 create table userinfo( id int not null auto_increment primary key, name varchar(32) not null, email varchar(64) not null, unique index ix_name(name) ) orcreate table userinfo( id int not null auto_increment, name varchar(32) not null, email varchar(64) not null, primary key(nid), unique index ix_name(name) ) 12创建主键索引alter table 表名 add primary key(列名); 123删除主键索引alter table 表名 drop primary key;alter table 表名 modify 列名 int, drop primary key; 组合索引组合索引是将n个列组合成一个索引 12联合普通索引create index 索引名 on 表名(列名1,列名2); 七.索引名词1234覆盖索引:在索引文件中直接获取数据select name from userinfo where name = 'alex50000';索引合并:把多个单例索引合并使用select * from userinfo where name = 'alex13131' and id = 13131; 八.索引注意事项123456789(1)避免使用select *(2)count(1)或count(列) 代替count(*)(3)创建表时尽量使用char代替varchar(4)表的字段顺序固定长度的字段优先(5)组合索引代替多个单列索引（经常使用多个条件查询时）(6)尽量使用短索引 （create index ix_title on tb(title(16));特殊的数据类型 text类型）(7)使用连接（join）来代替子查询(8)连表时注意条件类型需一致(9)索引散列（重复少）不适用于建索引，例如：性别不合适 数据库的引擎mysql所支持的引擎123show engines\G;查看所有支持的引擎show variables like 'storage_engine%'; 查看正在使用的存储引擎create table t1(id int)engine=innodb;# 指定表类型/存储引擎 默认不写就是innodb 1.innoDB存储引擎支持事务,其设计目标主要面向联机事务处理(OLTP)的应用,其特点是行锁的设计,支持外键,并支持类似oracle的非锁定读,即默认读取操作不会产生锁,从mysql5.58版本开始是默认的存储引擎 2.MylSAM存储引擎不支持事务,表锁设计,支持全文索引,主要面向一些OLAP数据库应用,在mysql5.58版本之前是默认的存储引擎,(除 Windows 版本外 )数据库系统 与文件系统一个很大的不同在于对事务的支持,MyISAM 存储引擎是不支持事务的。究其根 本,这也并不难理解。用户在所有的应用中是否都需要事务呢?在数据仓库中,如果没有 ETL 这些操作,只是简单地通过报表查询还需要事务的支持吗?此外,MyISAM 存储引擎的 另一个与众不同的地方是,它的缓冲池只缓存(cache)索引文件,而不缓存数据文件,这与 大多数的数据库都不相同。 3.NDB存储引擎 NDB 存储引擎是一个集群存储引擎,类似于 Oracle 的 RAC 集群,不过与 Oracle RAC 的 share everything 结构不同的是,其结构是 share nothing 的集群架构,因此能提供更高级别的 高可用性。NDB 存储引擎的特点是数据全部放在内存中(从 5.1 版本开始,可以将非索引数 据放在磁盘上),因此主键查找(primary key lookups)的速度极快,并且能够在线添加 NDB 数据存储节点(data node)以便线性地提高数据库性能。由此可见,NDB 存储引擎是高可用、 高性能、高可扩展性的数据库集群系统,其面向的也是 OLTP 的数据库应用类型。 4、Memory 存储引擎正如其名,Memory 存储引擎中的数据都存放在内存中,数据库重 启或发生崩溃,表中的数据都将消失。它非常适合于存储 OLTP 数据库应用中临时数据的临时表,也可以作为 OLAP 数据库应用中数据仓库的维度表。Memory 存储引擎默认使用哈希 索引,而不是通常熟悉的 B+ 树索引。 5.Infobright 存储引擎第三方的存储引擎。其特点是存储是按照列而非行的,因此非常 适合 OLAP 的数据库应用。其官方网站是 http://www.infobright.org/,上面有不少成功的数据 仓库案例可供分析。 6、NTSE 存储引擎网易公司开发的面向其内部使用的存储引擎。目前的版本不支持事务, 但提供压缩、行级缓存等特性,不久的将来会实现面向内存的事务支持 7、BLACKHOLE黑洞存储引擎，可以应用于主备复制中的分发主库。 数据库的锁表级别锁(table-level)表级别的锁定是mysql个存储引擎中最大颗粒度的锁定机制,该锁定最大的特点就是实现逻辑非常简单,带来的系统负面影响最小,所以获取锁和释放锁都非常快,由于表级锁一次会将整个表都锁住,所以可以很好的避免死锁的问题 使用表级锁的主要是:myiSAM,MEMORY,CSV等一些非事务型存储引擎 行级锁(row-level)行级锁最大的特点就是锁定对象的颗粒度很小,也是目前各大数据库管理软件所实现的锁定颗粒度最小的,由于颗粒度很小,所以发生多锁定字段争用的概率也是最小的,能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能 虽然在并发处理上有很大的优势,但是行级索引也因此带来很多的弊端,由于锁定资源的颗粒度很小,所以每次获取和释放锁需要做的事情也多了,因此带来的消耗也就大了,行级锁很容易带来死锁 使用行级锁的主要是innoDB存储引擎 页级锁定(page-level)页级锁定是mysql中比较独特的一种锁定级别,在其他的数据库管理中不是太常见,页级锁定的特点:锁定颗粒度介于行级锁和表级锁之间的,所以获取锁定所需要的开销以及所能够提供的并发处理能力也是介于上面两者之间的, 使用页级锁定的主要是berkeleyDB存储引擎 总结表级锁:开销小.加锁快,不会出现死锁;锁定粒度大,发生锁冲突的概率最高,并发度最低 行级锁:开销大,加锁慢,会出现死锁,锁定粒度最小,发生锁冲突概率最低,并发程度最高 页面锁:开锁和加锁时间介于表锁和行锁之间,会出现死锁;锁定粒度介于表锁和行锁之间,并发一般 应用三个锁之间各有各的特点,如果从锁的角度来说,表级锁更适合查询为主,只有少量按索引条件更新数据的应用 ,如web应用;航迹锁更适用于有大量按索引条件,并发更新少量不同数据,同时又有并发查询的应用,如一些在线事务处理(OLTP)系统 MYSQL表级锁有两种模式 表共享读锁(Table Read Lock) 对mylSAM表进行读取操作时不会阻塞其他用户对同一表的写操作 表独占写锁(Table write Lock) 对MylSAM表的写操作,则会阻塞对其他用户对同一表的读写操作 innoDB和MyiSAM锁最大的不同 InnoDB支持事务,Myisam不支持 innoDB可以使用行级锁和表锁,MyiSAM只支持表锁 视图1.视图的定义视图是虚拟表或逻辑表，它被定义为具有连接的SQL SELECT查询语句。因为数据库视图与数据库表类似，它由行和列组成，因此可以根据数据库表查询数据。其内容由查询定义。 但是，视图并不在数据库中以存储的数据值集形式存在，行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。简单的来说视图是由其定义结果组成的表； 2.视图的优点1.数据库视图允许简化复杂查询，通过数据库视图，您只需使用简单的SQL语句，而不是使用具有多个连接的复杂的SQL语句。2.安全性。一般是这样做的:创建一个视图，定义好该视图所操作的数据。之后将用户权限与视图绑定。这样的方式是使用到了一个特性：grant语句可以针对视图进行授予权限。 3.视图的缺点1、性能：从数据库视图查询数据可能会很慢，特别是如果视图是基于其他视图创建的。 2、表依赖关系：将根据数据库的基础表创建一个视图。每当更改与其相关联的表的结构时，都必须更改视图。 4.创建视图语法: create view 视图名称 as sql语句 12create view teacher_view as select tid from teacher where tname='李平老师';select cname from course where teacher_id = (select tid from teacher_view); 5.使用视图12345往真实表中插入一条数据，查看一下视图，发现视图表也会跟着更新insert into course(cname,teacher_id) values(&apos;张三丰&apos;,2);更新一下数据，发现视图的数据也会跟着更新update course set cname=&apos;王五&apos;;不能修改视图的数据 6.修改视图12语法：ALTER VIEW 视图名称 AS SQL语句alter view teacher_view as select * from course where cid&gt;3; 7.删除视图12语法：DROP VIEW 视图名称DROP VIEW teacher_view 触发器触发器:触发器是一个特殊的存储过程，它是MySQL在insert、update、delete的时候自动执行的代码块。 1.创建触发器1234567891011121314151617181920212223242526272829303132333435# 插入前CREATE TRIGGER tri_before_insert_tb1 BEFORE INSERT ON tb1 FOR EACH ROWBEGIN ...END# 插入后CREATE TRIGGER tri_after_insert_tb1 AFTER INSERT ON tb1 FOR EACH ROWBEGIN ...END# 删除前CREATE TRIGGER tri_before_delete_tb1 BEFORE DELETE ON tb1 FOR EACH ROWBEGIN ...END# 删除后CREATE TRIGGER tri_after_delete_tb1 AFTER DELETE ON tb1 FOR EACH ROWBEGIN ...END# 更新前CREATE TRIGGER tri_before_update_tb1 BEFORE UPDATE ON tb1 FOR EACH ROWBEGIN ...END# 更新后CREATE TRIGGER tri_after_update_tb1 AFTER UPDATE ON tb1 FOR EACH ROWBEGIN ...END 1234567891011121314151617181920212223242526272829# 创建用户表create table user( id int primary key auto_increment, name varchar(20) not null, reg_time datetime, # 注册用户的时间 affirm enum('yes','no') # no表示该用户执行失败);#创建日志表create table userLog( id int primary key auto_increment, u_name varchar(20) not null, u_reg_time datetime # 注册用户的时间);# 创建触发器 delimiter 默认情况下，delimiter是分号 触发器名称应遵循命名约定[trigger time]_[table name]_[trigger event]delimiter //create trigger after_user_insert after insert on user for each rowbegin if new.affirm = 'yes' then insert into userLog(u_name,u_reg_time) values(new.name,new.reg_time); end if;end //delimiter ;#往用户表中插入记录，触发触发器，根据if的条件决定是否插入数据insert into user(name,reg_time,affirm) values ('张三',now(),'yes'),('李四',now(),'yes'),('王五',now(),'no'); 注意:请注意，在为INSERT定义的触发器中，可以仅使用NEW关键字。不能使用OLD关键字。但是，在为DELETE定义的触发器中，没有新行，因此您只能使用OLD关键字。在UPDATE触发器中，OLD是指更新前的行，而NEW是更新后的行 2.使用触发器触发器无法由用户直接调用,而只能由于对表的[增删改查]操作被动引起的 3.删除触发器1drop trigger trigger_userLog;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql基础]]></title>
    <url>%2F2019%2F01%2F14%2Fmysql%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[mysql数据库基本命令数据库的增删改查12345678910111213-- 增create database 数据库名称;-- 删drop database 库名;-- 改alter database 库名 更改的内容;-- 查show create database 库名;查看当前创建的数据库show databases; 查看所有的数据库select database();查看所在的数据库 表的增删改查1234567891011121314-- 增create table 表名(字段名 类型 约束);-- 删drop table 表名;-- 改alter table 表名 modify 字段名 类型;alter table 表名 add 字段名;-- 查show create table 表名;查看表的详细信息show tables;查看这个数据库先所有的表desc 表名;查看这个表里面所有的字段 数据的增删改查123456789101112131415-- 增insert into 表名(字段名) values (内容);-- 删delete from 表名; 清空数据,但是里面的id自增不会去除truncate 表名; 删除所有的内容-- 改update 表名 set name="xxx" where 条件update 表名 set 要修改的内容-- 查select 字段名 from 表名;select 字段1,字段2 from 表名;select * from 表名; 查看所有的内容 mysql的数据类型数据类型:定义列中可以存储什么数据以及该数据实际怎样存储的基本规则，其用于以下几个目的 允许限制可存储在列中的数据 允许在内部更有效的存储数据 允许变换排序顺序（作为数值数据类型，数值才能正确排序） 一.字符串数据类型该类型为最常用的数据类型，用来存储串（比如名字、地址等）；有两种串类型，分别是定长串和变长串 定长串：接受长度固定的字符串，其长度实在创建表时指定的；定长列不允许多余指定的字符数目，它们分配的存储空间与指定的一样多（比如char） 变长串：存储可变长度的文本，有些变长数据类型具有最大定长，有些是完全变长的，不论哪种，指定的数据得到保存即可（灵活） 数据类型 大小 用途 char 0-255字节 定长字符串 varchar 0-65535字节 变长字符串 tinyblog 0-255字节 不超过255个字符的二进制字符串 tinytext 0-255字节 短文本字符串 blob 0-65535字节 二进制形式的长文本数据 text 0-65535字节 长文本数据 mediumblob 0-16777215字节 二进制形式的中等长度文本数据 mediumtext 0-16777215字节 中等长度文本数据 二.数值类型 类型 大小 范围(有符号) 无符号 用途 tinyint 1字节 (-128,127) (0,255) 小整数值 smallint 2字节 (-32768,32767) (0,35535) 大整数值 mediumint 3字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 int或integer 4字节 (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 bigint 8 字节 (-9 233 372 036 854 775 808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 float 4字节 (-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466 E+38) 单精度 浮点数值 double 8字节 (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 双精度 浮点数值 decimal 对DECIMAL(M,D) ，如果M&gt;D，为M+2否则为D+2 依赖于M和D的值 依赖于M和D的值 小数值 三.日期和时间类型表示时间值的日期和时间类型为DATETIME、DATE、TIMESTAMP、TIME和YEAR。 类型 大小(字节) 范围 格式 用途 date 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 time 3 -838:59:59’/‘838:59:59’ HH:MM:SS 时间值或持续时间 year 1 1901/2155 YYYY 年份值 datetime 8 1000-01-01 00:00:00/9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 timestamp 4 1970-01-01 00:00:00/2038结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038年1月19日 凌晨 03:14:07 YYYYMMDD HHMMSS 混合日期和时间值，时间戳 四.枚举和集合 enum 单选只能在给定的范围内选一个值,如sex男和male女 set 多选 在给定的范围内可以选择一个或一个以上的值(爱好1,爱好2) 完整性约束 类型 说明 not null 不能为空 default 默认值 unique 设置唯一 primary key 主键 auto_increment 自增 foreign key 外键 unsigned 无符号 zerofill 使用0填充 on delete cascade 同步删除 on update cascade 同步更新 表查询单表查询 from: 找表 where :指定约束条件 比较运算符:&gt;,&lt;,&gt;=,&lt;=,!= between 80 and 100 :值在80到100之间 in(80,90,100):值是80,90或100 like’xiaomage‘:模糊查找也可以是%,或_:模糊查找 逻辑运算符:and or not group by:分组 having:过滤 执行优先级:where&gt;group by &gt;having 1.where 发生在分组 group by之前,因而where 中可以有任意字段,但绝对不能使用聚合函数 2.having 发生在分组 group by之后,因而having中可以使用分组字段,无法直接取到其他字段,可以使用其他函数 select :挑选 distinct:去重 order by:排序 asc:正序 小–&gt;大 DESC:倒序 大—-&gt;小 limit:限制结果的显示条数 第一个是:起始位置 第二个是:显示的条数 多表查询 select 字段 from 表1 inner | left |right join 表2 on 表1.字段 = 表2.字段 inner 是只连接匹配的行 right:外键之右连接:优先显示右半部分 left:外键之左连接:优先显示左半部分 union:连接left和right:可以显示全部信息 符合条件的连接查询 on:后面加两个表的比较条件 子查询 子查询是将一个查询语句嵌套在另一个查询语句中 内层查询语句的查询结果,可以为外层查询语句提供条件 子查询中可以包含:in ,not,any,all,exists和not exists EXISTS:判断的是真和假,有内容为真,没有就是假 聚合函数 函数名 说明 max() 求最大值 min() 求最小值 avg() 求平均值 sum() 求和 count() 求总个数 group_concat(name): 查找这个组里所有的名字 pymsql的使用(python)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import pymysql1.连接 host:数据库地址 port:端口 user:用户名 password:密码 db:数据库 charset:指定类型conn = pymysql.connect(host='127.0.0.1', port=3306, user='root', password='', db='db8', charset='utf8') 2.创建游标cursor = conn.cursor()# 防止注入sql = "select * from userinfo where username='%s' and pwd='%s'" cursor.execute(sql,[user,pwd])# 增# 一条sql = "insert into userinfo(username,pwd,) values(xx,oo)" cursor.execute(sql)# 多条cursor.executemany(sql,[(),(),()])# 删sql = "delete from userinfo where id = 2"cursor.execute(sql)# 改sql = "update userinfo set userinfo=%s where id = 2"cursor.execute(sql,username)# 查fetchone():获取下一行数据，第一次为首行；fetchall():获取所有行数据源fetchmany(4):获取4行数据sql = 'select * from userinfo'cursor.execute(sql)# 查询第一行的数据row = cursor.fetchone() # 获取查询的指定条数的信息ret = cursor.fetchmany(3)# 获取查询的所有信息ret = cursor.fetchall()# ------------------事务--------------sql = "insert into userinfo(name,password) values(%s,%s)"try: # 执行SQL语句 res = cursor.execute(sql,["rain222","1234"]) # 提交事务 conn.commit() # 提交之后，获取刚插入的数据的ID last_id = cursor.lastrowidexcept Exception as e: # 有异常，回滚事务 conn.rollback()# ----------------------------------------# 移动指针cursor.scroll(1,mode='relative') # 相对当前位置移动cursor.scroll(2,mode='absolute') # 相对绝对位置移动第一个值为移动的行数，整数为向下移动，负数为向上移动，mode指定了是相对当前位置移动，还是相对于首行移动# 关闭连接，游标和连接都要关闭cursor.close()conn.close() 数据库的备份和还原备份1234567891011-- 备份一个数据库基本语法mysqldump -u username -p dbname table1 table2 ...-&gt; BackupName.sql dbname参数表示数据库的名称； table1和table2参数表示需要备份的表的名称，为空则整个数据库备份； BackupName.sql参数表设计备份文件的名称，文件名前面可以加上一个绝对路径。通常将数据库被分成一个后缀名为sql的文件；-- 备份多个数据库mysqldump -u username -p --databases dbname2 dbname2 &gt; Backup.sql 加上了--databases选项，然后后面跟多个数据库-- 备份所有数据库mysqldump -u -root -p -all-databases &gt; D:\all.sql 还原1mysql -u root -p &lt; C:\backup.sql 注意：这种方法不适用于InnoDB存储引擎的表，而对于MyISAM存储引擎的表很方便。同时，还原时MySQL的版本最好相同。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git学习笔记]]></title>
    <url>%2F2019%2F01%2F14%2Fgit%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[安装git1234567# 设置全局信息git config --global user.name "Your Name"git config --global user.email "email@example.com"# 设置局部信息git config --local user.name "Your Name"git config --local user.email "email@example.com" 管理工作目录123456789101112git init 初始化git status 查看工作树状态git reflog 查看之前所有的操作记录git log --all # 查看所有git log --all --graph # 图形化查看git log -n2 # 只显示最近两次提交git log --oneline # 一行查看gitk 图形化显示 三种状态/区域的切换12345678910111213141516工作区 暂存区 本地仓库git add ./&lt;filename&gt; 工作区到暂存区git commit -m "理由" 暂存区到本地仓库git reset ./&lt;filename&gt; 从暂存区回退到工作区git checkout ./&lt;filename&gt; 丢弃工作区的内容git reset --hard &lt;commit_id&gt; 版本的回退,并删除git reset --soft &lt;commit_id&gt; 把内容存到暂存区git reset &lt;commit_id&gt; 把内容回退到工作区git rm &lt;filename&gt; 删除内容git mv oldname newname # 变更文件名 分支管理123456git branch &lt;name&gt; 创建分支git branch -v # 查看本地有多少分支git branch :查看分支git branch -d &lt;name&gt; 删除分支git checkout &lt;name&gt; 切换分支git merge &lt;name&gt; 把name分支合并到当前分支 标签管理123git tag &lt;name&gt; &lt;commit_id&gt; 给指定的版本加标签git tag 查看所有标签git tag -d &lt;name&gt; 删除标签 远程仓库建立连接123--ssh1.本地生成公钥私钥,在主用户的根目录下2.把公钥放入github中 和远程仓库建立连接1git remote add '远程仓库的别名' 远程仓库的地址 查看所有的仓库1git remote 向远程仓库提交代码12git push -u 远程仓库别名 分支名注意 -u 第一次提交代码的时候本地分支跟远程仓库的分支建立起连接 从远程仓库拉代码1git pull 远程仓库的别名 分支名 克隆项目1git clone 地址 笔记123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475类型分为:commit tree blobgit cat-file -t hash值 查看类型git cat-file -p hash值 查看具体提交的内容分离头指针git checkout hash值 # 会分离出来头指针git branch 分支名 hash值 # 创建新的分支git branch -b 分支名 commit值/分支名 # 创建并切换到新分支下git diff commit1 commit2 # 比较两次commit的差异 HEAD / HEAD-1 # 比较head 和head的父亲 git branch -d 分支名 # 删除分支git commit --amend # 修改最近一次提交的描述git rebase -i 你要修改信息的前一个commit # 修改之前的提交信息合成commitgit rebase -i 最后一个commit # 根据提示进行合并合成间隔的commitgit rebase -i 最后一个commit # 把相关的commit放在一起进行合并git diff --cached HEAD # 比较暂存区和最后一次提交有哪些修改git diff # 比较工作区和暂存区的区别git reset HEAD # 工作区和暂存区都和head一致git checkout -- index.html # 把暂存区的内容覆盖到工作区git reset HEAD -- style.css # 撤销暂存区中的内容git reset --hard 08cf37e3fb5 #版本回退,暂存区和工作区都变为回退的版本(慎用)git diff 分支1 分支2 -- 文件名 # 比较两个分支git stash # 存放到一边git stash list # 查看存储里几个git stash apply # 拿出来存放的git stash pop # 拿出并删除.gitignore 文件# 编写.gitignore文件可以让git不需要管理那些文件连接githubgit remote add 库名 地址git fetch 库名 分支名# 只拷贝下来不合并git pull 库名 分支名# 拷贝下来并合并git merge --allow-unrelated-histories 其他分支# 合并两个不相关的两个分支 12in:readme # 匹配redadme中文本内容stars :&gt; 1000 # 大于1000个stars的项目]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go基础部分]]></title>
    <url>%2F2019%2F01%2F14%2Fgo%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86%2F</url>
    <content type="text"><![CDATA[基础语法变量定义12345678910111213141516变量需要先声明,再赋值// 声明:var a int // 声明int类型的变量var b [10]int // 声明int类型的数组var c []int // 声明int类型的切片var d *int // 声明int类型的指针// 赋值a = 10b[0] = 10// 同时声明与赋值var a = 10a := 10a,b,c,d := 1,2,true,"xxx" 常量定义123456789101112131415// const是用来定义常量的const filename = "abc.txt"const a,b = 3,4 const ( python = 1 go = 2 java = 3)const( python = iota //自增,初始值为0 go java) 条件语句和循环if条件语句123456789101112if a == 100&#123; return "满分"&#125;else if a &gt;=60&#123; return "及格"&#125;else&#123; return "不及格"&#125;if a,b := 1,2; a + b == 3&#123; fmt.Println(a,b)&#125;fmt.Println(a,b) // 此处会报错,a和b是在if里定义的,作用域仅限于if 中使用 switch条件语句12345678910111213141516// go中的switch会自动break,除非使用fallthroughk:= 1switch k &#123; case 1: fmt.Println(1) case 2: fmt.Println(2) case 3: fmt.Println(3) case 4: fmt.Println(4) case 5: fmt.Println(5) default: fmt.Println(6)&#125; for循环12345678910111213141516171819// 赋值语句；判断语句；递增语句for i:=100; i&gt;0; i--&#123; fmt.Println(i)&#125;// 无赋值func test(n int)&#123; for ; n&gt;0 ; n/=2 &#123; fmt.Println(n); &#125;&#125;// 仅赋值scanner := bufio.NewScanner(file)for scanner.Scan()&#123; fmt.Println(scanner.Text);&#125;// 死循环for&#123; fmt.Println(1);&#125; 函数123456789101112131415161718192021222324// 格式func eval(a,b int, s string) int&#123; ... &#125;// 当有返回多个值时func test1(a,b int) (int, int)&#123; return a+b, a*b&#125;// 为多个返回值起名字（仅用于简单函数）func test2(a,b int) (q, r int)&#123; q = a+b r = a*b return // 自动对号入座返回相应变量&#125;q, r := test2(1,2)// 输出错误func test(a,b int)(int, error) &#123; if a+b&gt;100&#123; return a+b, fmt.Errorf("%s","error!") &#125;else&#123; return a+b, nil &#125;&#125; 指针1234567891011// go语言的参数传递是值传递func main()&#123; a,b := 1,2 swap_text(&amp;a,&amp;b)&#125;func swap_text(a,b *int)&#123; fmt.Println(a,*b) // 0xc420014050 2&#125;// 理解： a,b *int 存的是 int 类型值的地址，当对指针类型的变量 *a 时，就是取出地址对应的值 内建容器数组定义数组1234var arr [3]int // 会初始化为 [0,0,0]arr := [3]int&#123;1,2,3&#125; // [1,2,3] 只能存放三个arr := [...]&#123;1,2,3,4,5&#125; // [1,2,3,4,5] 不用在意多少arr := [2][4]int // 2行4列 遍历数组1234arr := [3]int&#123;1, 2, 3&#125;for k, v := range arr &#123; fmt.Println(k, v)&#125; 函数传递(按值传递)1234567891011// 注意,[5]int 与 [10]int是不同类型的// go语言一般不直接使用数组,而是使用切片func printArr(arr [5]int) &#123; for k,v:=range (arr)&#123; fmt.Println(k,v) &#125;&#125;func main() &#123; arr :=[5] int &#123;6,7,8,9,10&#125; printArr(arr)&#125; 切片概念123456// 顾首不顾尾arr := [...]&#123;0,1,2,3,4,5,6,7&#125;arr1 := arr[1:2] // 1arr2 := arr[:5] // 0,1,2,3,4arr3 := arr[2:] // 2,3,4,5,6,7arr4 := arr[:] // 0,1,2,3,4,5,6,7 视图1234567891011// 切片是数组的 "视图" , 即引用func updateArr(arr []int) &#123; // []中不写具体大小，表示是切片，引用传递 arr[0] = 100&#125;func main() &#123; arr :=[5] int &#123;0,1,2,3,4&#125; arr1 := arr[1:3] fmt.Println(arr,arr1) // [0 1 2 3 4] [1 2] updateArr(arr1) fmt.Println(arr,arr1) // [0 100 2 3 4] [100 2]&#125; 切片的扩展(cap) 123456789101112131415161718// 切片的切片依然是对一个数组的引用func updateArr(arr []int) &#123; arr[0] = 100&#125;func main() &#123; arr :=[5] int &#123;0,1,2,3,4&#125; arr1 := arr[1:3] arr2 := arr1[0:3] fmt.Println(arr,arr1,arr2) // [0 1 2 3 4] [1 2] [1 2 3] updateArr(arr1) fmt.Println(arr,arr1,arr2) // [0 100 2 3 4] [100 2] [100 2 3]&#125;// 查看扩展arr :=[5] int &#123;0,1,2,3,4&#125;arr1 := arr[1:3]arr2 := arr1[0:3]fmt.Println(arr1,len(arr1),cap(arr1)) // [1 2] 2 4fmt.Println(arr2,len(arr2),cap(arr2)) // [1 2 3] 3 4 直接创建切片123a := []int&#123;1,2,3&#125;var a []int //会初始化为nila := make([]int,16,32) // make(切片类型,切片长度,切片cap长度) 添加元素123456789101112131415161718192021222324252627282930// 若添加元素个数不超过cap值,则在原数组修改arr :=[5] int &#123;0,1,2,3,4&#125;arr1 := arr[1:3]arr2 := append(arr1, 10, 11)fmt.Println(arr1,arr2,arr) // [1 2] [1 2 10 11] [0 1 2 10 11]//若添加元素个数超过cap值,则开辟新的数组,拷贝并添加arr :=[5] int &#123;0,1,2,3,4&#125;arr1 := arr[1:3]arr2 := append(arr1, 10, 11, 12)fmt.Println(arr1,arr2,arr) // [1 2] [1 2 10 11 12] [0 1 2 3 4]func main() &#123; var s []int for i:=0; i&lt;10; i++ &#123; s = append(s,i) fmt.Println(s, cap(s)) &#125;&#125;// 结果：（当cap超出，就会重新分配cap值更大的新数组）[0] 1[0 1] 2[0 1 2] 4[0 1 2 3] 4[0 1 2 3 4] 8[0 1 2 3 4 5] 8[0 1 2 3 4 5 6] 8[0 1 2 3 4 5 6 7] 8[0 1 2 3 4 5 6 7 8] 16[0 1 2 3 4 5 6 7 8 9] 16 copy(拷贝)1234s1 := []int&#123;0,1,2,3&#125;s2 := make([]int,6)copy(s2,s1) // 把s1中的内容拷贝到s2中fmt.Println(s1,s2) // [0 1 2 3] [0 1 2 3 0 0] map定义123456789m := map[string]int&#123;&#125; // nilvar m map[string]string // nilm := make(map[string]string) // empty mapm2 := map[string]string&#123; "name":"xxx", "age":"111"&#125;fmt.Println(m2) // map[name:xxx age:111] 遍历12345678// map是无序的hash map,所以遍历时每一次输出的顺序都不一样m := map[string]string&#123; "name":"xxx", "age":"111"&#125;for k,v := range m&#123; fmt.Println(k,v)&#125; 取值123456789101112131415161718192021m := map[string]string&#123; "name":"xxx", "age":"111"&#125;name := m["name"] mt.Println(name) // "xxx"// 获取一个不存在的值sex := m["sex"]mt.Println(sex) // 返回一个空值// 判断key是否存在value,ok := m["aaa"]mt.Println(value,ok) // 返回一个空和false// 标准用法if v,ok := m["age"]; ok&#123; fmt.Println(v)&#125;else&#123; fmt.Println("key not exist")&#125; 删除(delete)1delete(m,"age") // 删除m中的age 面对对象1// go语言的面对对象仅支持封装,不支持继承和多态 结构体定义123456789101112131415161718// 定义一个结构体type treeNode struct&#123; value int left,right *treeNode&#125;func main()&#123; root := treeNode&#123;1,nil,nil&#125; node1 := treeNode&#123;value:3&#125; root.left = &amp;node1 root.left.right = new(treeNode) // 内建函数初始化node new(treeNode) = &amp;&#123;0 &lt;nil&gt; &lt;nil&gt;&#125; nodes := []treeNode&#123; &#123;1,nil,nil&#125;, &#123;2,&amp;root,&amp;node1&#125;, &#125; fmt.Println(nodes[1].left.left.value) // 3&#125; 自定义工厂函数123456789// 由于没有构造函数,所以可以用工厂函数替代func createNode(value int) *treeNode&#123; return &amp;treeNode&#123;value:value&#125;&#125;func main()&#123; node := createNode(10) fmt.Println(node) // &amp;&#123;10,&lt;nil&gt;,&lt;nil&gt;&#125;&#125; 结构体方法123456789101112131415161718192021// 结构体方法并不是写在结构体中,而是像函数一样写在外面,他实际上就是定义了[接收对象]的函数// 由于本质依然是函数,所以按值传递,若要改变对象,需要用指针传递type treeNode struct&#123; value int left,right *treeNode&#125;// func(接收对象) 方法名(参数) 返回值&#123;&#125;func (node treeNode) get() int&#123; return node.value&#125;func (node *treeNode) set(value int)&#123; node.value = value&#125;func main()&#123; root := treeNode&#123;2,nil,nil&#125; res := root.get() root.set(10)&#125; 封装123// 名字一般用CamelCase(驼峰体)// 首字母大写是public(公有方法,可以调用)方法// 首字母小写是private(私有方法)方法 包123// 每个目录只有一个包(package)// main包 包含程序入口// 为某结构体定义方法必须放在同一包内,但可以放不同文件 继承123go语言没有继承,如何扩展系统类型或者自定义类型呢? 1.定义别名 2.使用组合 获取第三方库12// go get xxx 从第官方下载第三方库,需要翻墙// gopm 可以获取国内镜像 (需要在github下载gopm) 接口定义123type xxx interface&#123; FuncName() string // 定义接口方法与返回类型&#125; 实现12345678910111213141516171819202122232425262728293031323334// 结构体不需要显示"实现" 接口,只要定义好方法即可// interface/interface.gopackage filetype File interface &#123; Read() string Write(str string)&#125;// interface/implament.go// File1 结构体实现了接口规定的方法package filetype File1 struct &#123; Content string&#125;func (file File1) Read() string&#123; return file.Content&#125;func (file *File1) Write(str string) &#123; file.Content = str&#125;// interface/entry/main.gopackage mainimport ( "../../interface" "fmt")func get(f file.File) string &#123; // 只有实现了 File 接口的结构体实例才能调用此方法 res := f.Read() return res&#125;func main() &#123; f := file.File1&#123;&#125; f.Write("www") fmt.Println(get(f))&#125; 类型123456// 查看类型 i.(type)var i AnimalInterface // 定义变量 i 是动物接口类型i = Cat&#123;"cat"&#125; // 假设 Cat 结构体实现了 AnimalInterface 接口i.(type) // Cati = Dog&#123;"dog"&#125; // 假设 Dog 结构体实现了 AnimalInterface 接口i.(type) // Dog 约束接口类型: i.(xxx)12345678var i AnimalInterface // 定义变量 i 是动物接口类型i = Cat&#123;"cat"&#125; // 假设 Cat 结构体实现了 AnimalInterface 接口cat := i.(Cat) // 如果 i 是Cat类型的，则拷贝赋值给 cat变量，否则报错）if dog, ok := i.(Dog); ok&#123; // ok&#125;else&#123; // i isn't dog&#125; 泛型:interface{}123456789101112131415161718192021type Queue []int // 定义了一个 int 类型的切片func (q *Queue) Push(v int)&#123; *q = append(*q, v)&#125;func (q *Queue) Pop() int&#123; head := (*q)[0] *q = (*q)[1:] return head&#125;// 将上面的切片改成可以接受任意类型：type Queue []interface&#123;&#125; // 定义了一个 int 类型的切片func (q *Queue) Push(v interface&#123;&#125;)&#123; *q = append(*q, v)&#125;func (q *Queue) Pop() interface&#123;&#125;&#123; head := (*q)[0] *q = (*q)[1:] return head&#125;// 强制类型转换：head.(int) 组合1234567891011121314type Cat interface&#123; cat()&#125;type Dog interface&#123; dog()&#125;type Animal interface&#123; // 要实例既实现 Cat 又实现 Dog Cat Dog&#125;func get(i Animal)&#123; i.cat() i.dog()&#125; 常用系统接口123456789101112// 1. 类似 toString() 的信息打印接口type Stringer interface&#123; String() string&#125;// 2. Readertype Reader interface&#123; Read(p []byte) (n int, err error)&#125;// 3. Writertype Writer interface&#123; Write(p []byte) (n int, err error)&#125; 函数式编程闭包12345678910111213func add() func(int) int &#123; sum := 0 // 此处的 sum 为自由变量 return func(v int) int &#123; sum += v // 指向外层sum return sum &#125;&#125;func main()&#123; add := add() for i:=0; i&lt;10; i++ &#123; fmt.Printf(add(i)) // 从 0 到 10 的累加 &#125;&#125; 生成器123456789101112131415// 一个斐波那契数列的生成器func fib() func() int&#123; a, b := 0, 1 return func() int&#123; a, b = b, a+b return a &#125;&#125;func main()&#123; f = fib() f() // 1 f() // 1 f() // 2 f() // 3&#125; 函数接口12345678910111213141516171819202122232425262728293031323334package mainimport ( "io" "bufio" "fmt" "strings")type funcType func() intfunc fib() funcType&#123; a, b := 0, 1 return func() int&#123; a, b = b, a+b return a &#125;&#125;func (f funcType) Read(p []byte) (n int, err error) &#123; next := f() if next &gt; 1000 &#123; return 0, io.EOF &#125; s := fmt.Sprintf("%d ", next) return strings.NewReader(s).Read(p)&#125;func scan(read io.Reader) &#123; scanner := bufio.NewScanner(read) for scanner.Scan() &#123; text := scanner.Text() fmt.Printf(text) &#125;&#125;func main() &#123; f := fib() scan(f)&#125; 错误处理与资源管理defer123456789101112131415func writeFile(filename string) &#123; file, err := os.Create(filename) if err!=nil &#123; panic("创建文件失败！") // 打印错误信息 &#125; defer file.Close() // 函数执行完毕前。关闭文件句柄 writer := bufio.NewWriter(file) defer writer.Flush() // 函数执行完毕前，将缓冲区中的内容刷新到文件中去 for i:=0; i&lt;100; i++ &#123; fmt.Fprintln(writer,i) // 写入缓冲区 &#125;&#125;func main() &#123; writeFile("1.txt")&#125; panic与recover123456789panic: 1.停止当前函数执行 2.停止之前,执行每层defer 3.如果没有recover 程序直接退出recover: 1.近在defer中调用 2.可以获取 panic 的值 3.如果无法处理,可重新 panic 12345678910111213141516171819202122232425262728293031323334353637383940// 例一：捕获 panicfunc dopanic()&#123; defer func() &#123; err := recover() fmt.Println(err) // error!! &#125;() panic("error!!")&#125;func main() &#123; dopanic()&#125;// 例二：捕获其他异常func dopanic()&#123; defer func() &#123; err := recover() fmt.Println(err) // runtime error: integer divide by zero &#125;() a := 0 b := 1/a fmt.Println(b)&#125;func main() &#123; dopanic()&#125;// 例三：无异常处理func dopanic()&#123; defer func() &#123; err := recover() if err, ok := err.(error); ok&#123; fmt.Println(err) &#125;else&#123; fmt.Println("no error!") &#125; &#125;() a := 0 fmt.Println(a)&#125;func main() &#123; dopanic()&#125; goroutine并发goroutine1234567891011121314151617181920212223242526272829// go func()&#123;&#125;()// 用go关键字开启协程,协程是非抢占式多任务处理,有协程主动交出控制权// 第一种func main()&#123; for i := 0; i &lt; 1000; i++&#123; go func(i int)&#123; for &#123; fmt.Println("xxxxx") &#125; &#125;(i) &#125; time.Sleep(time.Millsecond)&#125;// 第二种func main()&#123; var a [10]int for i := 0; i &lt; 10; i++ &#123; go func(i int) &#123; for &#123; a[i]++ runtime.Gosched() &#125; &#125;(i) &#125; time.Sleep(time.Microsecond) fmt.Println(a)&#125; go语言调度器12345678// go func()&#123;&#125;() // 用 go 关键字开启协程，协程是非抢占式多任务处理，由协程主动交出控制权goroutine可能交出控制权的点： - I/O操作，select - channel - 等待锁 - 函数调用时（有时，不一定） - runtime.Gosched() channel channel其实就是传统语言的阻塞消息队列，可以用来做不同goroutine之间的消息传递 定义12 更进一步：channel工厂12 channel 方向（只读与只写）12 缓冲区 向管道中写入就必须定义相应的输出，否则会报错 有缓冲区与无缓冲区的区别是 一个是同步的 一个是非同步的，即阻塞型队列和非阻塞队列 详解：https://blog.csdn.net/samete/article/details/52751227 12 关闭管道12 用channel等待任务结束上面的例子使用 time.Sleep(time.Microsecond)来等待任务结束，不精确且耗时 12 用 sync.WaitGroup 等待任务结束1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( "fmt" "sync")type worker struct &#123; in chan int wg *sync.WaitGroup // *&#125;func createWorker(wg *sync.WaitGroup) worker&#123; worker := worker&#123; in:make(chan int), wg:wg, &#125; doWorker(worker); return worker&#125;func doWorker(w worker) &#123; go func(w worker) &#123; for &#123; fmt.Printf("%c \n", &lt;-w.in) w.wg.Done() // 发送任务结束的信号 &#125; &#125;(w)&#125;func main() &#123; var wg sync.WaitGroup // 定义WaitGroup var arr [10] worker for i:=0; i&lt;10; i++ &#123; arr[i] = createWorker(&amp;wg) //按址传递，用一个引用来开始和结束 &#125; for i:=0; i&lt;10; i++ &#123; wg.Add(1) // 开始一个任务前，计时器加一（一定要在开始前加） arr[i].in &lt;- 'a'+i &#125; for i:=0; i&lt;10; i++ &#123; wg.Add(1) arr[i].in &lt;- 'A'+i &#125; wg.Wait() // 阻塞等待所有任务 done&#125; select 有多个 case 语句，只要有一个 case 处于非阻塞可执行状态，就执行，否则一直阻塞 如果有多个case都可以运行，select会随机公平地选出一个执行，其他不会执行 用法12 12 定时器 time.After() 设置一个定时器，返回一个 channel，到一段时间后，向channel发送一条当前时间 time.Tick() 返回一个 channel，每过一段时间向channel发送一条当前时间 123456789101112131415161718func main() &#123; c1,c2 := create(1),create(2) tm := time.After(2*time.Second) // 定时器，2秒后触发 tm2 := time.Tick(1*time.Second) // 每1秒触发一次 for &#123; select &#123; case n1 := &lt;-c1: fmt.Printf("%c \n",n1) case n2 := &lt;-c2: fmt.Printf("%c \n",n2) case t := &lt;- tm2: fmt.Println("------- ",t," -----------") case &lt;- tm: fmt.Println("bye") return &#125; &#125;&#125; 标准库的使用bufio库encodeing/json库time 库log库regexp库strings/math/rand库]]></content>
      <categories>
        <category>go语言</category>
      </categories>
      <tags>
        <tag>go语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ的基本使用]]></title>
    <url>%2F2019%2F01%2F14%2FRabbitMQ%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[官网:RabbitMQ RabbitMQ是一个在AMQP基础上完整的，可复用的企业消息系统。他遵循Mozilla Public License开源协议 MQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。消 息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信，直接调用通常是用于诸如远程过程调用的技术。排队指的是应用程序通过 队列来通信。队列的使用除去了接收和发送应用程序同时执行的要求。 RabbitMQ 安装1234567891011# 安装配置epel源rpm -ivh http://dl.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm# 安装erlangyum -y install erlang# 安装RabbitMQyum -y install rabbitmq-server# 开启和关闭RabbitMQservice rabbitmq-server start/stop 安装API 12345# python3安装pip install pika# python2安装easy_install pik 生产者消费者生产者123456789101112131415161718192021import pika# 无密码# connection = pika.BlockingConnection(pika.ConnectionParameters('IP地址'))# 有密码credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 声明一个队列(创建一个队列) 并支持持久化channel.queue_declare(queue='队列名称',durable=True)channel.basic_publish(exchange='', routing_key='队列名称', # 消息队列名称 body='发送的内容', properties=pika.BasicProperties( delivery_mode = 2, # 对信息进行持久化 )) # 关闭connection.close() 消费者12345678910111213141516171819202122import pika# 连接rabbitMQcredentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 声明一个队列(创建一个队列)channel.queue_declare(queue='队列名称')# 设置闲置时消费,那个消费者消费完了就接收任务channel.basic_qos(prefetch_count=1)# 设置回调函数def callback(ch, method, properties, body): print("消费者接受到了任务: %r" % body) ch.basic_ack(delivery_tag=method.delivery_tag) # 给服务端发送我接收到了 # 监听队列 no_ack=false 表示给服务端发送我接收到了的消息channel.basic_consume(callback,queue='队列名称',no_ack=False)# 开始监听channel.start_consuming() 发布者和订阅者全部订阅用户发布者 123456789101112131415import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 设置 中间商 exchange_type : fanout(全部) channel.exchange_declare(exchange='中间商名称',exchange_type='fanout')# 向队列添加内容channel.basic_publish(exchange='中间商名称', routing_key='', body='内容')connection.close() 订阅者 123456789101112131415161718192021222324252627import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 创建中间商(有的话就不会创建)channel.exchange_declare(exchange='中间商名称',exchange_type='fanout')# 随机生成一个队列result = channel.queue_declare(exclusive=True)queue_name = result.method.queu# 让exchange和queque进行绑定.channel.queue_bind(exchange='中间商名称',queue=queue_name)# 设置回调函数def callback(ch, method, properties, body): print("消费者接受到了任务: %r" % body)# 对队列进行监听channel.basic_consume(callback,queue=queue_name,no_ack=True)# 开始监听channel.start_consuming() 关键字发布发布者 12345678910111213141516import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 创建中间商 exchange_type direct:代表关键字队列channel.exchange_declare(exchange='中间商名称',exchange_type='direct')channel.basic_publish(exchange='中间商名称', routing_key='关键字', body='内容')# 关闭connection.close() 订阅者 123456789101112131415161718192021222324252627import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 创建中间商 exchange_type direct:代表关键字队列channel.exchange_declare(exchange='名称',exchange_type='direct')# 随机生成一个队列result = channel.queue_declare(exclusive=True)queue_name = result.method.queue# 让exchange和queque进行绑定. routing_key:指定关键字,可以绑定多次channel.queue_bind(exchange='名称',queue=queue_name,routing_key='关键字1')channel.queue_bind(exchange='名称',queue=queue_name,routing_key='关键字1')# 设置回调函数def callback(ch, method, properties, body): print("消费者接受到了任务: %r" % body)# 对队列进行监听channel.basic_consume(callback,queue=queue_name,no_ack=True)# 开始监听channel.start_consuming() 模糊匹配发布者 1234567891011121314151617import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 创建一个中间商 topic:代表模糊匹配channel.exchange_declare(exchange='名称',exchange_type='topic')# 发送数据channel.basic_publish(exchange='m3', routing_key='xxx.xxx.py', body='内容')# 关闭connection.close() 订阅者 1234567891011121314151617181920212223242526import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 创建一个中间商 topic:代表模糊匹配channel.exchange_declare(exchange='名称',exchange_type='topic')# 随机生成一个队列result = channel.queue_declare(exclusive=True)queue_name = result.method.queue# 让exchange和queque进行绑定. # :代表全部 *代表一个单词channel.queue_bind(exchange='名称',queue=queue_name,routing_key='xxx.#')# 回调函数def callback(ch, method, properties, body): print("消费者接受到了任务: %r" % body)# 监听channel.basic_consume(callback,queue=queue_name,no_ack=True)# 开始监听channel.start_consuming() 基于RabbitMQ事项RPC这是程序与程序之间的信息传递,所以起名中间商和服务商 中间商123456789101112131415161718192021222324252627282930313233343536373839404142434445import pikaimport uuidclass FibonacciRpcClient(object): # 连接rabbitMQ def __init__(self): credentials = pika.PlainCredentials("root", "123") self.connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14', credentials=credentials)) self.channel = self.connection.channel() # 随机生成一个消息队列(用于接收结果) result = self.channel.queue_declare(exclusive=True) self.callback_queue = result.method.queue # 监听消息队列中是否有值返回,如果有值则执行 on_response 函数(一旦有结果,则执行on_response) self.channel.basic_consume(self.on_response, no_ack=True,queue=self.callback_queue) def on_response(self, ch, method, props, body): if self.corr_id == props.correlation_id: self.response = body def call(self, n): self.response = None self.corr_id = str(uuid.uuid4()) # 中间商 给 服务商 发送一个任务: 任务id = corr_id / 任务内容 = '30' / 用于接收结果的队列名称 self.channel.basic_publish(exchange='', routing_key='rpc_queue', # 服务商接收任务的队列名称 properties=pika.BasicProperties( reply_to = self.callback_queue, # 用于接收结果的队列 correlation_id = self.corr_id, # 任务ID ), body=str(n)) # 循环监听信息有没有传回来 while self.response is None: # process_data_events也是一直监听有没有值 self.connection.process_data_events() return self.response# 实例化fibonacci_rpc = FibonacciRpcClient()# 调用程序response = fibonacci_rpc.call(50)print('返回结果:',response) 服务商12345678910111213141516171819202122232425262728293031import pika# 连接credentials = pika.PlainCredentials("root","123")connection = pika.BlockingConnection(pika.ConnectionParameters('192.168.19.14',credentials=credentials))channel = connection.channel()# 服务商监听任务队列channel.queue_declare(queue='rpc_queue')# 回调函数def on_request(ch, method, props, body): # 接收到内容并处理 n = int(body) response = n + 100 # 把处理好的信息通过队列把它返回回去 ch.basic_publish(exchange='', routing_key=props.reply_to, # 指定队列名称 properties=pika.BasicProperties(correlation_id= props.correlation_id), # 返回id body=str(response)) # body返回的是内容 # 返回一个ack 给服务端发送我接收到了 ch.basic_ack(delivery_tag=method.delivery_tag)# 设置闲置时消费,那个消费者消费完了就接收任务channel.basic_qos(prefetch_count=1)# 监听队列channel.basic_consume(on_request, queue='rpc_queue')# 开始监听channel.start_consuming()]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker的常用命令]]></title>
    <url>%2F2019%2F01%2F13%2Fdocker%E7%9A%84%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[版本查看12345# 版本查看docker version# 显示docker系统的信息docker info 镜像拉取1docker pull 镜像名称 镜像查询12345678# 查看本地镜像docker image ls# 查看公共仓库镜像docker search image_name# 查看镜像历史docker history image_name 镜像删除1sudo docker rmi 镜像名称 容器运行​ docker容器可以理解为在沙盒中运行的进程,这个沙盒包含该进程所必须的资源,包括文件系统,系统类库,shell环境等,但这个沙盒默认是不会运行任何程序的,你需要在沙盒中运行一个进程来启动某个容器,这个进程是该容器的唯一进程,所以当该进程结束时,容器也会结束 12345678# 运行容器docker run 容器名称# 在容器中安装新的程序docker run image_name apt-get install -y app_name# 交互式进入容器中docker run -i -t image_name /bin/bash 端口映射1docker run nginx -p 主机端口：容器端口 挂存储卷1docker run mysql -v 主机地址：容器地址 # 做地址映射 进入容器12# 进入容器sudo docker exec -it CONTAINER ID /bin/bash 查看容器日志12345# 查看日志sudo docker logs -f CONTAINER ID# 保存对容器的修改 -a, --author="" Author; -m, --message="" Commit message docker commit ID new_image_name 查询容器12345678 # 查看运行的docker容器sudo docker ps # 查看运行过的容器sudo docker ps -a# 列出最近一次启动的containerdocker ps -1 设置环境变量1sudo docker run -e MYSQL_ALLOW_EMPTY_PASSWORD=123456 mysql # -e 指定环境变量 容器(停止,启动,杀死)1234# 停止,启动,杀死一个容器docker stop Name/IDdocker start Name/IDdocker kill Name/ID 容器删除12345# 删除所有容器docker rm `docker ps -a -q`# 删除单个容器docker rm Name/ID 镜像操作123456789101112131415# 列出一个容器里面被改变的文件或者目录,list列表会显示三种事件,A 增加 D删除 C被改变docker diff Name/ID# 显示一个运行的容器里面的进程信息docker top Name/ID# 从容器里面拷贝文件/目录到本地一个路径docker cp Name:/container_path to_path docker cp ID:/container_path to_path # 重启一个正在运行的容器docker restart Name/ID# 附加到一个运行的容器上docker attach ID 保存和加载镜像​ 当需要把一台机器上的镜像迁移到另一台机器上的时候,需要保存于加载镜像 1234567891011# 保存镜像到一个tar包 -o, --output="" Write to an file docker save image_name -o file_path# 加载一个tar包格式的镜像 -i, --input="" Read from a tar archive file docker load -i file_path# 机器adocker save image_name &gt; /home/save.tar# 使用scp将save.tar拷到机器b上,然后docker load &lt; /home/save.tar 仓库登录123# 登录register server -e, --email="" Email; -p, --password="" Password; -u, --username="" Username # 这里是阿里云的镜像仓库sudo docker login --username=春秋羽123 registry.cn-beijing.aliyuncs.com 镜像构建12sudo docker build -t 名称：版本 # 在当前文件找dockerfilesudo docker build -t 名称：版本 -f /root/dockerfile # -f 指定文件 镜像打tag1sudo docker tag mysql:5.6（或ID） mycangku/mysql:1.0 镜像推送1sudo docker push 镜像名称：id Dockerfile的基本语法123456FROM # 基础镜像RUN # 执行命令ADD #拷贝文件WORKDIR # 设置工作目录CMD # 运行命令EXPOSE # 暴露的端口 2.对image的操作(search,pull,images,rmi,history) view plaincopy1234567891011121314# 检索imagedocker search image_name# 下载imagedocker pull image_name# 列出镜像列表:-a, --all=false Show all images; --no-trunc=false Don't truncate output; -q, --quiet=false Only show numeric IDs docker images# 删除一个或多个镜像 -f, --force=false Force; --no-prune=false Do not delete untagged parents docker rmi image_name # 显示一个镜像的历史 --no-trunc=false Don't truncate output; -q, --quiet=false Only show numeric IDs docker history image_name 3.启动容器(run)​ docker容器可以理解为在沙盒中运行的进程,这个沙盒包含该进程所必须的资源,包括文件系统,系统类库,shell环境等,但这个沙盒默认是不会运行任何程序的,你需要在沙盒中运行一个进程来启动某个容器,这个进程是该容器的唯一进程,所以当该进程结束时,容器也会结束 12345678# 在容器中运行"echo" 命令,输出"hello word"docker run image_name echo "hello word"# 交互式进入容器中docker run -i -t image_name /bin/bash# 在容器中安装新的程序docker run image_name apt-get install -y app_name ​ 在执行apt-get 命令的时候，要带上-y参数。如果不指定-y参数的话，apt-get命令会进入交互模式，需要用户输入命令来进行确认，但在docker环境中是无法响应这种交互的。apt-get 命令执行完毕之后，容器就会停止，但对容器的改动不会丢失。 4.查看容器(ps) view plaincopy12345678# 列出当前所有运行的containerdocker ps# 列出所有的containerdocker ps -a# 列出最近一次启动的containerdocker ps -1 5.保存对容器的修改(commit)​ 当你对一个容器进行修改之后(通过容器中运行某一个命令),可以把容器的修改保存下来,这样下一次可以从保存后的最新状态运行该容器 view plaincopy 12# 保存对容器的修改 -a, --author="" Author; -m, --message="" Commit message docker commit ID new_image_name ​ Note:image相当于一个类,container相当于实例，不过可以动态给实例安装新软件，然后把这个container用commit命令固化成一个image。 6.对容器的操作(rm、stop、start、kill、logs、diff、top、cp、restart、attach ) view plaincopy1234567891011121314151617181920212223242526272829# 删除所有容器docker rm `docker ps -a -q`# 删除单个容器docker rm Name/ID# 停止,启动,杀死一个容器docker stop Name/IDdocker start Name/IDdocker kill Name/ID# 从一个容器中取日志docker logs Name/ID# 列出一个容器里面被改变的文件或者目录,list列表会显示三种事件,A 增加 D删除 C被改变docker diff Name/ID# 显示一个运行的容器里面的进程信息docker top Name/ID# 从容器里面拷贝文件/目录到本地一个路径docker cp Name:/container_path to_path docker cp ID:/container_path to_path # 重启一个正在运行的容器docker restart Name/ID# 附加到一个运行的容器上docker attach ID ​ Note:attach命令允许你查看或影响一个运行的容器,你可以在同一时间attach同一个容器,你也可以从一个容器中脱离出来,是CTRL + C 7.保存和加载镜像(save load)​ 当需要把一台机器上的镜像迁移到另一台机器上的时候,需要保存于加载镜像 1234567891011# 保存镜像到一个tar包 -o, --output="" Write to an file docker save image_name -o file_path# 加载一个tar包格式的镜像 -i, --input="" Read from a tar archive file docker load -i file_path# 机器adocker save image_name &gt; /home/save.tar# 使用scp将save.tar拷到机器b上,然后docker load &lt; /home/save.tar 8.登录 registry server (login) view plaincopy12# 登录register server -e, --email="" Email; -p, --password="" Password; -u, --username="" Username docker login]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker的安装]]></title>
    <url>%2F2019%2F01%2F13%2Fdocker%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[docker安装1.Ubuntu系统Ubuntu安装docker大概要区分为Ubuntu14.04之前和Ubuntu14.04之后两种方法 如果是14.04版本之后的Ubuntu,其内核版本以及一些依赖包都已经准备充分,直接运行下载最新版docker即可: 1curl -sSL https://get.docker.com/ | sh 新安装的系统可能会没有curl服务,需要下载: 12sudo apt-get update sudo apt-get install curl 顺便提及,docker应用的启动需要root的管理员权限,最好在安装之前获取root权限,啰嗦一下如何方便地将用户转为root角色 1sudo su 然后根据提示输入当前用户密码即可. 下载好之后可以测试,下载hello-world或者busybox测试一下. 1sudo docker run hello-world docker run是docker的运行命令.后面是容器名称,如果本地没有该命令,则docker服务会从docker仓库下载该容器,然后运行. 测试打印 hello world就说明成功了.可用docker info查看安装信息. 最好使用新版本的Ubuntu安装docker.如果是12.04或者13.04版本的则需要先安装一些依赖性的包 先要升级内核(同样先获取root权限) 12sudo apt-get updatesudo apt-get install linux-image-generic-lts-raring linux-headers-generic-lts-raring Docker有deb格式的安装包 1sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9 后把Docker的库添加到apt的源列表中，更新并安装lxc-docker包。 1234sudo sh -c &quot;echo deb http://get.docker.io/ubuntu docker main\&gt; /etc/apt/sources.list.d/docker.list&quot;sudo apt-get updatesudo apt-get install lxc-docker 如果有警告信息,yes即可 2.centos系统和rhel这两个系统在新的版本里面都自带了docker,只不过docker版本不一定是最新的,我记得centos7里面的自带的docker是0.9,当前最新docker版本已经到了0.11,不过不会影响试用. 系统安装需要保证内核版本在3.10以上,低于这个版本的理论上也可以安装,只不过需要大牛去研究一番,我们直接升级内核 yum安装带aufs模块的3.10内核 123cd /etc/yum.repos.d wget http://www.hop5.in/yum/el6/hop5.repoyum install kernel-ml-aufs kernel-ml-aufs-devel 修改grub的主配置文件/etc/grub.conf，设置default=0，表示第一个title下的内容为默认启动的kernel（一般新安装的内核在第一个位置）,之后重启. 执行安装: 1curl -sSL https://get.docker.com/ | sh 启动服务: 1sudo service docker start 如果是系统版本7以上,已经自带docker包,直接运行: 1yum install docker 镜像加速1网址：https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible的基本使用]]></title>
    <url>%2F2019%2F01%2F13%2Fansible%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[一.简介ansible是什么东西?官方的title是“Ansible is Simple IT Automation”——简单的自动化IT工具。这个工具的目标有这么几项：让我们自动化部署APP；自动化管理配置项；自动化的持续交付；自动化的（AWS）云服务管理。 所有的这几个目标本质上来说都是在一个台或者几台服务器上，执行一系列的命令而已。就像我之前有介绍过的Fabric，以及我们基于Fabric开发的自动化应用部署的工具： Essay 。都是做了这么个事——批量的在远程服务器上执行命令 。 那么fabric和ansible有什么差别呢？简单来说fabric像是一个工具箱，提供了很多好用的工具，用来在Remote执行命令，而Ansible则是提供了一套简单的流程，你要按照它的流程来做，就能轻松完成任务。这就像是库和框架的关系一样。 当然，它们之间也是有共同点的——都是基于 paramiko 开发的。这个paramiko是什么呢？它是一个纯Python实现的ssh协议库。因此fabric和ansible还有一个共同点就是不需要在远程主机上安装client/agents，因为它们是基于ssh来和远程主机通讯的。 二.安装及初步使用 编译安装,此处使用yum 12yum install epel # 下载epel源yum install -y ansible # 安装ansible 2.查看ansible生成的文件 1rpm -ql ansible 3.查看ansible生成的命令 1234ansible # 用来执行ansible的一些命令ansible-doc # 用来查看ansible的模块的帮助信息ansible-playbook # 用来执行playbookansible-galaxy # 用来下载第三方的playbook 4.ansible命令模式 1234567ansible &lt;host-pattern&gt; [options]-a MODULE_ARGS # 模块的参数-C --check # 测试,干跑-f FORKS # 指定并发数--list-hosts # 列出host-pattern主机--syntax-check # 语法检查-m MODULE_NAME # 指定模块 5.ansible第一条命令 1ansible all -m ping # 跟系统自带的ping不一样 6.host-pattern格式 123456789101112131415[web]192.168.19.33192.168.19.44[db]192.168.19.55[cache]192.168.19.66www[001:006].example.com指定所有 all指定单台机器(指定多个机器)指定分组(多个分组)指定分组并集 # ansible "web:db" -m ping指定分组的交集 # ansible "web:&amp;db" -m ping指定分组的差集 # ansible "web:!db" -m ping 7.ansible-doc 12345Usage: ansible-doc [-l|-F|-s] [options] [-t &lt;plugin type&gt; ] [plugin]-a # 列出所有的模块-l # 列出ansible的模块-s # 片段式显示模块的信息 8.补充 123456789[name] #分组name=CentOS-$releasever - Base - mirrors.aliyun.com #这个分组的名字failovermethod=prioritybaseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ #分组的url,叫baseurl http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/ http://mirrors.cloud.aliyuncs.com/centos/$releasever/os/$basearch/gpgcheck=0 # gpgcheck=1需要验证key文件,gpgcheck=0不验证keyenabled=1 #enabled=1 表示分组可用,enabled=0表示分组是不可用的gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7 #key文件 三.命令相关命令相关1.command 1234ansible web -m aommand "pwd"ansible web -a "chdir=/tmp/ mkdir /data2" # 切换到/tmp并执行pwdansible web -a "creates=/etc/ mkdir /data2" # 判断creates是否存在,真就忽略后面的操作ansible web -a "removes=/tmp/data mkdir /tmp/data2" # 判断removes是否存在,假就忽略后面的操作 2.shell 123ansible web -m shell -a "echo 'test1'|password --stdin test1" # 修改密码ansible 192.168.19.9 -m shell "/root/a.sh" # 指定远程主机上的shell脚本ansible 192.168.19.2 -m shell -a "/root/a.py" # 指定远程主机上的python文件 3.sctipt 1ansible all -m script -a "/root/a.sh" # 执行管控机的shell脚本 文件相关1.copy复制管控机文件到被管控机 123456ansible web -m copy -a "src=/etc/xxx dest=/data/xxx" # src指定源文件 dest指定目标文件ansible web -m copy -a "src=/etc/xxx dest=/data/xxx backup=yes" # backup备份ansible web -m copy -a "src=/etc/init.d dest=/data/" # 复制目录和目录下的文件到远程主机,远程主机也是一个文件夹ansible web -m copy -a "src=/etc/init.d/ dest=/data/" # 复制目录下的文件ansible web -m copy -a "src=/etc/xxx dest=/data/xxx backup=yes mode=600" # mode 指定权限,owner指定文件的属主,group用来指定属组ansible web -m copy -a "content='内容xxxxx' dest=/data10/xx.txt" # content 直接写内容 2.file 1234ansible db -m file -a "path=/data10 state=directory" # path指定地址,state=directory表示创建文件夹ansible db -m file -a "path=/data10/xxx state=touch" # state=touch 表示创建新文件ansible db -m file -a "path=/data10/test1 state=absent" # state=absent 代表删除ansible db -m file -a 'path=/data10/test10 src=/data10/test1 state=link' #src表示源文件,path是不是目标,state=link是不是创建一个软连接 3.fetch 1ansible db -m fetch -a "src=/etc/xxx dest/tmp" # src源地址(在被控机器上),dest目标地址(管控机上的地址)每个管控机的文件都生成了一个目录,会保持文件的原来目录结构 软件相关1.yum 1234ansible web -m yum -a "name=nginx state=installed" # 安装nginxansible web -m shell -a "rpm -qa | grep nginx" # 查看nginx是不是安装成功ansible web -m yum -a "name=nginx state=absent" # 卸载nginxansible web -m yum -a "name=redis,memcached" 2.pip 1ansible web -m pip -a "name=Django==1.11.15" 定时任务 cron 123ansible web -m cron -a "name=testjob minute=4 job='echo 哈哈 &gt; /tmp/xx.txt'" # 创建 name:指定的cron名字 minute:指定分钟 hour:指定小时 day:指定天 month:指定月 weekday:指定周 job:指定要执行的命令ansible web -m cron -a "name=testjob state=absent" # 删除任务ansible web -m cron -a "name=testjob minute=4 disabled=yes job='echo 哈哈 &gt; /tmp/xx.txt'" # disabled=yes表示禁用 用户相关 user 12ansible web -m user -a "name=客户1 home=/data/客户1" # 创建用户并指定家目录ansible web -m user -a "name=客户2 groups='xxx1,xxx2' home=/data/客户2" # groups='xxx1,xxx2' 指定用户的附加组 收集系统信息 setup 收集系统信息 1234567891011121314151617"ansible_all_ipv4_addresses" #ipv4简单信息"ansible_all_ipv6_addresses" #ipv6的简单信息"ansible_architecture": "x86_64", #系统架构"ansible_date_time": #系统时间"ansible_default_ipv4": #详细信息"ansible_devices": #磁盘信息"ansible_distribution_major_version": "7",#系统版本"ansible_distribution": "CentOS", #系统的发行商"ansible_distribution_file_variety": "RedHat", #系统系列"ansible_fqdn": "localhost.localdomain", #系统的主机名"ansible_hostname": "localhost",#简写主机名"ansible_kernel": "3.10.0-693.el7.x86_64", #系统的内核版本"ansible_os_family": "RedHat",# 系统的家族"ansible_processor_vcpus": 2, #cpu的个数"ansible_python_version": "2.7.5", # ansible所用python的版本 ansible web -m setup -a 'filter="*cpu*"' #filter搜索 启动应用 service 123enabled:#开机启动name:#服务的名称state: #操作 四.playbook的基本使用 playbook命令,建议:一个文件做一件事 1.基本格式 12345678ansible-playbook [options] playbook.yml-C # 干跑,检查-f FORKS # 用来做并发,来指定并发数--list-hosts #列出执行命令的主机--syntax-check # 检查语法--list-tasks #列出playbook要执行的任务列表-t TAGS, #指定要运行到tags-e EXTRA_VARS #给playbook传递变量 2.单个playbook 12345678#单个playbook- hosts: web #指定要运行命令的主机 remote_user: root # 指定运行命令的用户 tasks: #任务列表 - name: mkdir # 任务1,name是必须的 file: path=/data state=directory # 指定的模块: 模块的参数 - name: copyfile copy: src=/etc/fstab dest=/data/f 3.多个playbook 1234567891011121314##多个playbook- hosts: web remote_user: root tasks: - name: mkdir file: path=/data state=directory - name: copyfile copy: src=/etc/fstab dest=/data/f- hosts: db remote_user: root tasks: - name: wget shell: "wget -O /data/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo" 4.指定tags 123456789##指定tags- hosts: web remote_user: root tasks: - name: mkdir file: path=/data state=directory - name: copyfile copy: src=/etc/fstab dest=/data/f tags: copyfile 变量1.第一种 123456## 传递变量 -e"key=value"- hosts: web remote_user: root tasks: - name: yum &#123;&#123;pkg_name&#125;&#125; pkg yum: name=&#123;&#123;pkg_name&#125;&#125; 2.第二种 1234567- hosts: web remote_user: root vars: - pkg_name: memcached tasks: - name: yum &#123;&#123;pkg_name&#125;&#125; pkg yum: name=&#123;&#123;pkg_name&#125;&#125; 3.第三种 1234#在hosts文件里面写,值可以不同[web]192.168.19.9 pkg_name=nginx192.168.19.26 pkg_name=redis 4.第四种 12[web:vars]pkg_name=nginx 5.变量的应用顺序 1-e &gt; yml文件 &gt; hosts文件 #命令行里面是最高的,hosts文件是最低的 条件 when 条件判断 123456789- hosts: cache remote_user: root tasks: - name: copyfile1 copy: content='wusir zhenchou' dest=/tmp/a.txt when: ansible_os_family=="RedHat" #只有为真的时候才会执行上面的操作 - name: copyfile2 copy: content='alex gengchou' dest=/tmp/b.txt when: ansible_os_family=="OpenBSD" 循环with_items1.循环单个 12345678910111213- hosts: cache remote_user: root tasks: - name: create user user: name=&#123;&#123;item&#125;&#125; ## 循环下面的with_items with_items: - yuchao - yantao - name: create group group: name=&#123;&#123;item&#125;&#125;## 循环下面的with_items with_items: - yuchao2 - yantao2 2.循环嵌套 12345678910111213- hosts: cache remote_user: root tasks: - name: create group group: name=&#123;&#123;item&#125;&#125; with_items: - yuchao4 - yantao4 - name: create user user: name=&#123;&#123;item.name&#125;&#125; group=&#123;&#123;item.group&#125;&#125; #可以通过字典取值 with_items: - &#123;"name":yuchao3,"group":yuchao4&#125; - &#123;"name":yantao3,"group":yuchao4&#125; 模板文件1.模板的基本使用 12345678910- hosts: cache remote_user: root tasks: - name: install redis yum: name=redis - name: copyfile template: src=redis.conf.j2 dest=/etc/redis.conf ## 模板基于jinja2 - name: start service: name=redis state=started #模板文件放在templates,可以直接用相对路径去调用配置文件 roles(高级使用) 作用 结构清晰 可以重用 结构 12345tasks #目录是必须的,存放任务templates #是存放模板vars #用来存放变量 ### 切记,不能加-,加-报错files #用来存放文件mkdir -p &#123;nginx,uwsgi,mysql&#125;/&#123;tasks,templates,vars,files&#125; #创建目录结构的命令 补充生成公私钥 1ssh-keygen 复制公钥到远程主机 1ssh-copy-id 192.168.19.99 ping命令发送的是ICMP协议 查看用户相关 1234tail -l /etc/shadow 查看最后一个用户echo "testl" | password --stdin testl 设置用户密码,不需要二次确useradd # 创建用户默认的家目录在/home -d 可以指定用户的家目录groupadd # 用来创建用户组,用户组没有家目录 创建链接 12ln 创建硬链接 链接文件变更 源文件不变ln -s 创建软连接 链接文件变更 源文件变 pip的基本使用 123pip freeze &gt; file # 给当前的python模块做快照pip install -r xxx.txt # 安装pip list # 查看所有的python模块 crontab定时任务 1234567* */5 * * * job #/n 表示每隔n 0 */5 * * 3,6 job #3,6 表示周三和周六## 切记 最前面不能用*,表示每时每刻都在执行,一定要有一个时间## 应用场景: 打包日志,定期的同步时间,备份-e # 编辑-l # 列出-r # 删除 启动应用 12systemctl restart nginx # centos7中的操作应用service nginx restart # centos6里面的操作 查看系统内存使用量 1free -m 查看系统的内存使用量 Ad-hoc:命令行的意思 mv 的使用 1mv redis.conf&#123;,.j2&#125; == mv redis.conf redis.conf.j2 yum和rpm的基本使用 1234yum remove 卸载rpm redhat pk manageyum 自动解决依赖关系rpm 不会自动解决依赖关系 CI和CD的基本使用 12CI 持续交付 jenkins maven war包CD 持续集成 脚本去做 docker (最大的一个作用,到处运行 ) k8s 暂时关闭防火墙 1setenforce 0 #暂时关闭selinux uwsgi的配置 1234567891011121314151617[uwsgi]http = :8000 #端口#the local unix socket file than commnuincate to Nginxsocket = /data/mysite/mysite.socket #socket 只能本机使用# the base directory (full path)chdir = /data/mysite #当前工作目录# Django's wsgi filewsgi-file = mysite/wsgi.py #要执行的文件# maximum number of worker processesprocesses = 4 #进程数#thread numbers startched in each worker processthreads = 2 #线程数# clear environment on exitvacuum = truedaemonize = /data/mysite/uwsgi.log #后台启动,并提供日志py-autoreload=1 #py文件变更后uwsgi自动重启 kill -9 可以杀死父进程 启动uwsgi 1uwsgi --http :8000 --module mysite.wsgi ## --http 启动的端口 --module 项目.wsgi文件]]></content>
      <categories>
        <category>运维开发之路</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
</search>
